{"metadata": {"signature": "sha256:e5ad248aa021fb48dc8263d44b4460543481084da0f29f2f9eeb6b7c7b0d87db"}, "nbformat": 3, "nbformat_minor": 0, "original_thread": "58637c716a5e6d00522939b7", "worksheets": [{"cells": [{"cell_type": "markdown", "id": "0FD805DB55864976964D3533B973EDBA", "metadata": {}, "source": "# Tensorflow \u7b14\u8bb0 1 CNN "}, {"cell_type": "code", "collapsed": false, "id": "83AF315C089F4855BC19965C26AEDDF4", "input": "%%time\nfrom __future__ import division\nfrom __future__ import print_function  \nimport numpy as np\nimport pandas as pd\nimport matplotlib.pylab as plt\n%matplotlib inline\nimport seaborn as sns\n\nimport tensorflow as tf\n\nfac = np.load('/home/big/Quotes/TensorFlow deal with Uqer/fac16.npy').astype(np.float32)\nret = np.load('/home/big/Quotes/TensorFlow deal with Uqer/ret16.npy').astype(np.float32)\n#fac = np.load('/home/big/Quotes/TensorFlow deal with Uqer/fac16.npy')\n#ret = np.load('/home/big/Quotes/TensorFlow deal with Uqer/ret16.npy')\n\n# Parameters\nlearning_rate = 0.001 # \u5b66\u4e60\u901f\u7387\uff0c\ntraining_iters = 20 # \u8bad\u7ec3\u6b21\u6570\nbatch_size = 1024 # \u6bcf\u6b21\u8ba1\u7b97\u6570\u91cf \u6279\u6b21\u5927\u5c0f\ndisplay_step = 10 # \u663e\u793a\u6b65\u957f\n\n# Network Parameters\nn_input = 40*17 # 40\u5929\u00d717\u591a\u56e0\u5b50\nn_classes = 7 # \u6839\u636e\u6da8\u8dcc\u5e45\u5ea6\u5206\u62107\u7c7b\u522b\n# \u8fd9\u91cc\u6ce8\u610f\u8981\u4f7f\u7528 one-hot\u683c\u5f0f\uff0c\u4e5f\u5c31\u662f\u5982\u679c\u5206\u7c7b\u59823\u7c7b -1,0,1 \u5219\u9700\u89813\u5217\u6765\u8868\u8fbe\u8fd9\u4e2a\u5206\u7c7b\u7ed3\u679c\uff0c3\u7c7b\u662f-1 0 1 \u7136\u540e\u662f\u54ea\u7c7b\uff0c\u54ea\u7c7b\u90a3\u4e00\u884c\u4e3a1 \u5426\u5219\u4e3a0\ndropout = 0.8 # Dropout, probability to keep units\n\n# tensorflow \u56fe Graph \u8f93\u5165 input\uff0c\u8fd9\u91cc\u7684\u5360\u4f4d\u7b26\u5747\u4e3a\u8f93\u5165\nx = tf.placeholder(tf.float32, [None, n_input])\ny = tf.placeholder(tf.float32, [None, n_classes])\nkeep_prob = tf.placeholder(tf.float32) #dropout (keep probability)", "language": "python", "metadata": {}, "outputs": [], "trusted": true}, {"cell_type": "markdown", "id": "9188246C50844C0683081FC7C1111E49", "metadata": {}, "source": "### 2\u5c42"}, {"cell_type": "code", "collapsed": false, "id": "42F7F9968A2D45088E3D905ABE3E666E", "input": "# 2\u5c42CNN\ndef CNN_Net_two(x,weights,biases,dropout=0.8,m=1):\n    # \u5c06\u8f93\u5165\u5f20\u91cf\u8c03\u6574\u6210\u56fe\u7247\u683c\u5f0f\n    # CNN\u56fe\u50cf\u8bc6\u522b\uff0c\u8fd9\u91cc\u5c06\u524d40\u5929\u7684\u591a\u56e0\u5b50\u6570\u636e\u5047\u8bbe\u6210\u56fe\u7247\u6570\u636e\n    x = tf.reshape(x, shape=[-1,40,17,1])\n    \n    # \u5377\u79ef\u5c421\n    x = tf.nn.conv2d(x, weights['wc1'], strides=[1,m,m,1],padding='SAME')\n    # x*W + b\n    x = tf.nn.bias_add(x,biases['bc1'])\n    # \u6fc0\u6d3b\u51fd\u6570\n    x = tf.nn.relu(x)\n    \n    # \u5377\u79ef\u5c422 \u611f\u53d7\u91ce 5 5 16 64 \u79fb\u52a8\u6b65\u957f1\n    x = tf.nn.conv2d(x, weights['wc2'], strides=[1,m,m,1],padding='SAME')\n    x = tf.nn.bias_add(x,biases['bc2'])\n    x = tf.nn.relu(x)\n    \n    # \u5168\u8fde\u63a5\u5c42\n    x = tf.reshape(x,[-1,weights['wd1'].get_shape().as_list()[0]])\n    x = tf.add(tf.matmul(x,weights['wd1']),biases['bd1'])\n    x = tf.nn.relu(x)\n    \n    # Apply Dropout\n    x = tf.nn.dropout(x,dropout)\n    # Output, class prediction\n    x = tf.add(tf.matmul(x,weights['out']),biases['out'])\n    return x\n\n# Store layers weight & bias\nweights = {\n    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 16])),\n    'wc2': tf.Variable(tf.random_normal([5, 5, 16, 64])),\n    # fully connected, 7*7*64 inputs, 1024 outputs\n    'wd1': tf.Variable(tf.random_normal([40*17*64, 1024])),\n    'out': tf.Variable(tf.random_normal([1024, n_classes]))\n}\n\nbiases = {\n    'bc1': tf.Variable(tf.random_normal([16])),\n    'bc2': tf.Variable(tf.random_normal([64])),\n    'bd1': tf.Variable(tf.random_normal([1024])),\n    'out': tf.Variable(tf.random_normal([n_classes]))\n}", "language": "python", "metadata": {}, "outputs": [], "trusted": true}, {"cell_type": "markdown", "id": "6291C8589B444C958D667C6D1380EFF2", "metadata": {}, "source": "### 3\u5c42"}, {"cell_type": "code", "collapsed": false, "id": "B92D96B0B9974DEB88073F8B8B032B02", "input": "def CNN_Net_three(x,weights,biases,dropout=0.8,m=1):\n    \n    x = tf.reshape(x, shape=[-1,40,17,1])\n    \n    # \u5377\u79ef\u5c421\n    x = tf.nn.conv2d(x, weights['wc1'], strides=[1,m,m,1],padding='SAME')\n    x = tf.nn.bias_add(x,biases['bc1'])\n    x = tf.nn.relu(x)\n    \n    # \u5377\u79ef\u5c422 \n    x = tf.nn.conv2d(x, weights['wc2'], strides=[1,m,m,1],padding='SAME')\n    x = tf.nn.bias_add(x,biases['bc2'])\n    x = tf.nn.relu(x)\n    \n    # \u5377\u79ef\u5c423 \n    x = tf.nn.conv2d(x, weights['wc3'], strides=[1,m,m,1],padding='SAME')\n    x = tf.nn.bias_add(x,biases['bc3'])\n    x = tf.nn.relu(x)    \n    \n    # \u5168\u8fde\u63a5\u5c42\n    x = tf.reshape(x,[-1,weights['wd1'].get_shape().as_list()[0]])\n    x = tf.add(tf.matmul(x,weights['wd1']),biases['bd1'])\n    x = tf.nn.relu(x)\n    \n    # Apply Dropout\n    x = tf.nn.dropout(x,dropout)\n    # Output, class prediction\n    x = tf.add(tf.matmul(x,weights['out']),biases['out'])\n    return x\n\n# Store layers weight & bias\nweights = {\n    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 16])),\n    'wc2': tf.Variable(tf.random_normal([5, 5, 16, 32])),\n    'wc3': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n    # fully connected, 7*7*64 inputs, 1024 outputs\n    'wd1': tf.Variable(tf.random_normal([40*17*64, 1024])),\n    'out': tf.Variable(tf.random_normal([1024, n_classes]))\n}\n\nbiases = {\n    'bc1': tf.Variable(tf.random_normal([16])),\n    'bc2': tf.Variable(tf.random_normal([32])),\n    'bc3': tf.Variable(tf.random_normal([64])),\n    'bd1': tf.Variable(tf.random_normal([1024])),\n    'out': tf.Variable(tf.random_normal([n_classes]))\n}", "language": "python", "metadata": {}, "outputs": [], "trusted": true}, {"cell_type": "code", "collapsed": false, "id": "A1A04E163D514EFC9C75B7E359BC80F7", "input": "%%time\n# \u6a21\u578b\u4f18\u5316\npred = CNN_Net_two(x,weights,biases,dropout=keep_prob)\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred,y))\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\ncorrect_pred = tf.equal(tf.argmax(pred,1),tf.arg_max(y,1))\n# tf.argmax(input,axis=None) \u7531\u4e8e\u6807\u7b7e\u7684\u6570\u636e\u683c\u5f0f\u662f -1 0 1 3\u5217\uff0c\u8be5\u8bed\u53e5\u662f\u8868\u793a\u8fd4\u56de\u503c\u6700\u5927\u4e5f\u5c31\u662f1\u7684\u7d22\u5f15\uff0c\u4e24\u4e2a\u7d22\u5f15\u76f8\u540c\u5219\u662f\u9884\u6d4b\u6b63\u786e\u3002\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n# \u66f4\u6539\u6570\u636e\u683c\u5f0f\uff0c\u964d\u4f4e\u5747\u503c\ninit = tf.global_variables_initializer()\nwith tf.Session() as sess:\n    sess.run(init)\n    # for step in range(300):\n    for step in range(1):\n        for i in range(int(len(fac)/batch_size)):\n            batch_x = fac[i*batch_size:(i+1)*batch_size]\n            batch_y = ret[i*batch_size:(i+1)*batch_size]\n            sess.run(optimizer,feed_dict={x:batch_x,y:batch_y,keep_prob:dropout})\n            if i % 10 ==0:\n                print(i,'----',(int(len(fac)/batch_size)))\n        loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,y: batch_y,keep_prob: 1.})\n        print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n                  \"{:.5f}\".format(acc))\n    print(\"Optimization Finished!\")   \n    sess.close()", "language": "python", "metadata": {}, "outputs": [], "trusted": true}, {"cell_type": "markdown", "id": "1EA32E3F81F94897B9AA338E92DC3DF2", "metadata": {}, "source": "### 5\u5c42"}, {"cell_type": "code", "collapsed": false, "id": "214D142925D2478D89413F7E75FA3B06", "input": "def CNN_Net_five(x,weights,biases,dropout=0.8,m=1):\n    \n    x = tf.reshape(x, shape=[-1,40,17,1])\n    \n    # \u5377\u79ef\u5c421\n    x = tf.nn.conv2d(x, weights['wc1'], strides=[1,m,m,1],padding='SAME')\n    x = tf.nn.bias_add(x,biases['bc1'])\n    x = tf.nn.relu(x)\n    \n    # \u5377\u79ef\u5c422 \n    x = tf.nn.conv2d(x, weights['wc2'], strides=[1,m,m,1],padding='SAME')\n    x = tf.nn.bias_add(x,biases['bc2'])\n    x = tf.nn.relu(x)\n    \n    # \u5377\u79ef\u5c423 \n    x = tf.nn.conv2d(x, weights['wc3'], strides=[1,m,m,1],padding='SAME')\n    x = tf.nn.bias_add(x,biases['bc3'])\n    x = tf.nn.relu(x)    \n    \n    # \u5377\u79ef\u5c424 \n    x = tf.nn.conv2d(x, weights['wc4'], strides=[1,m,m,1],padding='SAME')\n    x = tf.nn.bias_add(x,biases['bc4'])\n    x = tf.nn.relu(x) \n    \n    # \u5377\u79ef\u5c425 \n    x = tf.nn.conv2d(x, weights['wc5'], strides=[1,m,m,1],padding='SAME')\n    x = tf.nn.bias_add(x,biases['bc5'])\n    x = tf.nn.relu(x) \n    \n    # \u5168\u8fde\u63a5\u5c42\n    x = tf.reshape(x,[-1,weights['wd1'].get_shape().as_list()[0]])\n    x = tf.add(tf.matmul(x,weights['wd1']),biases['bd1'])\n    x = tf.nn.relu(x)\n    \n    # Apply Dropout\n    x = tf.nn.dropout(x,dropout)\n    # Output, class prediction\n    x = tf.add(tf.matmul(x,weights['out']),biases['out'])\n    return x\n\n# Store layers weight & bias\nweights = {\n    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 16])),\n    'wc2': tf.Variable(tf.random_normal([5, 5, 16, 32])),\n    'wc3': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n    'wc4': tf.Variable(tf.random_normal([5, 5, 64, 32])),\n    'wc5': tf.Variable(tf.random_normal([5, 5, 32, 16])),\n    # fully connected, 7*7*64 inputs, 1024 outputs\n    'wd1': tf.Variable(tf.random_normal([40*17*16, 1024])),\n    'out': tf.Variable(tf.random_normal([1024, n_classes]))\n}\n\nbiases = {\n    'bc1': tf.Variable(tf.random_normal([16])),\n    'bc2': tf.Variable(tf.random_normal([32])),\n    'bc3': tf.Variable(tf.random_normal([64])),\n    'bc4': tf.Variable(tf.random_normal([32])),\n    'bc5': tf.Variable(tf.random_normal([16])),\n    'bd1': tf.Variable(tf.random_normal([1024])),\n    'out': tf.Variable(tf.random_normal([n_classes]))\n}", "language": "python", "metadata": {}, "outputs": [], "trusted": true}, {"cell_type": "code", "collapsed": false, "id": "4856491F26514B6B8757FA19C6564617", "input": "%%time\n# \u6a21\u578b\u4f18\u5316\npred = CNN_Net_five(x,weights,biases,dropout=keep_prob)\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred,y))\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\ncorrect_pred = tf.equal(tf.argmax(pred,1),tf.arg_max(y,1))\n# tf.argmax(input,axis=None) \u7531\u4e8e\u6807\u7b7e\u7684\u6570\u636e\u683c\u5f0f\u662f -1 0 1 3\u5217\uff0c\u8be5\u8bed\u53e5\u662f\u8868\u793a\u8fd4\u56de\u503c\u6700\u5927\u4e5f\u5c31\u662f1\u7684\u7d22\u5f15\uff0c\u4e24\u4e2a\u7d22\u5f15\u76f8\u540c\u5219\u662f\u9884\u6d4b\u6b63\u786e\u3002\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n# \u66f4\u6539\u6570\u636e\u683c\u5f0f\uff0c\u964d\u4f4e\u5747\u503c\ninit = tf.global_variables_initializer()\n\nwith tf.Session() as sess:\n    sess.run(init)\n    for step in range(1):\n        for i in range(int(len(fac)/batch_size)):\n            batch_x = fac[i*batch_size:(i+1)*batch_size]\n            batch_y = ret[i*batch_size:(i+1)*batch_size]\n            sess.run(optimizer,feed_dict={x:batch_x,y:batch_y,keep_prob:dropout})\n            print(i,'----',(int(len(fac)/batch_size)))\n        loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,y: batch_y,keep_prob: 1.})\n        print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n                  \"{:.5f}\".format(acc))\n    print(\"Optimization Finished!\") \n    sess.close()", "language": "python", "metadata": {}, "outputs": [], "trusted": true}, {"cell_type": "markdown", "id": "C70E5FCAE49D49CB812A606BC4AD805E", "metadata": {}, "source": "\u6211\u4f18\u5316\u53c2\u6570\u4e4b\u540e\u51c6\u786e\u7387\u5927\u6982\u572894%+"}], "metadata": {}}]}