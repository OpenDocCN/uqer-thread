{"metadata": {"signature": "sha256:5eed8760c5e783732a4437af0883509e12b1718e1ffec9948c551e7f0cc75667"}, "nbformat": 3, "nbformat_minor": 0, "worksheets": [{"cells": [{"cell_type": "markdown", "id": "4ED66DBD665A4D318803D73485EBBD4D", "metadata": {}, "source": "# "}, {"cell_type": "markdown", "id": "8813B5906EB74F9D81F3A9FCB92A587D", "metadata": {}, "source": "\u7f51\u4e0a\u5e7f\u4e3a\u6d41\u4f20\u7684\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u901f\u67e5\uff08Python & R\uff09\n\u73b0\u5c06python\u5171\u4eab\u4e4b\uff0c\u5171\u52c9\uff01\n\u66f4\u591a\u5185\u5bb9\u53c2\u8003\uff1ahttp://blog.csdn.net/han_xiaoyang/article/details/51191386"}, {"cell_type": "code", "collapsed": false, "id": "F1D20B76180849C889C043027C7F013D", "input": "#1.\u7ebf\u6027\u56de\u5f52 (Linear Regression)\n#Import Library\n#Import other necessary libraries like pandas, numpy...\nfrom sklearn import linear_model\n#Load Train and Test datasets\n#Identify feature and response variable(s) and values must be numeric and numpy arrays\n\nx_train=input_variables_values_training_datasets\ny_train=target_variables_values_training_datasets\nx_test=input_variables_values_test_datasets\n\n# Create linear regression object\nlinear = linear_model.LinearRegression()\n\n# Train the model using the training sets and check score\nlinear.fit(x_train, y_train)\nlinear.score(x_train, y_train)\n\n#Equation coefficient and Intercept\nprint('Coefficient: \\n', linear.coef_)\nprint('Intercept: \\n', linear.intercept_)\n\n#Predict Output\npredicted= linear.predict(x_test)", "language": "python", "metadata": {}, "outputs": [], "trusted": true}, {"cell_type": "code", "collapsed": false, "id": "DC05608E1062449988F33A683CA0A686", "input": "#2.\u903b\u8f91\u56de\u5f52 (Logistic Regression)\n#Import Library\nfrom sklearn.linear_model import LogisticRegression\n#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset\n\n# Create logistic regression object\n\nmodel = LogisticRegression()\n\n# Train the model using the training sets and check score\nmodel.fit(X, y)\nmodel.score(X, y)\n\n#Equation coefficient and Intercept\nprint('Coefficient: \\n', model.coef_)\nprint('Intercept: \\n', model.intercept_)\n\n#Predict Output\npredicted= model.predict(x_test)", "language": "python", "metadata": {}, "outputs": [], "trusted": true}, {"cell_type": "code", "collapsed": false, "id": "9BFC9F0FB07C42C7880985377DDC22E3", "input": "#3.\u51b3\u7b56\u6811 (Decision Tree)\n#Import Library\n#Import other necessary libraries like pandas, numpy...\n\nfrom sklearn import tree\n#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset\n\n# Create tree object \nmodel = tree.DecisionTreeClassifier(criterion='gini') # for classification, here you can change the algorithm as gini or entropy (information gain) by default it is gini  \n\n# model = tree.DecisionTreeRegressor() for regression\n\n# Train the model using the training sets and check score\nmodel.fit(X, y)\nmodel.score(X, y)\n\n#Predict Output\npredicted= model.predict(x_test)", "language": "python", "metadata": {}, "outputs": [], "trusted": true}, {"cell_type": "code", "collapsed": false, "id": "DCF61C7AE6214B808D59E4342A66CED3", "input": "#4.\u652f\u6301\u5411\u91cf\u673a\uff08SVM\uff09\n#Import Library\nfrom sklearn import svm\n#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset\n# Create SVM classification object \n\nmodel = svm.svc() # there is various option associated with it, this is simple for classification. You can refer link, for mo# re detail.\n\n# Train the model using the training sets and check score\nmodel.fit(X, y)\nmodel.score(X, y)\n\n#Predict Output\npredicted= model.predict(x_test)", "language": "python", "metadata": {}, "outputs": [], "trusted": true}, {"cell_type": "code", "collapsed": false, "id": "1271376C3DE64DE0AC903B65E46FEFE8", "input": "#5.\u6734\u7d20\u8d1d\u53f6\u65af (Naive Bayes)\n#Import Library\nfrom sklearn.naive_bayes import GaussianNB\n#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset\n\n# Create SVM classification object model = GaussianNB() # there is other distribution for multinomial classes like Bernoulli Naive Bayes, Refer link\n\n# Train the model using the training sets and check score\nmodel.fit(X, y)\n\n#Predict Output\npredicted= model.predict(x_test)", "language": "python", "metadata": {}, "outputs": [], "trusted": true}, {"cell_type": "code", "collapsed": false, "id": "AC708DAC188146A188EE14D844945F38", "input": "#6.K\u90bb\u8fd1\u7b97\u6cd5\uff08KNN\uff09\n#Import Library\nfrom sklearn.neighbors import KNeighborsClassifier\n\n#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset\n# Create KNeighbors classifier object model \n\nKNeighborsClassifier(n_neighbors=6) # default value for n_neighbors is 5\n\n# Train the model using the training sets and check score\nmodel.fit(X, y)\n\n#Predict Output\npredicted= model.predict(x_test)", "language": "python", "metadata": {}, "outputs": [], "trusted": true}, {"cell_type": "code", "collapsed": false, "id": "503CFF06E68044EE9EB79B73FD2C5B32", "input": "#7.K-\u5747\u503c\u7b97\u6cd5\uff08K-means\uff09\n#Import Library\nfrom sklearn.cluster import KMeans\n\n#Assumed you have, X (attributes) for training data set and x_test(attributes) of test_dataset\n# Create KNeighbors classifier object model \nk_means = KMeans(n_clusters=3, random_state=0)\n\n# Train the model using the training sets and check score\nmodel.fit(X)\n\n#Predict Output\npredicted= model.predict(x_test)", "language": "python", "metadata": {}, "outputs": [], "trusted": true}, {"cell_type": "code", "collapsed": false, "id": "4D8AACB69C6644C1A5492FE764169B91", "input": "#8.\u968f\u673a\u68ee\u6797 (Random Forest)\n#random forest\n#import library\nfrom sklearn.ensemble import  RandomForestClassifier\n#assumed you have x(predictor)and y(target) for training data set and x_test(predictor)of test_dataset\n#create random forest object\nmodel=RandomForestClassifier()\n#train the model using the training sets and chek score\nmodel.fit(x,y)\n#predict output\npredict=model.presort(x_test)", "language": "python", "metadata": {}, "outputs": [], "trusted": true}, {"cell_type": "code", "collapsed": false, "id": "B07429E5F8B4433C88F433967ED90D2D", "input": "#9.\u964d\u4f4e\u7ef4\u5ea6\u7b97\u6cd5\uff08Dimensionality Reduction Algorithms\uff09\n#Import Library\nfrom sklearn import decomposition\n#Assumed you have training and test data set as train and test\n# Create PCA obeject pca= decomposition.PCA(n_components=k) #default value of k =min(n_sample, n_features)\n# For Factor analysis\n#fa= decomposition.FactorAnalysis()\n# Reduced the dimension of training dataset using PCA\n\ntrain_reduced = pca.fit_transform(train)\n\n#Reduced the dimension of test dataset\ntest_reduced = pca.transform(test)", "language": "python", "metadata": {}, "outputs": [], "trusted": true}, {"cell_type": "code", "collapsed": false, "id": "4EABE06373F045D596CD3BA24E41DCB2", "input": "#10.Gradient Boost\u548cAdaboost\u7b97\u6cd5\n#Import Library\nfrom sklearn.ensemble import GradientBoostingClassifier\n#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset\n# Create Gradient Boosting Classifier object\nmodel= GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n\n# Train the model using the training sets and check score\nmodel.fit(X, y)\n#Predict Output\npredicted= model.predict(x_test)", "language": "python", "metadata": {}, "outputs": [], "trusted": true}], "metadata": {}}]}