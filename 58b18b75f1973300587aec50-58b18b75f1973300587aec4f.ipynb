{"metadata": {"signature": "sha256:51c7d66d52406b7840993f35526d6839c48d58cdac07a52bb5ea4f693929dfed"}, "nbformat": 3, "nbformat_minor": 0, "worksheets": [{"cells": [{"cell_type": "markdown", "id": "B4DF941521FD4149884F3D3D9FBF9972", "metadata": {}, "source": "# A\u80a12012\u5e74\u81f3\u4eca\u5404\u56e0\u5b50\u7684\u6700\u5927\u6700\u5c0f\u503c\u4e0e\u53d1\u751f\u65f6\u95f4\u548c\u4e2a\u80a1"}, {"cell_type": "markdown", "id": "AC0B7ECD98C84052909097A3AA21B894", "metadata": {}, "source": "\u904d\u5386\u4e86\u5404\u4e2a\u80a1\u7968\u6bcf\u5929\u7684\u56e0\u5b50\uff0c\u8d44\u91d1\u6d41\u5165\u6d41\u51fa\u60c5\u51b5\uff0c\u5e74\u62a5\uff0c\u5f97\u5230\u4e86\u6bcf\u4e2a\u6570\u636e\u7684\u6700\u5927\u6700\u5c0f\u503c\u8bb0\u5f55\uff0c\u4ee5\u53ca\u53d1\u751f\u5728\u54ea\u5929\u54ea\u53ea\u4e2a\u80a1\u4e0a\u3002"}, {"cell_type": "code", "collapsed": false, "id": "8565F10F692C41B68C15F34611B98E6B", "input": "import numpy as np\nimport pandas as pd\nimport time,datetime\nimport math\ntrain_start_date = u'2012-01-25'\ntrain_end_date = u\"2017-01-01\"\ndef merge_interval_data(original_data,interval_data,interval_type):\n    tradeDates = original_data['tradeDate']\n    actPubtimes = interval_data[interval_type]\n    dataFrame =  pd.DataFrame()\n    for tradeDate in tradeDates:\n        tDate = datetime.datetime.strptime(tradeDate, \"%Y-%m-%d\").date()\n        recentDate=np.NaN\n        recentInterval=0\n        for actPubtime in actPubtimes:\n            pubDate = datetime.datetime.strptime(actPubtime, \"%Y-%m-%d %H:%M:%S\").date()\n            interval = (tDate - pubDate).total_seconds();\n            if interval > 0 and (interval < recentInterval or recentInterval==0):\n                recentInterval = interval\n                recentDate = actPubtime\n        recentData = interval_data[interval_data['actPubtime']==recentDate]\n        recentData['tradeDate'] = tradeDate\n        recentData.drop_duplicates(['tradeDate'])\n        dataFrame=pd.concat([dataFrame,recentData],ignore_index=1)\n    return pd.merge(original_data,dataFrame,on=['tradeDate'],how='outer')\n\nfactor_frame = pd.DataFrame()\nfirst = 1\ncompeleteList = []\n#\u83b7\u53d6\u80a1\u7968\u5217\u8868\nstockBasicData = DataAPI.EquGet(equTypeCD=u\"A\",listStatusCD=u\"L\",field=u\"secID,listDate\",pandas=\"1\").set_index('secID')\nallVaildStocks = stockBasicData.index\nprint len(allVaildStocks)\nprint len(compeleteList)\nfor sec in allVaildStocks:\n    if sec in compeleteList:\n        continue\n    #\u83b7\u53d6\u6536\u76d8\u4ef7\u7b49\u6210\u4ea4\u4fe1\u606f\n    exchangeData = DataAPI.MktEqudGet(secID=sec,beginDate=train_start_date,endDate=train_end_date,isOpen=\"1\",field=u\"secID,secShortName,tradeDate,closePrice,negMarketValue,marketValue\",pandas=\"1\")\n    if len(exchangeData) == 0:\n        continue\n    #\u83b7\u53d6\u5404\u56e0\u5b50\n    infoData = DataAPI.MktStockFactorsDateRangeGet(secID=sec,beginDate=train_start_date,endDate=train_end_date,pandas=\"1\")\n    #\u5408\u5e76\n    merge_data = pd.merge(exchangeData,infoData,on=['tradeDate'])\n#   \u83b7\u53d6\u8d44\u91d1\u6d41\u5165\u6d41\u51fa\u8be6\u7ec6\u60c5\u51b5\n    flowDataDetail = DataAPI.MktEquFlowOrderGet(secID=sec,beginDate=train_start_date,endDate=train_end_date,field=u\"tradeDate,inflowS,inflowM,inflowL,inflowXl,outflowS,outflowM,outflowL,outflowXl,netInflowS,netInflowM,netInflowL,netInflowXl\",pandas=\"1\") \n    #\u5408\u5e76\n    merge_data = pd.merge(merge_data,flowDataDetail,on=['tradeDate'])\n    #\u83b7\u53d6\u603b\u8d44\u91d1\u6d41\u5165\u6d41\u51fa\n    flowDataAll =DataAPI.MktEquFlowGet(secID=sec,beginDate=train_start_date,endDate=train_end_date,field=u\"tradeDate,moneyInflow,moneyOutflow,netMoneyInflow\",pandas=\"1\")\n    #\u5408\u5e76\n    merge_data = pd.merge(merge_data,flowDataAll,on=['tradeDate'])\n    #\u6784\u5efa\u6d41\u5165\u6d41\u51fa\u6bd4\u7387\n    columns = ['inflowS','inflowM','inflowL','inflowXl','outflowS','outflowM','outflowL','outflowXl','netInflowS','netInflowM','netInflowL','netInflowXl','moneyInflow','moneyOutflow','netMoneyInflow'];\n    for column in columns:\n        merge_data[column+'Rate'] = merge_data[column]/merge_data['negMarketValue']\n    #\u5bfc\u5165\u4e1a\u7ee9\u62a5\u544a\n    performanceData=DataAPI.FdmtEfGet(secID=sec,beginDate=train_start_date,endDate=train_end_date,field=u\"currencyCD,reportType,actPubtime,revChgrLL,revChgrUPL,expRevLL,expRevUPL,NIncomeChgrLL,NIncomeChgrUPL,expnIncomeLL,expnIncomeUPL,NIncAPChgrLL,NIncAPChgrUPL,expnIncAPLL,expnIncAPUPL,expEPSLL,expEPSUPL\",pandas=\"1\")\n    # \u5bfc\u5165\u5b63\u62a5\u6570\u636e\n    merge_data = merge_interval_data(merge_data,performanceData[(performanceData['currencyCD']=='CNY')&( performanceData['reportType']=='A')],'actPubtime')\n    del merge_data['currencyCD']\n    del merge_data['reportType']\n    del merge_data['actPubtime']\n    percolumns = ['revChgrLL','revChgrUPL','expRevLL','expRevUPL','NIncomeChgrLL','NIncomeChgrUPL','expnIncomeLL','expnIncomeUPL','NIncAPChgrLL','NIncAPChgrUPL','expnIncAPLL','expnIncAPUPL'];\n    for percolumn in percolumns:\n        merge_data[percolumn+'Rate'] = merge_data[percolumn]/merge_data['marketValue']\n    #\u5bfc\u5165\u5408\u5e76\u8d44\u4ea7\u8d1f\u503a\u8868\n    propData = DataAPI.FdmtBSGet(secID=sec,beginDate=train_start_date,endDate=train_end_date,field=u'actPubtime,reportType,currencyCD,cashCEquiv,settProv,loanToOthBankFi,tradingFA,NotesReceiv,AR,prepayment,premiumReceiv,reinsurReceiv,reinsurReserReceiv,intReceiv,divReceiv,othReceiv,purResaleFa,inventories,NCAWithin1Y,othCA,TCA,disburLA,availForSaleFa,htmInvest,LTReceive,LTEquityInvest,investRealEstate,fixedAssets,CIP,constMaterials,fixedAssetsDisp,producBiolAssets,oilAndGasAssets,intanAssets,RD,goodwill,LTAmorExp,deferTaxAssets,othNCA,TNCA,TAssets,STBorr,CBBorr,depos,loanFrOthBankFi,tradingFL,NotesPayable,AP,advanceReceipts,soldForRepurFa,commisPayable,payrollPayable,taxesPayable,intPayable,divPayable,othPayable,reinsurPayable,insurReser,fundsSecTradAgen,fundsSecUndwAgen,NCLWithin1Y,othCL,TCL,LTBorr,bondPayable,LTPayable,specificPayables,estimatedLiab,deferTaxLiab,othNCL,TNCL,TLiab,paidInCapital,capitalReser,treasuryShare,specialReser,surplusReser,ordinRiskReser,retainedEarnings,forexDiffer,TEquityAttrP,minorityInt,TShEquity,TLiabEquity')\n    merge_data = merge_interval_data(merge_data,propData[(propData['currencyCD']=='CNY')&( propData['reportType']=='A')],'actPubtime')\n    del merge_data['currencyCD']\n    del merge_data['reportType']\n    del merge_data['actPubtime']\n    propClumns = [u'cashCEquiv', u'settProv',\n           u'loanToOthBankFi', u'tradingFA', u'NotesReceiv', u'AR_y', u'prepayment',\n           u'premiumReceiv', u'reinsurReceiv', u'reinsurReserReceiv', u'intReceiv',\n           u'divReceiv', u'othReceiv', u'purResaleFa', u'inventories',\n           u'NCAWithin1Y', u'othCA', u'TCA', u'disburLA', u'availForSaleFa',\n           u'htmInvest', u'LTReceive', u'LTEquityInvest', u'investRealEstate',\n           u'fixedAssets', u'CIP', u'constMaterials', u'fixedAssetsDisp',\n           u'producBiolAssets', u'oilAndGasAssets', u'intanAssets', u'RD',\n           u'goodwill', u'LTAmorExp', u'deferTaxAssets', u'othNCA', u'TNCA',\n           u'TAssets', u'STBorr', u'CBBorr', u'depos', u'loanFrOthBankFi',\n           u'tradingFL', u'NotesPayable', u'AP', u'advanceReceipts',\n           u'soldForRepurFa', u'commisPayable', u'payrollPayable', u'taxesPayable',\n           u'intPayable', u'divPayable', u'othPayable', u'reinsurPayable',\n           u'insurReser', u'fundsSecTradAgen', u'fundsSecUndwAgen', u'NCLWithin1Y',\n           u'othCL', u'TCL', u'LTBorr', u'bondPayable', u'LTPayable',\n           u'specificPayables', u'estimatedLiab', u'deferTaxLiab', u'othNCL',\n           u'TNCL', u'TLiab', u'paidInCapital', u'capitalReser', u'treasuryShare',\n           u'specialReser', u'surplusReser', u'ordinRiskReser',\n           u'retainedEarnings', u'forexDiffer', u'TEquityAttrP', u'minorityInt',\n           u'TShEquity', u'TLiabEquity']\n    for propClumn in propClumns:\n        merge_data[propClumn+'Rate'] = merge_data[propClumn]/merge_data['marketValue']\n    #\u8ba1\u7b97\n    description = merge_data.describe()\n    if first:\n        try:\n            factor_frame = pd.read_csv('factor/limitation'+train_start_date+'-'+train_end_date+'.csv',index_col=0)\n        except:\n            factor_frame = pd.DataFrame(np.nan,index=['secID_min','tradeDate_min','min','secID_max','tradeDate_max','max'],columns=description.columns)\n    for factor in description.columns:\n        if (description[factor]['min'] < factor_frame[factor]['min'] or first) :\n            factor_frame[factor]['min']=description[factor]['min']\n            factor_frame[factor]['secID_min'] = sec\n            min_index = merge_data[factor].idxmin('columns')\n            if not math.isnan(min_index):\n                factor_frame[factor]['tradeDate_min'] = merge_data['tradeDate'][min_index]\n        if (description[factor]['max']> factor_frame[factor]['max'] or first):\n            factor_frame[factor]['max']=description[factor]['max']\n            factor_frame[factor]['secID_max'] = sec\n            max_index = merge_data[factor].idxmax('columns')\n            if not math.isnan(max_index) :\n                factor_frame[factor]['tradeDate_max'] = merge_data['tradeDate'][max_index]\n    factor_frame.to_csv('factor/limitation'+train_start_date+'-'+train_end_date+'.csv') \n    compeleteList.append(sec)\n    first = 0\n    print compeleteList\n    print float(len(compeleteList))/float(len(allVaildStocks))", "language": "python", "metadata": {}, "outputs": [], "trusted": true}, {"cell_type": "code", "collapsed": false, "id": "1B918ACCB363425E9BBD8C9C92BDE5B0", "input": "pd.read_csv('factor/limitation'+train_start_date+'-'+train_end_date+'.csv',index_col=0)", "language": "python", "metadata": {}, "outputs": [], "trusted": true}], "metadata": {}}]}