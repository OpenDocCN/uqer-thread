{"metadata": {"signature": "sha256:cc59dc3941ca545f258f8e42b363559e9e653e009ab6c2188e6218e76efee9d7"}, "nbformat": 3, "nbformat_minor": 0, "worksheets": [{"cells": [{"cell_type": "markdown", "id": "18275F15991649DD9DB5B6EBA87B5E31", "metadata": {}, "source": "# 4 \u51fd\u6570 PB\u56e0\u5b50\u8ba1\u7b97\u8fc7\u7a0b(\u7b14\u8bb0P149)"}, {"cell_type": "code", "collapsed": false, "id": "0C4BB9CA54CD4272809DDD16E1A3C2BD", "input": "def str2date(date_str):\n    date_obj = dt.datetime(int(date_str[0:4]), int(date_str[4:6]), int(date_str[6:8]))\n    return Date.fromDateTime(date_obj)\n\ndef signal_pb_calc(universe, current_date):\n    today = str2date(current_date)\n    start_date = (today - Period('1Y')).toDateTime().strftime('%Y%m%d')\n    end_date = today.toDateTime().strftime('%Y%m%d')\n    \n    # dealing with the numerator\n    # \u6caa\u6df1\u80a1\u7968\u65e5\u884c\u60c5 : DataAPI.MktEqudGet(secID=u\"\",ticker=u\"\",tradeDate=u\"20150513\",beginDate=u\"\",endDate=u\"\",isOpen=\"\",field=u\"\",pandas=\"1\")\n    market_capital = DataAPI.MktEqudGet(secID=universe, field=['secID', 'tradeDate', 'marketValue', 'negMarketValue', 'turnoverVol'], beginDate=start_date, endDate=end_date, pandas='1')\n    market_capital = market_capital[market_capital['turnoverVol'] > 0] # turnoverVol : \t\u6210\u4ea4\u91cf ; marketValue : \u603b\u5e02\u503c\n    market_capital = market_capital.sort(columns=['secID', 'tradeDate'], ascending=[True, True])\n    market_capital = market_capital.drop_duplicates(subset='secID', take_last=True)\n    market_capital['marketValue'][isnull(market_capital['marketValue'])] = market_capital['negMarketValue'][isnull(market_capital['marketValue'])]\n    market_capital = market_capital.drop('negMarketValue', axis=1) # axis \u9ed8\u8ba4\u4e3a0\uff0c\u6307\u5220\u9664\u884c\uff0c\u56e0\u6b64\u5220\u9664columns\u65f6\u8981\u6307\u5b9aaxis=1\uff1b\n    \n    numerator = market_capital.dropna() # \u5220\u9664\u542b\u6709\u7a7a\u6570\u636e\u7684\u5168\u90e8\u884c\n    numerator.rename(columns={'marketValue': 'numerator'}, inplace=True)\n    \n    # dealing with the denominator\n    equity = DataFrame()\n    for rpt_type in ['Q1', 'S1', 'Q3', 'A']:\n        try:\n            # FdmtBSGet : \u5408\u5e76\u8d44\u4ea7\u8d1f\u503a\u8868 (Point in time)\n            # TEquityAttrP\tfloat\t\u5f52\u5c5e\u4e8e\u6bcd\u516c\u53f8\u6240\u6709\u8005\u6743\u76ca\u5408\u8ba1\n            tmp = DataAPI.FdmtBSGet(secID=universe, field=['secID', 'endDate', 'publishDate', 'TEquityAttrP'], beginDate=start_date, publishDateEnd=end_date, reportType=rpt_type)\n        except:\n            tmp = DataFrame()\n        equity = pd.concat([equity, tmp], axis=0)\n        \n    equity = equity.sort(columns=['secID', 'endDate', 'publishDate'], ascending=[True, False, False])\n    equity = equity.dropna()\n    equity = equity.drop_duplicates(subset='secID',take_last=True)\n    \n    denominator = equity\n    denominator.rename(columns={\"TEquityAttrP\": \"denominator\"},inplace=True)\n    \n    # merge two dataframe and calculate price-to- book ratio\n    dat_info = numerator.merge(denominator, on='secID', how='inner')\n    dat_info = dat_info[abs(dat_info['denominator']) >= 1e-8]\n    dat_info['PB'] = dat_info['numerator'] / dat_info['denominator']\n    \n    pb_signal = dat_info[['secID', 'PB']]\n    pb_signal[\"secID\"] = pb_signal[\"secID\"].apply(lambda x:x[:6])\n    return pb_signal\n\n# ------------------------------------------------------------------------------------------------------------------------------------\n\nimport numpy as np\nimport pandas as pd\nimport datetime as dt\nfrom pandas import Series, DataFrame, isnull\nfrom datetime import timedelta, datetime\nfrom CAL.PyCAL import * # CAL provides classes and functions dealing with date, time, and calendars. \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nstart = datetime(2015, 1, 1)\nend = datetime(2015,1, 11)\n\nuniv = set_universe('HS300')\ncal = Calendar('China.SSE')\n\nall_files = []\ntoday = start\nwhile((today - end).days < 0):\n    today_CAL = Date.fromDateTime(today)\n    if(cal.isBizDay(today_CAL)):\n        today_str = today.strftime(\"%Y%m%d\")\n        print(\"Calculating PB values on \" + today_str)\n        \n        pb_value = signal_pb_calc(univ, today_str)\n        \n        file_name = today_str + '.csv'\n        pb_value.to_csv(file_name, index=False, header=False)\n        all_files.append(file_name)\n    today = today + timedelta(days=1)\n    \n# exporting all *.csv files to PB.zip\nnum=zip_files(\"PB\"+ \"_\" + start.strftime(\"%Y%m%d\") + \"_\" + end.strftime(\"%Y%m%d\"), all_files) # zip_files(zip_filename, file_list) : Python builtin\nprint(num)\n\n# delete all *.csv\nnum=delete_files(all_files) # delete_files(file_list) : Python builtin\nprint(num)\n\nprint(\"fin.\")", "language": "python", "metadata": {}, "outputs": [{"output_type": "stream", "stream": "stdout", "text": "Calculating PB values on 20150105"}, {"output_type": "stream", "stream": "stdout", "text": "\nCalculating PB values on 20150106"}, {"output_type": "stream", "stream": "stdout", "text": "\nCalculating PB values on 20150107"}, {"output_type": "stream", "stream": "stdout", "text": "\nCalculating PB values on 20150108"}, {"output_type": "stream", "stream": "stdout", "text": "\nCalculating PB values on 20150109"}, {"output_type": "stream", "stream": "stdout", "text": "\n5"}, {"output_type": "stream", "stream": "stdout", "text": "\n5\nfin.\n"}], "trusted": true}, {"cell_type": "code", "collapsed": false, "id": "FB264BC66E0049C4876A40241F7BFC98", "input": "zip_files?", "language": "python", "metadata": {}, "outputs": [], "trusted": true}], "metadata": {}}]}