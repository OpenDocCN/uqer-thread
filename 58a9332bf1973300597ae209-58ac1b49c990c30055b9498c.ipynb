{"metadata": {"signature": "sha256:72670781d089dbe195cdcd16ec70e9105e92319d5bdde7334cb7e47403f585ff"}, "nbformat": 3, "nbformat_minor": 0, "original_thread": "58a9332bf1973300597ae209", "worksheets": [{"cells": [{"cell_type": "markdown", "id": "336C851359034540907A8B83CE952C92", "metadata": {}, "source": "# tensorflow\u7b14\u8bb08 \u4f7f\u7528scan\u6784\u5efaGRUcell0"}, {"cell_type": "markdown", "id": "73638B4402AE4AB2B57556686FD0CF30", "metadata": {}, "source": "\u770bRNN\u7684paper\u5927\u591a\u6570\u96c6\u4e2d\u5728RNNcell\u5185\u90e8\u6784\u5efa\uff0c\u5c11\u6570\u6d89\u53caunits\u4e4b\u95f4\u4ea4\u4e92\uff0c   \ntensorflow\u63d0\u4f9b\u4e86\u51e0\u79cd\u6700\u6d41\u884c\u7684RNN\u53d8\u79cd\u7c7b\uff0c\u4f46\u6ca1\u6709CNN\u7f16\u5199\u65b9\u4fbf\uff0c\u8fd9\u91cc\u5206\u4eab   \n\u4e00\u6bb5\u4f7f\u7528tf.scan\u6784\u5efaGRUcell\u4ee3\u7801\uff0c\u53ef\u4ee5\u4f5c\u4e3a\u81ea\u5b9a\u4e49RNNcell\u7684\u53c2\u8003\u3002"}, {"cell_type": "code", "collapsed": false, "id": "406C789E624E402D9FE326824ACEB88E", "input": "import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport pylab as pl\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n%matplotlib inline", "language": "python", "metadata": {}, "outputs": [], "trusted": true}, {"cell_type": "code", "collapsed": false, "id": "455DA307D7E841C7B7157CC149AAE251", "input": "class GRUcell(object):\n    \n    def __init__(self):\n        self.in_length= 28\n        self.in_width= 28\n        self.hidden_layer_size = 2000\n        self.out_classes = 10\n        \n        self.Wr = tf.Variable(tf.zeros([self.in_width, self.hidden_layer_size]))\n        self.Wz = tf.Variable(tf.zeros([self.in_width, self.hidden_layer_size]))\n        self.W_ = tf.Variable(tf.zeros([self.in_width, self.hidden_layer_size]))   \n        self.Ur = tf.Variable(tf.truncated_normal([self.hidden_layer_size, self.hidden_layer_size]))\n        self.Uz = tf.Variable(tf.truncated_normal([self.hidden_layer_size, self.hidden_layer_size]))\n        self.U_ = tf.Variable(tf.truncated_normal([self.hidden_layer_size, self.hidden_layer_size]))\n        \n        self.Wout = tf.Variable(tf.truncated_normal([self.hidden_layer_size, self.out_classes], mean=0., stddev=.1))\n        self.bout = tf.Variable(tf.truncated_normal([self.out_classes], mean=0., stddev=.1))\n        \n        self.inX = tf.placeholder(shape=[None, self.in_length, self.in_width], dtype=tf.float32)\n        self.initial_hidden = tf.matmul(self.inX[:,0,:], tf.zeros([self.in_width, self.hidden_layer_size]))\n        self.X = tf.transpose(self.inX, perm=[1,0,2])\n    \n    def GRU(self, hidden_states_previous, current_input_X):\n        \"\"\"\n        GRU topology unit\n        Note that the input order above is for the fn function\n        The two tensors are entered for the fn function, \n        the first tensor is the output calculated in the previous step, \n        and the second tensor is the input value at this time\n        \"\"\"\n        hp = hidden_states_previous\n        x = current_input_X\n        \n        r = tf.sigmoid(tf.matmul(x, self.Wr) + tf.matmul(hp, self.Ur))\n        z = tf.sigmoid(tf.matmul(x, self.Wz) + tf.matmul(hp, self.Uz)) \n        h_ = tf.tanh(tf.matmul(x, self.W_) + tf.matmul(r*hp ,self.U_))\n        h = tf.multiply(hp,z) + tf.multiply((1-z),h_)\n        return h      \n    \n    def PRO_TS(self):\n        \"\"\"\n        Perform recursive operations in time series\n        Iterates through time/ sequence to get all hidden state\n        Input format : [in_length, batch_size, in_width]\n        Output format : [in_length, batch_size, hidden_layer_size]\n        \"\"\"\n        return tf.scan(fn= self.GRU, elems=self.X, initializer=self.initial_hidden)\n    \n    def Full_Connection_Layer(self, batch_hidden_layer_states):\n        \"\"\"\n        The hidden layer state input is converted to \n        output through the full connection layer\n        Input format : [batch_size, hidden_layer_size]\n        Output format : [batch_size, out_classes]\n        \"\"\"\n        return (tf.nn.bias_add(tf.matmul(batch_hidden_layer_states, self.Wout), self.bout))\n        \n    \n    def deal_hidden_layer(self):\n        \"\"\"\n        Handle all state output of hidden layer\n        Input format : [in_length, batch_size, hidden_layer_size]\n        Output format : [in_length, batch_size, out_classes]\n        \"\"\"\n        #all_hidden_states = self.PRO_TS()\n        #return tf.map_fn(self.Full_Connection_Layer, all_hidden_states)\n        return tf.map_fn(self.Full_Connection_Layer, self.PRO_TS())  \n    \n    def last_output(self):\n        tp = tf.reverse(self.deal_hidden_layer(), axis=[0])[0,:,:]\n        return tf.nn.softmax(tp)        ", "language": "python", "metadata": {}, "outputs": [], "trusted": true}, {"cell_type": "code", "collapsed": false, "id": "D66AD58E7A9949038E87BFA41DF38520", "input": "y = tf.placeholder(tf.float32, shape=[None, 10],name='inputs')\nrnn = GRUcell()\noutput = rnn.last_output()\ncross_entropy = -tf.reduce_sum(y * tf.log(output))\ntrain_step = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cross_entropy)\ncorrect_prediction = tf.equal(tf.argmax(y,1), tf.argmax(output,1))\naccuracy = (tf.reduce_mean(tf.cast(correct_prediction, tf.float32)))\nsess=tf.InteractiveSession()\nsess.run(tf.global_variables_initializer())", "language": "python", "metadata": {}, "outputs": [], "trusted": true}, {"cell_type": "code", "collapsed": false, "id": "C42E8570793544D1B9D59605EC6E2113", "input": "batch_size = 32\nss = []\nfor i in range(5000):\n    batch_x, batch_y = mnist.train.next_batch(batch_size)\n    batch_x = batch_x.reshape((batch_size, 28, 28))\n    sess.run(train_step, feed_dict={rnn.inX:batch_x, y:batch_y})\n    t = sess.run(accuracy, feed_dict={rnn.inX:batch_x, y:batch_y})\n    ss.append(t)\n\nttt = pd.Series(ss)\nttt.plot()", "language": "python", "metadata": {}, "outputs": [], "trusted": true}], "metadata": {}}]}