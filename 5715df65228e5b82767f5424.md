# 【Machine Learning: Recipes for New Developers】Episode 1

这是根据谷歌开发者的机器学习视频整理的代码，加入了详细的注释和一些补充的内容，大家可以直接克隆代码进行学习。
视频传送门：[Machine Learning: Recipes for New Developers](https://developers.googleblog.com/2016/03/introducing-new-developer-show-machine.html)




这一集讲述了在sklearn中构建决策树。
决策树算法的主要思想是给定一些特征，根据这些特征进行分类。例如按照重量和表面粗糙程度来分类苹果和橘子。
我们可以通过加入更多特征，使分类结果更精确。




```python
from sklearn import tree#导入决策树
features=[[140,1],[130,1],[150,0],[170,0]]#构建训练特征，这个例子中第一个数代表重量，第二个数代表光滑还是毛糙
labels=[-1,-1,1,1]#上面四组对象对应的分类，这里为苹果或橘子
clf=tree.DecisionTreeClassifier()#定义决策树分类函数
clf=clf.fit(features,labels)#对所给出的特征和结果进行分类
print clf.predict([[165,0]])#预测所给定特征的分类结果
```


#################################################################
上面，我们给出了用sklearn实现决策树的方法，怎么样，很简单吧？
决策树算法究竟帮我们做了什么呢？想一探究竟的童鞋可以接着往下看。
我们不使用sklearn机器学习包来实现决策树算法。

```python
import numpy as np
from numpy import *
def decisionTree(dataSet,labellist,D):
    dataMat=mat(dataSet);labelMat=mat(labellist).T
    m,n=shape(dataMat)#数据集行列数
    numSteps=10.0#迭代步数
    bestFeat={}#最优项列
    bestClass=mat(zeros((m,1)))#最优预测分类
    minError=inf#初始化最小误差为无穷大
    for i in range(n):#按列迭代
        rangeMin=dataMat[:,i].min()#最小值
        rangeMax=dataMat[:,i].max()#最大值
        stepSize=(rangeMax-rangeMin)/numSteps#步长=（最大值-最小值）/步长数
        for j in range(-1,int(numSteps)+1):#对每个步长数迭代
            #计算阈值：（最小值+迭代步数x步长数）
            threshVal=(rangeMin+float(j)*stepSize)
            #operator操作符，有两个取值：lt表示小于，gt表示大于
            for operator in ['lt','gt']:
                #调用splitDataSet方法得出预测结果列
                predictedVals=splitDataSet(dataMat,i,threshVal,operator)
                errSet=mat(ones((m,1)))#初始化误差集为一个全1的向量
                #误差集：列向量的预测值==类别标签 则赋值为0
                errSet[predictedVals==labelMat]=0
                weightedError=D.T*errSet#权重误差=Dx误差数组；权重误差是一个标量
                if weightedError&lt;minError:
                    minError=weightedError#更新最小误差为权重误差
                    bestClass=predictedVals.copy()#最优预测类
                    bestFeat['dim']=i#最优列
                    bestFeat['thresh']=threshVal#最优阈值
                    bestFeat['oper']=operator#最优分隔符号（大于或小于号）
    return bestFeat,minError,bestClass

#决策树划分数据集函数
def splitDataSet(dataMat,column,threshVal,operator):
    retArray=ones((shape(dataMat)[0],1))#与数据集行数相同的全1向量
    if operator=='lt':
        retArray[dataMat[:,column]&lt;=threshVal]=-1.0
    else:
        retArray[dataMat[:,column]&gt;threshVal]=-1.0
    return retArray#返回预测结果
#决策树分分类函数
def TreeClassify(datToClass,bestFeat):
    dataMatrix=mat(datToClass)
    m=shape(dataMatrix)[0]
    ClassEst=splitDataSet(dataMatrix,bestFeat['dim'],bestFeat['thresh'],bestFeat['oper'])
    return ClassEst


features=[[140,1],[130,1],[150,0],[170,0]]#构建训练特征，这个例子中第一个数代表重量，第二个数代表光滑还是毛糙
labels=[-1,-1,1,1]#上面四组对象对应的分类，这里为苹果或橘子
bestFeat,minError,bestClass=decisionTree(features,labels)#训练决策树
print bestFeat,minError,bestClass
datToClass=[[125,1],[165,0]]#进行预测
print TreeClassify(datToClass,bestFeat)
```
