{"metadata": {"signature": "sha256:e01efc8e93047085fc72ee13a46df4033d7cd919a4305b05325474c6afe254fc"}, "nbformat": 3, "nbformat_minor": 0, "worksheets": [{"cells": [{"cell_type": "markdown", "id": "440C4DD8CDB34DD993EA1FFD279704B5", "metadata": {}, "source": "# Xgboost1"}, {"cell_type": "strategy", "collapsed": false, "has_detail": true, "id": "C30065F7A50C4B22872031374275B53C", "input": "import numpy as np\nimport pandas as pd\nimport csv\nimport math\nimport scipy\nfrom scipy.stats import spearmanr\n#import graphviz\nfrom scipy.stats import rankdata\nimport pickle\n#from gplearn import genetic\n#from gplearn.functions import make_function\n#from gplearn.genetic import SymbolicTransformer, SymbolicRegressor\n#from gplearn.fitness import make_fitness\nfrom sklearn.utils import check_random_state\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom pandas import Series\nimport statsmodels.api as sm\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy.stats import pearsonr\nimport threading\n\nimport xgboost as xgb\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\nfield=['openPrice','highestPrice','lowestPrice','closePrice','turnoverVol','preClosePrice','PE','PB','PS','ROA','LCAP','NetProfitGrowRate']\nfactors=['factor1','factor2','factor3','factor4','factor5','factor6','factor7','factor8']\n#\u6781\u7aef\u503c\u5904\u7406(MAD)\ndef filter_extereme_MAD(series,n):\n    median=series.quantile(0.5)\n    diff_median=((series-median).abs()).quantile(0.5)\n    max_range=median+n*diff_median\n    min_range=median-n*diff_median\n    return np.clip(series,min_range,max_range)\n\ndef factor_MAD(data,n):\n    for i in range(len(field)):\n        initial_factor=data[:,i]\n        initial_factor=Series(initial_factor)\n        data[:,i] = filter_extereme_MAD(initial_factor,n)\n    return data\n\n#\u6807\u51c6\u5316\u5904\u7406\uff08Z-score\uff09\ndef standard_z_score(series):\n    std = series.std() \n    mean = series.mean() \n    return (series-mean)/std\n\ndef factor_standard(data):\n    for i in range(len(field)):\n        initial_factor=data[:,i]\n        data[:,i] = standard_z_score(initial_factor)\n    return data\n\n#\u5e02\u503c\u4e2d\u6027\u5316(Market cap neutrality)\ndef factor_MC_neutrality(data):\n    for i in range(len(field)):\n        x=data.iloc[:,i].values.reshape(-1,1)\n        data_log_marketcap=np.array(data.iloc[:,10].values,dtype=np.float64)\n        y=data_log_marketcap.flatten()\n        # \u5efa\u7acb\u56de\u5f52\u65b9\u7a0b\n        lr = LinearRegression()\n        lr.fit(x, y)  # \u62df\u5408\n        y_predict = lr.predict(x)  # \u9884\u6d4b\n        data.iloc[:,i] = y - y_predict   #\u6b8b\u5dee\u5373\u4e3a\u5e02\u503c\u4e2d\u6027\u5316\u540e\u7684\u65b0\u56e0\u5b50\u503c\n    return data\n    \n#\u5b9a\u4e49scale\u51fd\u6570\uff0c\u8fd4\u56de\u503c\u4e3a\u5411\u91cfa*X/sum(abs(X))\uff0ca\u7684\u7f3a\u7701\u503c\u4e3a1\uff0ca\u4e00\u822c\u4e3a\u6b63\u6570\ndef _scale(data):\n    data = pd.Series(data)\n    value = data.mul(1).div(np.abs(data).sum())\n    value = np.nan_to_num(value)    \n    return value\n#scale = make_function(function=_scale, name='scale', arity=1)\n\n# \u5c06\u56e0\u5b50\u683c\u5f0f\u7684dataframe\uff0c\u8f6c\u6362\u6210feature\u548clabel\u4e24\u4e2aarray\uff0c\u4fbf\u4e8e\u8f93\u5165\u6a21\u578b\ndef format_feature_label(data_df, y_marker, factor_names):\n    '''\n    \u53c2\u6570:\n        df: \u539f\u59cb\u8f93\u5165\u6570\u636e\uff0cDataFrame, columns\u5305\u62ec\uff1atrade_date(\u53ef\u80fd\u6ca1\u6709), \u5404\u4e2a\u56e0\u5b50\u7684\u771f\u5b9eIC\uff0c\u7279\u5f81\n        y_marker: \u771f\u5b9e\u503c\u5217\u7684\u7ed3\u5c3e\u6807\u8bc6  [\u5404\u4e2a\u56e0\u5b50\u7684\u771f\u5b9eIC\u5217: ROE_IC, GROW_IC, EP_IC\u7b49]\n        factor_names: list, \u4f5c\u4e3alabel\u7684\u56e0\u5b50\u5217\u8868\uff0clabel_lists\u7684\u987a\u5e8f\u548cfactor_names\u4e25\u683c\u4e00\u81f4\n        \u9664\u4e86trade_date, \u5e26y_marker\u7684\u5217\u90fd\u4f1a\u88ab\u8ba4\u4e3a\u662f\u7279\u5f81\n        #\u5e26y_marker\u7684\u76f8\u5f53\u4e8e\u4e2a\u80a1\u539f\u59cb\u7279\u5f81\uff0c\u76f8\u5f53\u4e8e\u6837\u672c\u6807\u7b7e\n    \u8fd4\u56de:\n        feature: np.array, \u5bf9\u5e94\u7740\u66f4\u6539\u683c\u5f0f\u540e\u7684\u6570\u636e\u7279\u5f81, N*K\u4e2a\u7279\u5f81\n        label_lists: \u5355\u4e2a\u5143\u7d20\u4e3a np.array, \u5bf9\u5e94\u7740\u66f4\u6539\u683c\u5f0f\u540e\u7684\u6570\u636e\u6807\u7b7e, N*1\n    '''\n    df = data_df.copy()\n    if 'trade_date' in df.columns:\n        del df['trade_date']\n    end_tag_length = len(y_marker)\n    # \u63d0\u53d6\u51fa\u7279\u5f81\u5217\n    valid_feature_col = [x for x in df.columns if x[-end_tag_length:] != y_marker]\n    # \u7279\u5f81\u6570\u7ec4\n    feature = np.array(df[valid_feature_col])\n    # \u6807\u7b7e\u6570\u7ec4\uff08\u9884\u6d4b\u7684\u771f\u5b9e\u503c\u7ec4\uff09\n    label_lists = []\n    for factor_name in factor_names:\n        label = np.array(df[factor_name + y_marker])\n        label_lists.append(label)\n    return feature, label_lists\n\n\n\n    # \u8dd1static\u7684\u6a21\u578b\n    if debug_flag:\n        static_result = run_xgboost_predict(model_data, train_start='2012-01-01', train_end='2022-01-01',\n                                       test_start='2012-01-01', test_end='2022-01-01')\n    else:\n        static_result = run_xgboost_predict(model_data,  run_type='static')\n    static_result = static_result.merge(model_data[['trade_date']+feature], on=['trade_date'], how='left')\n    static_time2 = time.time()\n    #print(\"static\", static_time2 - static_time1)\n    #print(static_result.head())\n    #static_result.to_pickle(os.path.join(raw_data_dir, \"static_result.pickle\"))", "language": "python", "metadata": {}, "outputs": [{"metadata": {}, "output_type": "pyout", "prompt_number": 5, "text": "'{\"information\": 0.26704, \"benchmark_cumulative_return\": {\"1387238400000\": -0.0660219188, \"1385337600000\": -0.0532392636, \"1368748800000\": 0.0273885729, \"1385510400000\": -0.0429933213, \"1388361600000\": -0.0885828098, \"1359936000000\": 0.0892130244, \"1385683200000\": -0.0332983214, \"1361491200000\": 0.0291920173, \"1375660800000\": -0.0969579262, \"1362096000000\": 0.057825165, \"1377475200000\": -0.0742503815, \"1377043200000\": -0.0849640302, \"1361145600000\": 0.085027448, \"1384214400000\": -0.0725143186, \"1370304000000\": 0.0169325591, \"1371081600000\": -0.0487564161, \"1370476800000\": 0.0019421709, \"1378080000000\": -0.0803067837, \"1380153600000\": -0.0549000178, \"1373500800000\": -0.0777898888, \"1366848000000\": -0.0218276224, \"1379980800000\": -0.0313363325, \"1357516800000\": 0.0051685527, \"1378166400000\": -0.0667670782, \"1387152000000\": -0.0614479082, \"1369267200000\": 0.023742048, \"1374192000000\": -0.1317782754, \"1364256000000\": 0.0206504291, \"1376438400000\": -0.068915357, \"1366070400000\": -0.0251134585, \"1366934400000\": -0.0299807765, \"1384300800000\": -0.0930775481, \"1386806400000\": -0.0447650568, \"1371427200000\": -0.0472106066, \"1377648000000\": -0.0772468737, \"1383868800000\": -0.0852177015, \"1376870400000\": -0.0759111358, \"1363132800000\": 0.0017994808, \"1382659200000\": -0.0611942369, \"1366675200000\": -0.0291246358, \"1385078400000\": -0.0495412117, \"1359417600000\": 0.0606115856, \"1365984000000\": -0.0341386076, \"1362355200000\": 0.0090251491, \"1380499200000\": -0.0451495273, \"1375228800000\": -0.1307715175, \"1374710400000\": -0.1130700172, \"1380240000000\": -0.0507263323, \"1363910400000\": 0.0377970233, \"1358812800000\": 0.0293109257, \"1378339200000\": -0.0718246497, \"1384819200000\": -0.0439128798, \"1361232000000\": 0.0644721457, \"1386201600000\": -0.0217007868, \"1381276800000\": -0.0274955905, \"1361404800000\": 0.0347212588, \"1365379200000\": -0.020075705, \"1378944000000\": -0.0061396381, \"1365465600000\": -0.0132860342, \"1378771200000\": -0.019049129, \"1369008000000\": 0.0343486791, \"1375920000000\": -0.0975722864, \"1357603200000\": 0.0009433401, \"1375315200000\": -0.1100259617, \"1367539200000\": -0.0119066965, \"1374624000000\": -0.108523752, \"1386633600000\": -0.0275986444, \"1363824000000\": 0.0364811035, \"1368576000000\": -0.0063497097, \"1358380800000\": 0.0118155334, \"1366588800000\": 0.00305991, \"1381449600000\": -0.0215779147, \"1382054400000\": -0.0384074199, \"1361750400000\": 0.0325055986, \"1377734400000\": -0.0811113974, \"1372118400000\": -0.1417110922, \"1386720000000\": -0.0436750629, \"1385942400000\": -0.0412850037, \"1358899200000\": 0.0334965021, \"1382486400000\": -0.0414039121, \"1372204800000\": -0.1405695713, \"1363046400000\": 0.012949127, \"1364860800000\": -0.0144909729, \"1374451200000\": -0.1271368834, \"1381881600000\": -0.0402623912, \"1358294400000\": 0.0214590063, \"1378425600000\": -0.0654670128, \"1368057600000\": 0.0019183892, \"1364515200000\": -0.0110465923, \"1368662400000\": 0.0117957153, \"1381968000000\": -0.0434491369, \"1381708800000\": -0.0199805783, \"1375401600000\": -0.109272875, \"1365724800000\": -0.0241146277, \"1364342400000\": 0.0240115738, \"1387411200000\": -0.0755227016, \"1386288000000\": -0.0280068967, \"1368144000000\": 0.0070909055, \"1388448000000\": -0.0764660417, \"1386028800000\": -0.0317762936, \"1369353600000\": 0.029441725, \"1367798400000\": 0.001200975, \"1358726400000\": 0.0348599853, \"1359590400000\": 0.0649755247, \"1369872000000\": 0.0441427694, \"1370390400000\": 0.0148992251, \"1379376000000\": -0.0379040409, \"1383004800000\": -0.0598109356, \"1373932800000\": -0.0812937236, \"1358208000000\": 0.0288987098, \"1364947200000\": -0.0156166393, \"1370563200000\": -0.0153748588, \"1371686400000\": -0.0798588953, \"1376352000000\": -0.0649557066, \"1387497600000\": -0.0970332349, \"1384732800000\": -0.0372777899, \"1362528000000\": 0.0504369884, \"1379462400000\": -0.0358469252, \"1383264000000\": -0.0546939099, \"1358121600000\": 0.0217126776, \"1373587200000\": -0.098131156, \"1363564800000\": -0.0081095543, \"1360195200000\": 0.0939059434, \"1377820800000\": -0.0828553875, \"1357862400000\": -0.0157434749, \"1381363200000\": -0.0371113181, \"1360108800000\": 0.100235835, \"1383696000000\": -0.0671356943, \"1357689600000\": 0.0012604293, \"1362441600000\": 0.0395806496, \"1387843200000\": -0.0930260211, \"1361836800000\": 0.0176975366, \"1367971200000\": 0.0078677738, \"1375142400000\": -0.1322103094, \"1386892800000\": -0.0461007947, \"1372636800000\": -0.122725381, \"1384128000000\": -0.082070592, \"1380067200000\": -0.0372262629, \"1366329600000\": 0.0043124121, \"1370217600000\": 0.0315781129, \"1373846400000\": -0.0854753364, \"1386115200000\": -0.0189500386, \"1369612800000\": 0.0303771379, \"1371513600000\": -0.0413008581, \"1366761600000\": -0.0108484116, \"1362614400000\": 0.0382607662, \"1385596800000\": -0.0330644682, \"1375056000000\": -0.1375294794, \"1362700800000\": 0.0332864306, \"1359504000000\": 0.065700866, \"1386547200000\": -0.0285697299, \"1381795200000\": -0.0219703125, \"1358985600000\": 0.0237024119, \"1358467200000\": 0.0287322381, \"1357776000000\": 0.0030202739, \"1368403200000\": 0.0030995462, \"1379289600000\": -0.0176618641, \"1387756800000\": -0.0944727402, \"1376265600000\": -0.0674448562, \"1371772800000\": -0.0814760499, \"1384473600000\": -0.0682613607, \"1374537600000\": -0.1019045165, \"1363305600000\": 0.0067064349, \"1381190400000\": -0.0321607642, \"1364774400000\": -0.0117957153, \"1387324800000\": -0.0656850116, \"1385424000000\": -0.0537188609, \"1372896000000\": -0.1192928913, \"1376524800000\": -0.0798152956, \"1369958400000\": 0.0330882499, \"1372377600000\": -0.1277512436, \"1368489600000\": -0.0117362611, \"1379030400000\": -0.0134961057, \"1360022400000\": 0.0985869716, \"1375833600000\": -0.0960502586, \"1363651200000\": 0.000852177, \"1384992000000\": -0.044772984, \"1377129600000\": -0.0868110743, \"1359676800000\": 0.0873461622, \"1367452800000\": -0.0290572544, \"1383782400000\": -0.0722963198, \"1367884800000\": 0.0027705662, \"1372032000000\": -0.1394161597, \"1362960000000\": 0.0275154085, \"1374105600000\": -0.1100378525, \"1382572800000\": -0.0485304901, \"1366243200000\": -0.0230285975, \"1382400000000\": -0.0305436097, \"1383177600000\": -0.0591490121, \"1360281600000\": 0.0986067897, \"1372982400000\": -0.1173626112, \"1383091200000\": -0.0457718147, \"1357257600000\": 0.0005786876, \"1369699200000\": 0.0481222379, \"1363737600000\": 0.0345706415, \"1378857600000\": -0.0158782378, \"1369180800000\": 0.0376860421, \"1388016000000\": -0.1021106245, \"1374796800000\": -0.1184882776, \"1369094400000\": 0.0364256129, \"1359072000000\": 0.0193107275, \"1366156800000\": -0.0255573832, \"1373414400000\": -0.1184644959, \"1376611200000\": -0.0867278384, \"1384387200000\": -0.0865851483, \"1364428800000\": -0.0093739472, \"1371168000000\": -0.0420856537, \"1382918400000\": -0.0622287402, \"1372723200000\": -0.1192928913, \"1364169600000\": 0.0357319804, \"1383609600000\": -0.05516558, \"1378684800000\": -0.0326363979, \"1377561600000\": -0.0721655205, \"1373328000000\": -0.142801086, \"1365638400000\": -0.0178640084, \"1382313600000\": -0.0204641392, \"1377216000000\": -0.0935492182, \"1373241600000\": -0.1424245427, \"1383523200000\": -0.0564814998, \"1375747200000\": -0.0908896332, \"1365552000000\": -0.0149190432, \"1379894400000\": -0.0200796686, \"1372291200000\": -0.1435660635, \"1363219200000\": 0.0044868111, \"1376956800000\": -0.083426148, \"1371600000000\": -0.0484313998, \"1362009600000\": 0.0596048277, \"1372809600000\": -0.1264868507, \"1361318400000\": 0.0712221804, \"1374019200000\": -0.0951703363, \"1384905600000\": -0.0388830536, \"1387929600000\": -0.0863433679, \"1369785600000\": 0.0474087873, \"1376006400000\": -0.0939138707, \"1378252800000\": -0.0682732516, \"1361923200000\": 0.0284310034, \"1388102400000\": -0.086989437, \"1359331200000\": 0.0510949484}, \"benchmark_annualized_return\": -0.08016, \"turnover_rate\": 0.0, \"max_drawdown\": 0.0, \"beta\": 0.0, \"sharpe\": null, \"alpha\": -0.035, \"volatility\": 0.0, \"recovery_days\": 0, \"annualized_return\": 0.0, \"cumulative_return\": {\"1387238400000\": 0.0, \"1385337600000\": 0.0, \"1368748800000\": 0.0, \"1385510400000\": 0.0, \"1388361600000\": 0.0, \"1359936000000\": 0.0, \"1385683200000\": 0.0, \"1361491200000\": 0.0, \"1375660800000\": 0.0, \"1362096000000\": 0.0, \"1377475200000\": 0.0, \"1377043200000\": 0.0, \"1361145600000\": 0.0, \"1384214400000\": 0.0, \"1370304000000\": 0.0, \"1371081600000\": 0.0, \"1370476800000\": 0.0, \"1378080000000\": 0.0, \"1380153600000\": 0.0, \"1373500800000\": 0.0, \"1366848000000\": 0.0, \"1379980800000\": 0.0, \"1357516800000\": 0.0, \"1378166400000\": 0.0, \"1387152000000\": 0.0, \"1369267200000\": 0.0, \"1374192000000\": 0.0, \"1364256000000\": 0.0, \"1376438400000\": 0.0, \"1366070400000\": 0.0, \"1366934400000\": 0.0, \"1384300800000\": 0.0, \"1386806400000\": 0.0, \"1371427200000\": 0.0, \"1377648000000\": 0.0, \"1383868800000\": 0.0, \"1376870400000\": 0.0, \"1363132800000\": 0.0, \"1382659200000\": 0.0, \"1366675200000\": 0.0, \"1385078400000\": 0.0, \"1359417600000\": 0.0, \"1365984000000\": 0.0, \"1362355200000\": 0.0, \"1380499200000\": 0.0, \"1375228800000\": 0.0, \"1374710400000\": 0.0, \"1380240000000\": 0.0, \"1363910400000\": 0.0, \"1358812800000\": 0.0, \"1378339200000\": 0.0, \"1384819200000\": 0.0, \"1361232000000\": 0.0, \"1386201600000\": 0.0, \"1381276800000\": 0.0, \"1361404800000\": 0.0, \"1365379200000\": 0.0, \"1378944000000\": 0.0, \"1365465600000\": 0.0, \"1378771200000\": 0.0, \"1369008000000\": 0.0, \"1375920000000\": 0.0, \"1357603200000\": 0.0, \"1375315200000\": 0.0, \"1367539200000\": 0.0, \"1374624000000\": 0.0, \"1386633600000\": 0.0, \"1363824000000\": 0.0, \"1368576000000\": 0.0, \"1358380800000\": 0.0, \"1366588800000\": 0.0, \"1381449600000\": 0.0, \"1382054400000\": 0.0, \"1361750400000\": 0.0, \"1377734400000\": 0.0, \"1372118400000\": 0.0, \"1386720000000\": 0.0, \"1385942400000\": 0.0, \"1358899200000\": 0.0, \"1382486400000\": 0.0, \"1372204800000\": 0.0, \"1363046400000\": 0.0, \"1364860800000\": 0.0, \"1374451200000\": 0.0, \"1381881600000\": 0.0, \"1358294400000\": 0.0, \"1378425600000\": 0.0, \"1368057600000\": 0.0, \"1364515200000\": 0.0, \"1368662400000\": 0.0, \"1381968000000\": 0.0, \"1381708800000\": 0.0, \"1375401600000\": 0.0, \"1365724800000\": 0.0, \"1364342400000\": 0.0, \"1387411200000\": 0.0, \"1386288000000\": 0.0, \"1368144000000\": 0.0, \"1388448000000\": 0.0, \"1386028800000\": 0.0, \"1369353600000\": 0.0, \"1367798400000\": 0.0, \"1358726400000\": 0.0, \"1359590400000\": 0.0, \"1369872000000\": 0.0, \"1370390400000\": 0.0, \"1379376000000\": 0.0, \"1383004800000\": 0.0, \"1373932800000\": 0.0, \"1358208000000\": 0.0, \"1364947200000\": 0.0, \"1370563200000\": 0.0, \"1371686400000\": 0.0, \"1376352000000\": 0.0, \"1387497600000\": 0.0, \"1384732800000\": 0.0, \"1362528000000\": 0.0, \"1379462400000\": 0.0, \"1383264000000\": 0.0, \"1358121600000\": 0.0, \"1373587200000\": 0.0, \"1363564800000\": 0.0, \"1360195200000\": 0.0, \"1377820800000\": 0.0, \"1357862400000\": 0.0, \"1381363200000\": 0.0, \"1360108800000\": 0.0, \"1383696000000\": 0.0, \"1357689600000\": 0.0, \"1362441600000\": 0.0, \"1387843200000\": 0.0, \"1361836800000\": 0.0, \"1367971200000\": 0.0, \"1375142400000\": 0.0, \"1386892800000\": 0.0, \"1372636800000\": 0.0, \"1384128000000\": 0.0, \"1380067200000\": 0.0, \"1366329600000\": 0.0, \"1370217600000\": 0.0, \"1373846400000\": 0.0, \"1386115200000\": 0.0, \"1369612800000\": 0.0, \"1371513600000\": 0.0, \"1366761600000\": 0.0, \"1362614400000\": 0.0, \"1385596800000\": 0.0, \"1375056000000\": 0.0, \"1362700800000\": 0.0, \"1359504000000\": 0.0, \"1386547200000\": 0.0, \"1381795200000\": 0.0, \"1358985600000\": 0.0, \"1358467200000\": 0.0, \"1357776000000\": 0.0, \"1368403200000\": 0.0, \"1379289600000\": 0.0, \"1387756800000\": 0.0, \"1376265600000\": 0.0, \"1371772800000\": 0.0, \"1384473600000\": 0.0, \"1374537600000\": 0.0, \"1363305600000\": 0.0, \"1381190400000\": 0.0, \"1364774400000\": 0.0, \"1387324800000\": 0.0, \"1385424000000\": 0.0, \"1372896000000\": 0.0, \"1376524800000\": 0.0, \"1369958400000\": 0.0, \"1372377600000\": 0.0, \"1368489600000\": 0.0, \"1379030400000\": 0.0, \"1360022400000\": 0.0, \"1375833600000\": 0.0, \"1363651200000\": 0.0, \"1384992000000\": 0.0, \"1377129600000\": 0.0, \"1359676800000\": 0.0, \"1367452800000\": 0.0, \"1383782400000\": 0.0, \"1367884800000\": 0.0, \"1372032000000\": 0.0, \"1362960000000\": 0.0, \"1374105600000\": 0.0, \"1382572800000\": 0.0, \"1366243200000\": 0.0, \"1382400000000\": 0.0, \"1383177600000\": 0.0, \"1360281600000\": 0.0, \"1372982400000\": 0.0, \"1383091200000\": 0.0, \"1357257600000\": 0.0, \"1369699200000\": 0.0, \"1363737600000\": 0.0, \"1378857600000\": 0.0, \"1369180800000\": 0.0, \"1388016000000\": 0.0, \"1374796800000\": 0.0, \"1369094400000\": 0.0, \"1359072000000\": 0.0, \"1366156800000\": 0.0, \"1373414400000\": 0.0, \"1376611200000\": 0.0, \"1384387200000\": 0.0, \"1364428800000\": 0.0, \"1371168000000\": 0.0, \"1382918400000\": 0.0, \"1372723200000\": 0.0, \"1364169600000\": 0.0, \"1383609600000\": 0.0, \"1378684800000\": 0.0, \"1377561600000\": 0.0, \"1373328000000\": 0.0, \"1365638400000\": 0.0, \"1382313600000\": 0.0, \"1377216000000\": 0.0, \"1373241600000\": 0.0, \"1383523200000\": 0.0, \"1375747200000\": 0.0, \"1365552000000\": 0.0, \"1379894400000\": 0.0, \"1372291200000\": 0.0, \"1363219200000\": 0.0, \"1376956800000\": 0.0, \"1371600000000\": 0.0, \"1362009600000\": 0.0, \"1372809600000\": 0.0, \"1361318400000\": 0.0, \"1374019200000\": 0.0, \"1384905600000\": 0.0, \"1387929600000\": 0.0, \"1369785600000\": 0.0, \"1376006400000\": 0.0, \"1378252800000\": 0.0, \"1361923200000\": 0.0, \"1388102400000\": 0.0, \"1359331200000\": 0.0}}'"}], "trusted": true}, {"cell_type": "strategy", "collapsed": false, "id": "B3DD0F6EBC134A97ACE3D6AF8A3EC63C", "input": "import numpy as np\nimport pandas as pd\nimport math\nimport scipy\nfrom scipy.stats import spearmanr\nfrom scipy.stats import rankdata\nimport pickle\n#from gplearn.functions import make_function\nfrom sklearn.utils import check_random_state\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom pandas import Series\nimport statsmodels.api as sm\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy.stats import pearsonr\n#import threading\n\nimport xgboost as xgb\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nimport time\n#import os\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn import  metrics  \nfrom sklearn.grid_search import GridSearchCV  \nfrom sklearn.preprocessing import MinMaxScaler   #\u6700\u5927\u6700\u5c0f\u5f52\u4e00\u5316\nfrom sklearn.preprocessing import StandardScaler   #\u6807\u51c6\u5316\nfrom sklearn.model_selection import train_test_split     #\u5212\u5206\u6570\u636e\u96c6\nfrom sklearn.model_selection import cross_val_score  \nimport matplotlib.pyplot as plt\n\n\nfield=['openPrice','highPrice','lowPrice','closePrice','turnoverVol','preClosePrice','PE','PB','PS','ROA','LCAP','NetProfitGrowRate']\nfactors=['factor1','factor2','factor3','factor4','factor5','factor6','factor7','factor8']\n#\u6781\u7aef\u503c\u5904\u7406(MAD)\ndef filter_extereme_MAD(series,n):\n    median=series.quantile(0.5)\n    diff_median=((series-median).abs()).quantile(0.5)\n    max_range=median+n*diff_median\n    min_range=median-n*diff_median\n    return np.clip(series,min_range,max_range)\n\ndef factor_MAD(data,n):\n    for i in range(len(field)):\n        initial_factor=data[:,i]\n        initial_factor=Series(initial_factor)\n        data[:,i] = filter_extereme_MAD(initial_factor,n)\n    return data\n\n#\u6807\u51c6\u5316\u5904\u7406\uff08Z-score\uff09\ndef standard_z_score(series):\n    std = series.std() \n    mean = series.mean() \n    return (series-mean)/std\n\ndef factor_standard(data):\n    for i in range(len(field)):\n        initial_factor=data[:,i]\n        data[:,i] = standard_z_score(initial_factor)\n    return data\n\n#\u5e02\u503c\u4e2d\u6027\u5316(Market cap neutrality)\ndef factor_MC_neutrality(data):\n    for i in range(len(field)):\n        x=data.iloc[:,i].values.reshape(-1,1)\n        data_log_marketcap=np.array(data.iloc[:,10].values,dtype=np.float64)\n        y=data_log_marketcap.flatten()\n        # \u5efa\u7acb\u56de\u5f52\u65b9\u7a0b\n        lr = LinearRegression()\n        lr.fit(x, y)  # \u62df\u5408\n        y_predict = lr.predict(x)  # \u9884\u6d4b\n        data.iloc[:,i] = y - y_predict   #\u6b8b\u5dee\u5373\u4e3a\u5e02\u503c\u4e2d\u6027\u5316\u540e\u7684\u65b0\u56e0\u5b50\u503c\n    return data\n    \n#\u5b9a\u4e49scale\u51fd\u6570\uff0c\u8fd4\u56de\u503c\u4e3a\u5411\u91cfa*X/sum(abs(X))\uff0ca\u7684\u7f3a\u7701\u503c\u4e3a1\uff0ca\u4e00\u822c\u4e3a\u6b63\u6570\ndef _scale(data):\n    data = pd.Series(data)\n    value = data.mul(1).div(np.abs(data).sum())\n    value = np.nan_to_num(value)    \n    return value\n#scale = make_function(function=_scale, name='scale', arity=1)\n\n\n\nclass BoostModel:\n    '''\n    \u5b9a\u4e49\u4e00\u4e2a\u5229\u7528xgboost\u6765\u505aboosting tree\u7684\u6d41\u7a0b\n    '''\n\n    def __init__(self, max_depth=6, subsample=0.9, num_round=200, early_stopping_rounds=50):\n        '''\n        \u521d\u59cb\u5316\n        \u53c2\u6570:\n            max_depth\uff1a\u6811\u7684\u6700\u5927\u6df1\u5ea6\n            subsample\uff1a \u91c7\u6837\u7387\uff0c\u4e5f\u5c31\u662f\u9009\u53d6\u591a\u5c11\u6bd4\u4f8b\u7684\u6837\u672c\u8fdb\u884c\u8bad\u7ec3\n            num_round\uff1a \u6700\u5927\u5faa\u73af\u6b21\u6570\uff0c\u4e5f\u5c31\u662f\u6700\u5927\u7684\u6811\u4e2a\u6570\n            early_stopping_rounds\uff1a\u63d0\u524d\u505c\u6b62\u6b21\u6570\uff0c\u5047\u8bbe\u4e3a50\uff0c\u4e5f\u5c31\u662f\u8bf4\u9a8c\u8bc1\u96c6\u7684\u8bef\u5dee\u8fed\u4ee3\u5230\u4e00\u5b9a\u7a0b\u5ea6\u572850\u6b21\u5185\u4e0d\u80fd\u518d\u7ee7\u7eed\u964d\u4f4e\uff0c\u5c31\u505c\u6b62\u8fed\u4ee3\n        '''\n\n        # \u4e0b\u9762\u7684\u53c2\u6570eta: \u5b66\u4e60\u7387\uff1bsilent: \u662f\u5426\u6253\u5370\u8bad\u7ec3\u8fc7\u7a0b\u4fe1\u606f\uff1balpha: L1 \u6b63\u5219\u7684\u60e9\u7f5a\u7cfb\u6570\uff1blambda: L2 \u6b63\u5219\u7684\u60e9\u7f5a\u7cfb\u6570\uff1b\n        # eval_metric: \u8bc4\u4ef7\u6307\u6807\uff1bobjective: \u5b9a\u4e49\u5b66\u4e60\u4efb\u52a1\u53ca\u76f8\u5e94\u7684\u5b66\u4e60\u76ee\u6807\n        self.params = {'booster':gbtree,'max_depth': max_depth, 'eta': 0.02, 'gamma':0.1,'silent': 1,    'alpha': 0.5, 'lambda': 0.5, 'eval_metric': 'rmse', 'subsample': subsample, 'objective': 'reg:linear',\n                       'colsample_bytree': 0.8,'min_child_weight':3}\n        #self.params = {'booster':gbtree,'max_depth': max_depth, 'eta': 0.02, 'gamma':0.1,'silent': 1, #'alpha': 0.5, 'lambda': 0.5, 'eval_metric': 'auc', 'subsample': subsample, 'objective': 'binary:logistic',\n        #               'colsample_bytree': 0.8,'min_child_weight':3}\n        self.num_round = num_round\n        self.early_stopping_rounds = early_stopping_rounds\n        \n    #\u7f51\u683c\u641c\u7d22\u5316\u8c03\u53c2    \n    #from sklearn.model_selection import GridSearchCV\n    #parameters={'n_estimators':range(10, 300, 10),\n                #'max_depth':range(3,10,1),\n                #'learning_rate': [ 0.01, 0.05, 0.1, 0.2, 0.3],\n                #'min_child_weight':range(5, 21, 1),\n                #'gamma':[0.1, 0.2, 0.3, 0.4],\n                #'colsample_bytree':[0.5, 0.6, 0.7, 0.8, 0.9, 1],\n                #'colsample_bylevel':[0.5, 0.6, 0.7, 0.8, 0.9, 1]\n                #}\n\n    def fit(self, train_data, train_label, val_data, val_label):\n        '''\n        \u8bad\u7ec3\u6a21\u578b\n        \u53c2\u6570:\n            train_data, train_label\uff1a\u5206\u522b\u5bf9\u5e94\u7740\u8bad\u7ec3\u7279\u5f81\u6570\u636e\uff0c\u8bad\u7ec3\u6807\u7b7e\n            val_data, val_label\uff1a \u5206\u7c7b\u5bf9\u5e94\u7740\u9a8c\u8bc1\u7279\u5f81\u6570\u636e\uff0c\u9a8c\u8bc1\u6807\u7b7e\n        \u8fd4\u56de:\n            boost_model, \u8bad\u7ec3\u540e\u7684xgboost\u6a21\u578b\n        '''\n\n        dtrain = xgb.DMatrix(train_data, label=train_label)\n        deval = xgb.DMatrix(val_data, label=val_label)\n\n        boost_model = xgb.train(self.params, dtrain, num_boost_round=self.num_round,\n                                evals=[(dtrain, 'train'), (deval, 'eval')],\n                                early_stopping_rounds=self.early_stopping_rounds, verbose_eval=False)\n        # print('get best eval auc : %s, in step %s' % (boost_model.best_score, boost_model.best_iteration))\n        self.boost_model = boost_model\n\n        return boost_model\n\n    def predict(self, test_data):\n        '''\n        \u9884\u6d4b\n        \u53c2\u6570:\n            test_data\uff1a\u5f85\u9884\u6d4b\u7684\u7279\u5f81\u6570\u636e\n        \u8fd4\u56de:\n            predict_score: \u9884\u6d4b\u503c\n        '''\n\n        dtest = xgb.DMatrix(test_data)\n        predict_score = self.boost_model.predict(dtest, ntree_limit=self.boost_model.best_ntree_limit)\n\n        return predict_score\n\n    \n\n# \u62c6\u5206\u8bad\u7ec3\u3001\u9a8c\u8bc1\u3001\u6d4b\u8bd5\u96c6\ndef get_train_val_test_data(df, train_pct=0.8, train_start_date='2012-01-01', train_end_date='2017-12-31', test_start_date='2018-01-01', test_end_date='2022-01-01'):\n    '''\n    \u53c2\u6570:\n        df: \u6570\u636e\u96c6\uff0ccolumns\u5305\u62ec\uff1atrade_date(YYYY-mm-dd), \u4e2a\u80a1\u7684\u6536\u76ca\u7387\u6807\u7b7e\uff0c\u7279\u5f81\n        train_start_date, train_end_date: \u65f6\u95f4\u533a\u6bb5\u5185\u7684\u6570\u4f5c\u4e3a\u8bad\u7ec3\u96c6\n        train_pct: \u8bad\u7ec3\u96c6\u4e2d\uff0c\u591a\u5927\u7684\u6bd4\u4f8b\u4f5c\u4e3a\u9a8c\u8bc1\u96c6\n    \u8fd4\u56de:\n        train_df, val_df, test_df: \u4e09\u4e2a\u5747\u4e3aDataFrame\uff0c\u5bf9\u5e94\u7740\u8bad\u7ec3\u3001\u9a8c\u8bc1\u3001\u6d4b\u8bd5\u7684\u6570\u636e\u96c6\n        \u4e0a\u8ff03\u4e2adataframe\u7684columns\u4f9d\u7136\u4e3a trade_date, \u5404\u6837\u672c\u6807\u7b7e\uff0c\u7279\u5f81\n    '''\n    t1 = time.time()\n\n    train_val_df = df[(df['trade_date'] >= train_start_date) & (df['trade_date'] <= train_end_date)]\n    train_val_df = train_val_df.sample(frac=1, random_state=666).reset_index(drop=True)\n\n    # \u62c6\u5206\u8bad\u7ec3\u96c6\u3001\u9a8c\u8bc1\u96c6\n    train_df = train_val_df.iloc[0:int(len(train_val_df) * train_pct)]\n    val_df = train_val_df.iloc[int(len(train_val_df) * train_pct):]\n\n    test_df = df[df.trade_date > train_end_date]\n    if test_start_date and test_end_date:\n        test_df = test_df[(test_df.trade_date >= test_start_date) & (test_df.trade_date <= test_end_date)]\n    t2 = time.time()\n    #print(\"get train_val_test_data, time_cost:\", t2 - t1)\n    #print(\"[data verify], train, %s to %s\" % (min(train_df.trade_date.values), max(train_df.trade_date.values)))\n    #print(\"[data verify], val, %s to %s\" % (min(val_df.trade_date.values), max(val_df.trade_date.values)))\n    #print(\"[data verify], test, %s to %s\" % (min(test_df.trade_date.values), max(test_df.trade_date.values)))\n    return train_df, val_df, test_df\n\n\n# \u5c06\u56e0\u5b50\u683c\u5f0f\u7684dataframe\uff0c\u8f6c\u6362\u6210feature\u548clabel\u4e24\u4e2aarray\uff0c\u4fbf\u4e8e\u8f93\u5165\u6a21\u578b\ndef format_feature_label(data_df, init_feature, init_label):\n    '''\n    \u53c2\u6570:\n        df: \u539f\u59cb\u8f93\u5165\u6570\u636e\uff0cDataFrame, columns\u5305\u62ec\uff1atrade_date(\u53ef\u80fd\u6ca1\u6709), \u4e2a\u80a1\u539f\u59cb\u7279\u5f81\u3001\u6807\u7b7e  \n        init_label: list, \u4f5c\u4e3alabel\u7684\u56e0\u5b50\u5217\u8868\uff0clabel_lists\u7684\u987a\u5e8f\u548cinit_label\u4e25\u683c\u4e00\u81f4\n        \u5e26init_feature\u7684\u5217\u90fd\u4f1a\u88ab\u8ba4\u4e3a\u662f\u7279\u5f81\n    \u8fd4\u56de:\n        feature: np.array, \u5bf9\u5e94\u7740\u66f4\u6539\u683c\u5f0f\u540e\u7684\u6570\u636e\u7279\u5f81, N*K\u4e2a\u7279\u5f81\n        label_lists: \u5355\u4e2a\u5143\u7d20\u4e3a np.array, \u5bf9\u5e94\u7740\u66f4\u6539\u683c\u5f0f\u540e\u7684\u6570\u636e\u6807\u7b7e, N*1\n    '''\n    df = data_df.copy()\n    if 'trade_date' in df.columns:\n        del df['trade_date']\n    #end_tag_length = len(y_marker)\n    # \u63d0\u53d6\u51fa\u7279\u5f81\u5217\n    #valid_feature_col = [x for x in df.columns if x[-end_tag_length:] != y_marker]\n    # \u7279\u5f81\u6570\u7ec4\n    feature = np.array(df[init_feature])\n    # \u6807\u7b7e\u6570\u7ec4\uff08\u9884\u6d4b\u7684\u771f\u5b9e\u503c\u7ec4\uff09\n    label_lists = []\n    for lab in init_label:\n        label = np.array(df[lab])\n        label_lists.append(label)\n    return feature, label_lists\n\n\n\n# \u8ba1\u7b97n\u4e2a\u5b63\u5ea6\u4e4b\u540e\u7684\u65e5\u671f     #n=2\uff0c\u6a21\u578b\u6bcf180\u5929\u4e2a\u4ea4\u6613\u65e5\u8bad\u7ec3\u4e00\u6b21\ndef calc_time(ori_date, periods):\n    '''\n    \u8f93\u5165\u53c2\u6570\uff1a\n        ori_date: \u5f00\u59cb\u65e5\u671f\uff0cYYYY-mm-dd\u683c\u5f0f\n        periods: \u5b63\u5ea6\u6570\n    \u8f93\u51fa\uff1a\n        periods\u4e2a\u5b63\u5ea6\u4e4b\u540e\u7684\u65e5\u671fstop_date\uff0c\u4ee5\u53castop\u7684\u4e0b\u4e00\u4e2a\u65e5\u671fnext_start_date\n    '''\n    end_fix = {\"01\": \"01\", \"04\": \"01\", \"07\": \"01\", \"10\": \"01\", \"03\": \"31\", \"06\": \"30\", \"09\": \"30\", \"12\": \"31\"}\n    [ori_y, ori_m, ori_d] = ori_date.split(\"-\")\n\n    ori_y = int(ori_y)\n    ori_m = int(ori_m)\n    next_start_m = ori_m + int(periods)\n    start_year_skip = next_start_m / 12\n    next_start_m = next_start_m % 12\n    next_start_y = ori_y + start_year_skip\n    stop_m = next_start_m\n    stop_y = next_start_y\n\n    if stop_m == 1:\n        stop_m = 12\n        stop_y -= 1\n    else:\n        stop_m -= 1\n    next_start_date = \"%s-%s-%s\" % (next_start_y, str(next_start_m).zfill(2), end_fix[str(next_start_m).zfill(2)])\n    stop_date = \"%s-%s-%s\" % (stop_y, str(stop_m).zfill(2), end_fix[str(stop_m).zfill(2)])\n\n    return stop_date, next_start_date\n\n# \u5212\u5206\u65f6\u95f4\u533a\u6bb5\ndef get_rolling_date(train_start, test_start, test_end, test_quarter_periods=3, train_quarter_periods=72):\n    '''\n    1. \u65f6\u95f4\u90fd\u662fYYYY-mm-dd\u683c\u5f0f\n    2. \u4ecetest_start\u5230test_end\uff0c\u6309\u7167\u5b63\u5ea6\u5e73\u79fb\u8bad\u7ec3\u671f\uff0c \u5206\u6210\u4e00\u4e2a\u4e2a\u5b50\u533a\u95f4\n    test_quarter_periods = 3  # \u6d4b\u8bd5\u671f\u4e3a3\u4e2a\u6708\n    train_quarter_periods = 72 # \u4fdd\u6301\u8bad\u7ec3\u671f\u4e3a6\u5e74\n    \u8fd4\u56de\uff1a\n        [[train_s, train_e, test_s, test_e], [train_s, train_e, test_s, test_e]]\n    '''\n    test_begin = test_start\n    train_begin = train_start\n\n    date_constrains = []\n    while 1:\n        test_stop, next_test_start = calc_time(test_begin, test_quarter_periods)\n        train_stop, _ = calc_time(train_begin, train_quarter_periods)\n        _, next_train_start = calc_time(train_begin, test_quarter_periods)\n        if test_stop >= test_end:\n            test_stop = test_end\n            date_constrains.append([train_begin, train_stop, test_begin, test_stop])\n            break\n        else:\n            date_constrains.append([train_begin, train_stop, test_begin, test_stop])\n        test_begin = next_test_start\n        train_begin = next_train_start\n    return date_constrains\n\n# \u7528xgboost\u6a21\u578b\u6765\u9884\u6d4binit_label\u4e2d\u5404\u4e2a\u80a1\u7968\u7684\u6536\u76ca\u503c\uff08\u5bf9\u5e94\u7684\u7279\u5f81\u548c\u65f6\u95f4\u5728test_df\u4e2d\uff09\ndef predict_factors(train_df, val_df, test_df, init_label):\n    '''\n    \u8f93\u5165\u53c2\u6570\uff1a\n        train_df, val_df, test_df: \u8bad\u7ec3\u96c6\u3001\u9a8c\u8bc1\u96c6\u3001\u6d4b\u8bd5\u96c6\u6570\u636e\n    \u8f93\u51fa\uff1a\n        \u9884\u6d4b\u503cdf\uff0ccolumns\u4e3a trade_date, \u56e0\u5b50\u771f\u5b9e\u503c\uff08\u8fd9\u4e24\u9879\u662f\u53d6\u81eatest_df\u4e2d\uff09\uff0c\u56e0\u5b50\u7684\u9884\u6d4b\u503c\n\n    '''\n    train_feature, train_labels = format_feature_label(train_df, feature, init_label)\n    val_feature, val_labels = format_feature_label(val_df, feature, init_label)\n    test_feature, test_labels = format_feature_label(test_df, feature, init_label)\n\n    test_date_values = list(test_df.trade_date.values)\n    result_dict = {\"trade_date\": test_date_values}\n    # xgboost\u6a21\u578b\u8bad\u7ec3\uff0c\u5f97\u5230\u56e0\u5b50\u503c\u8f93\u51fa\n    for tcount in range(len(init_label)):\n        factor_name =  init_label[tcount]\n        #print(\"predicting %s...\" % factor_name)\n        if debug_flag:\n            boost_model = BoostModel(num_round=200, early_stopping_rounds=20)\n        else:\n            boost_model = BoostModel()\n        train_start = time.time()\n        boost_model.fit(train_feature, train_labels[tcount], val_feature, val_labels[tcount])\n        train_stop = time.time()\n        print(\"train time cost:%s\" % (train_stop - train_start))\n        predict_score = boost_model.predict(test_feature)\n        predict_stop = time.time()\n        print(\"predict time cost:%s\" % (predict_stop - train_stop))\n        predict_score = list(predict_score)\n        result_dict[factor_name + \"_predict\"] = predict_score\n        tcount += 1\n    return pd.DataFrame(result_dict)\n\n# \u7528xgboost\u6a21\u578b\u9884\u6d4b\u6837\u672c\u6807\u7b7e\u503c\ndef run_xgboost_predict(df, run_type='rolling', train_start='2012-01-01', train_end='2017-12-31',\n                        test_start='2018-01-01', test_end='2022-01-01'):\n    '''\n    \u8f93\u5165\u53c2\u6570\uff1a\n        df: dataframe\uff0c\u5305\u62ec\u8bad\u7ec3\u96c6+\u6d4b\u8bd5\u96c6\u7684\u6240\u6709\u6570\u636e\uff0ccolumns\u5305\u62ec\uff1atrade_date(YYYY-mm-dd), \u5404\u4e2a\u56e0\u5b50\u7684\u771f\u5b9eIC\uff0c\u7279\u5f81\n        run_type: \u662f\u9759\u6001\u8bad\u7ec3+\u9884\u6d4b\uff0c\u8fd8\u662f\u6eda\u52a8\u8bad\u7ec3+\u9884\u6d4b\n    \u8fd4\u56de\uff1a\n        \u6d4b\u8bd5\u671f\u7684\u771f\u5b9e\u503c\u3001\u9884\u6d4b\u503c\u7684dataframe, columns\u5305\u62ec\uff1a trade_date, \u56e0\u5b50\u7684\u771f\u5b9eIC\uff0c\u56e0\u5b50\u7684\u9884\u6d4bIC\n    '''\n    global factors\n    predict_df = pd.DataFrame()  # \u5217\u4e3a: \u5404\u56e0\u5b50\u503c.\n    # \u9759\u6001\u9884\u6d4b\n    if run_type == 'static':\n        print(\"\\n====================== run_type:\", run_type)\n        print(\"[train]: %s to %s\" % (train_start, train_end))\n        print(\"[test]: %s to %s\" % (test_start, test_end))\n        # \u62ff\u5230\u8bad\u7ec3\u3001\u9a8c\u8bc1\u3001\u6d4b\u8bd5\u96c6\u6570\u636e\n        train_df, val_df, test_df = get_train_val_test_data(df, 0.8, train_start, train_end, test_start, test_end)\n        if debug_flag:\n            predict_df = predict_factors(train_df, val_df, test_df, init_label)       #???\n        else:\n            predict_df = predict_factors(train_df, val_df, test_df, factors)\n    # \u6eda\u52a8\u9884\u6d4b\n    else:\n        print(\"\\n====================== run_type:\", run_type)\n        predict_df_list = []\n        # \u6839\u636e\u5b63\u5ea6\u5212\u5206\u65f6\u95f4\u533a\u95f4\n        date_constrains = get_rolling_date(train_start, test_start, test_end)\n        # \u5728\u6bcf\u4e2a\u65f6\u95f4\u533a\u95f4\u5185\u8fdb\u884c\u8bad\u7ec3\u548c\u9884\u6d4b\n        for [train_s, train_e, test_s, test_e] in date_constrains:\n            print(\"\\n---------------- > new rolling periods < ----------------------\")\n            print(\"[train]: %s to %s\" % (train_s, train_e))\n            print(\"[test]: %s to %s\" % (test_s, test_e))\n            train_df, val_df, test_df = get_train_val_test_data(df, 0.8, train_s, train_e, test_s, test_e)\n            if debug_flag:\n                tmp_predict_df = predict_factors(train_df, val_df, test_df, init_label)\n            else:\n                tmp_predict_df = predict_factors(train_df, val_df, test_df, factors)\n\n            predict_df_list.append(tmp_predict_df)\n        # \u5c06\u4e0d\u540c\u5b63\u5ea6\u7684\u7ed3\u679c\u5408\u5e76\u5230\u4e00\u8d77\n        predict_df = pd.concat(predict_df_list)\n    return predict_df\n\n\n# \u67d0\u65e5\u7684ST\u80a1\u7968\u80a1\u7968\ndef get_st_stocks(source_universe, st_date=None):\n    \"\"\"\n    Args:\n        source_universe (list of str): \u9700\u8981\u8fdb\u884c\u7b5b\u9009\u7684\u80a1\u7968\u5217\u8868\n        st_date (datetime): \u8fdb\u884c\u7b5b\u9009\u7684\u65e5\u671f,\u9ed8\u8ba4\u4e3a\u8c03\u7528\u5f53\u5929\n    Returns:\n        list: ST\u80a1\u7968\u5217\u8868\n    \"\"\"\n    st_date = st_date if st_date is not None else datetime.datetime.now().strftime('%Y%m%d')\n    df_ST = DataAPI.SecSTGet(secID=source_universe, beginDate=st_date, endDate=st_date, field=['secID'])\n    return list(df_ST['secID'].values)\n\n\n\n#xgboost\u7684rolling\u7ec4\u5408\nfactor_name='rolling'\nstart = '2012-01-01'                       # \u56de\u6d4b\u8d77\u59cb\u65f6\u95f4\nend = '2022-01-01'                         # \u56de\u6d4b\u7ed3\u675f\u65f6\u95f4\nuniverse = DynamicUniverse('HS300')        # \u8bc1\u5238\u6c60\uff0c\u652f\u6301\u80a1\u7968\u3001\u57fa\u91d1\u3001\u671f\u8d27\u3001\u6307\u6570\u56db\u79cd\u8d44\u4ea7\nbenchmark = 'HS300'                        # \u7b56\u7565\u53c2\u8003\u6807\u51c6\nfreq = 'd'                                 # \u7b56\u7565\u7c7b\u578b\uff0c'd'\u8868\u793a\u65e5\u95f4\u7b56\u7565\u4f7f\u7528\u65e5\u7ebf\u56de\u6d4b\uff0c'm'\u8868\u793a\u65e5\u5185\u7b56\u7565\u4f7f\u7528\u5206\u949f\u7ebf\u56de\u6d4b\nrefresh_rate = 30                           # \u8c03\u4ed3\u9891\u7387\uff0c\u8868\u793a\u6267\u884chandle_data\u7684\u65f6\u95f4\u95f4\u9694\uff0c\u82e5freq = 'd'\u65f6\u95f4\u95f4\u9694\u7684\u5355\u4f4d\u4e3a\u4ea4\u6613\u65e5\uff0c\u82e5freq = 'm'\u65f6\u95f4\u95f4\u9694\u4e3a\u5206\u949f\n  \n# \u914d\u7f6e\u8d26\u6237\u4fe1\u606f\uff0c\u652f\u6301\u591a\u8d44\u4ea7\u591a\u8d26\u6237\naccounts = {\n    'security_account': AccountConfig(account_type='security', capital_base=10000000, commission=Commission(buycost=0.001,sellcost=0.002,unit='perValue'), slippage=Slippage(value=0.0, unit='perValue'))\n}\n  \ndef initialize(context):\n    pass\n \n    previous_date = context.previous_date.strftime('%Y-%m-%d')\n    # \u83b7\u53d6\u5404\u539f\u59cb\u56e0\u5b50\u7684\u7684\u5386\u53f2\u6570\u636e\u96c6\uff0c\u622a\u6b62\u5230\u524d\u4e00\u4e2a\u4ea4\u6613\u65e5\n    hist = context.history(symbol=context.get_universe(exclude_halt=True), attribute=['openPrice','highPrice','lowPrice','closePrice','turnoverVol','preClosePrice','PE','PB','PS','ROA','LCAP','NetProfitGrowRate'], time_range=1, freq='1d', style='tas', rtype='frame')[previous_date]\n\n    #\u6570\u636e\u9884\u5904\u7406\n    #\u7f3a\u5931\u503c\u5904\u7406 \n    hist=pd.DataFrame(hist)\n    #for i in range(len(field)):\n    #    hist.iloc[:,i]=hist.iloc[:,i].fillna(hist.iloc[:,i].mean())\n    hist=hist.dropna(axis=0)    #\u5220\u9664\u542b\u7a7a\u503c\u884c\n    #\u6781\u7aef\u503c\u5904\u7406    \n    #hist=np.array(hist)\n    #hist_filter_extereme = factor_MAD(hist,5)\n    for field in fields:\n        hist[field]=winsorize(hist[field], win_type='QuantileDraw', pvalue=0.05)\n    #\u6807\u51c6\u5316\u5904\u7406\n    #hist_standard = factor_standard(hist_filter_extereme)\n    #hist_standard = factor_standard(hist)\n    for field in fields:\n        hist[field]=standardize(hist[field])\n    #\u5e02\u503c\u4e2d\u5fc3\u5316\n    #hist_standard=pd.DataFrame(hist_standard, columns=field)\n    #hist_processed = factor_MC_neutrality(hist_standard)\n    for field in fields:\n        hist[field]=neutralize(hist[field], previous_date, industry_type='SW1', exclude_style_list=[])\n    \n    #\u8ba1\u7b97\u6240\u6709\u80a1\u7968\u7684\u6240\u6709\u56e0\u5b50\u7684\u5f53\u671f\u503c\uff0c\u4f5c\u4e3a\u6837\u672c\u7684\u539f\u59cb\u7279\u5f81\n    hist_processed=pd.DataFrame(hist_processed,columns=fields)\n    hist_factor=pd.DataFrame(columns=['factor1','factor2','factor3','factor4','factor5','factor6','factor7','factor8'])\n    pre_factor1=hist_processed.closePrice/abs(hist_processed.preClosePrice)\n    hist_factor.loc[:,'factor1']=pre_factor1**0.5\n    hist_factor.loc[:,'factor2']=hist_processed.closePrice/abs(hist_processed.preClosePrice)\n    hist_factor.loc[:,'factor3']=hist_processed.closePrice/(hist_processed.preClosePrice*0.827)\n    hist_factor.loc[:,'factor4']=hist_processed.closePrice/(hist_processed.preClosePrice*(hist_processed.openPrice/hist_processed.lowPrice))\n    hist_factor.loc[:,'factor5']=hist_processed.closePrice/hist_processed.openPrice\n#    hist_factor.loc[:,'factor6']=scale(hist_processed.highPrice)/(hist_processed.preClosePrice*(hist_processed.openPrice/hist_processed.lowPrice))\n#    hist_factor.loc[:,'factor7']=scale(hist_processed.highPrice)/(hist_processed.preClosePrice*(hist_processed.preClosePrice/hist_processed.lowPrice))\n    hist_factor.loc[:,'factor6']=hist_processed.highPrice/(hist_processed.preClosePrice*(hist_processed.openPrice/hist_processed.lowPrice))\n    hist_factor.loc[:,'factor7']=hist_processed.highPrice/(hist_processed.preClosePrice*(hist_processed.preClosePrice/hist_processed.lowPrice))\n    hist_factor.loc[:,'factor8']=hist_processed.highPrice/(hist_processed.preClosePrice*(hist_processed.openPrice/hist_processed.lowPrice))\n    \n    \n    #\u8ba1\u7b97\u4e0b\u4e00\u4e2a\u8c03\u4ed3\u5468\u671f\u7684\u4e2a\u80a1\u6536\u76ca\u7387\uff0c\u4f5c\u4e3a\u6837\u672c\u7684\u6807\u7b7e\n    histt = context.history(symbol=universe, attribute='closePrice', time_range=1, freq='1d', style='tas', rtype='frame')[previous_date]\n    hist_return=pd.DataFrame(columns=['return_rate'],index=universe)\n    for date in previous_date[:-1]:\n        hist_return.loc[:,'return_rate']=histt.loc[date+30,:,'closePrice']/histt.loc[date,:,'closePrice']-1\n        \n    #\u5c06\u4e2a\u80a1\u56e0\u5b50\u503c\uff08\u7279\u5f81\u503c\uff09\u3001\u4e0b\u4e00\u4e2a\u8c03\u4ed3\u5468\u671f\u7684\u6536\u76ca\u7387\uff08\u6807\u7b7e\uff09\u5bf9\u9f50\n    model_data = hist_factor.merge(hist_return, on=['trade_date'], how='inner')\n    model_data=model_data.dropna()\n    \n    train_df,val_df,test_df=get_train_val_test_data(model_data, train_pct=0.8, train_start_date='2012-01-01', train_end_date='2017-12-31', test_start_date='2018-01-01', test_end_date='2022-01-01')  \n    train_data=train_df[factors]       #\u7279\u5f81\n    train_label=train_df['return_rate']       #\u6807\u7b7e\n    val_data=val_df[factors]\n    val_label=val_df['return_rate']\n    test_data=test_df[factors]\n    test_label=test_df['return_rate']\n    feature,label_lists=format_feature_label(model_data, hist_factors, hist_return)\n    #\u8c03\u7528class BoostModel\n    #boost=BoostModel()    \n    boost._init_(max_depth=6, subsample=0.9, num_round=200, early_stopping_rounds=50)   #?\n    boost.fit(train_data, train_label, val_data, val_label)\n    boost.predict(test_data)\n    \n    stop_date,next_start_date=calc_time('2012-01-01', 2)   # \u8ba1\u7b97n\u4e2a\u5b63\u5ea6\u4e4b\u540e\u7684\u65e5\u671f     #n=2\uff0c\u6a21\u578b\u6bcf180\u5929\u4e2a\u4ea4\u6613\u65e5\u8bad\u7ec3\u4e00\u6b21\n    date_constrains=get_rolling_date('2012-01-01' '2018-01-01', '2022-01-01', test_quarter_periods=3,train_quarter_periods=72) \n    # \u5212\u5206\u65f6\u95f4\u533a\u6bb5, \u6d4b\u8bd5\u671f\u4e3a3\u4e2a\u6708, \u4fdd\u6301\u8bad\u7ec3\u671f\u4e3a6\u5e74\n    \n    # \u901a\u8fc7flag\u6765\u63a7\u5236\u662f\u5426\u8981debug\n    debug_flag = 0\n    #static_time1 = time.time()\n    # \u6570\u636e\u8bbe\u7f6e\n    field=['openPrice','highPrice','lowPrice','closePrice','turnoverVol','preClosePrice','PE','PB','PS','ROA','LCAP','NetProfitGrowRate']\n    factors=['factor1','factor2','factor3','factor4','factor5','factor6','factor7','factor8']\n    #\u8dd1rolling\u7684\u6a21\u578b\n    if debug_flag:\n        rolling_result = run_xgboost_predict(model_data, run_type='rolling', train_start='2012-01-01',\n                                        train_end='2017-12-31', test_start='2018-01-01', test_end='2022-1-1')\n    else:\n        rolling_result = run_xgboost_predict(model_data, run_type='rolling')\n    rolling_result = rolling_result.merge(model_data[['trade_date']+feature], on=['trade_date'], how='left')\n    rolling_time = time.time()\n    #print(rolling_result.head())\n    #rolling_result.to_pickle(os.path.join(raw_data_dir, \"rolling_result.pickle\"))\n    #print(\"rolling\", rolling_time - static_time2)   \n    \n    predict_df=run_xgboost_predict(model_data, run_type='rolling', train_start='2012-01-01', train_end='2017-12-31',\n                        test_start='2018-01-01', test_end='2022-01-01')\n        \n   \n    \n# \u6bcf\u4e2a\u5355\u4f4d\u65f6\u95f4(\u5982\u679c\u6309\u5929\u56de\u6d4b,\u5219\u6bcf\u5929\u8c03\u7528\u4e00\u6b21,\u5982\u679c\u6309\u5206\u949f,\u5219\u6bcf\u5206\u949f\u8c03\u7528\u4e00\u6b21)\u8c03\u7528\u4e00\u6b21\ndef handle_data(context):      \n        \n    # \u6caa\u6df1300\u6210\u5206\u80a1\uff0c\u5254\u9664\u505c\u724c\n    universe_secIDs = list(universe.preview(context.current_date.strftime(\"%Y-%m-%d\"),skip_halted=True))\n    # \u5f53\u5929\u7684ST\u80a1\n    st_stocks = get_st_stocks(universe_secIDs, st_date=context.current_date.strftime(\"%Y-%m-%d\"))\n    # \u5254\u9664ST\u80a1\n    buy_factor_frame = total_factor_frame[~(total_factor_frame.secID.isin(st_stocks))]\n    # \u5728\u6210\u5206\u80a1\u5185\n    buy_factor_frame = buy_factor_frame[buy_factor_frame.secID.isin(universe_secIDs)]\n\n    \n    # \u62ff\u53d6\u8c03\u4ed3\u65e5\u524d\u4e00\u4e2a\u4ea4\u6613\u65e5\u7684\u56e0\u5b50\uff0c\u9009\u53d6\u9884\u6d4b\u503c\u6700\u9ad8\u768430\u652f\u80a1\u7968\u7b49\u6743\u4e70\u5165\n    target_list = get_stock_list(buy_factor_frame, pre_date, factor_name, True, quantile_num=10)\n    #signal = predict_df['return_rate'].order(ascending=False)    #\u964d\u5e8f\n    #target_list = signal[:30].index\n    \n    # \u5c06\u56e0\u5b50\u503c\u4ece\u5927\u5230\u5c0f\u6392\u5e8f\uff0c\u5e76\u53d6\u524d30\u652f\u80a1\u7968\u4f5c\u4e3a\u76ee\u6807\u6301\u4ed3\n    #hist_factor_final=hist_factor\n    #hist_factor_final['sum_factor']=hist_factor_final.apply(lambda x:x.sum,axis=1)    #\u6309\u884c\u6c42\u548c\n    #signal = hist_factor_final['sum_factor'].order(ascending=False)    #\u964d\u5e8f\n    #target_position = signal[:30].index\n   \n\n    ############### \u6267\u884c\u4ea4\u6613 ################\n    # \u83b7\u53d6\u5f53\u524d\u8d26\u6237\u4fe1\u606f\n    account = context.get_account('security_account')   \n    current_position = account.get_positions(exclude_halt=True)       \n     \n    # \u5356\u51fa\u5f53\u524d\u6301\u6709\uff0c\u4f46\u76ee\u6807\u6301\u4ed3\u6ca1\u6709\u7684\u90e8\u5206\n    for stock in set(current_position).difference(target_position):\n        account.order_to(stock, 0)\n     \n    # \u6839\u636e\u76ee\u6807\u6301\u4ed3\u6743\u91cd\uff0c\u9010\u4e00\u59d4\u6258\u4e0b\u5355\n    for stock in target_position:\n        account.order_pct_to(stock, 1.0/len(target_position))   #\u7b49\u6743\u4e70\u5165\n   \n", "language": "python", "metadata": {}, "outputs": [{"ename": "Exception", "evalue": "Exception in \"Context.__init__\": 'NoneType' object has no attribute 'strftime'!", "output_type": "pyerr", "traceback": ["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)", "\u001b[1;32m<mercury-input-4-B3DD0F6EBC134A97ACE3D6AF8A3EC63C>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    558\u001b[0m                                             \u001b[0maccounts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccounts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreload_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_QUARTZ_PRELOAD_DATA\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m                                             \u001b[0mdisplay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_quartz_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m                                             threaded=quartz_createVar.get('threaded', True), need_tracking=True)\n\u001b[0m\u001b[0;32m    561\u001b[0m     \u001b[0m_QUARTZ_CACHE\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'start'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[0m_QUARTZ_CACHE\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'end'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", "\u001b[1;32m/home/ipython/anaconda/lib/python2.7/site-packages/mercuryq-quartz-3.61.0-1530.egg/quartz/utils/tracking_utils.pyc\u001b[0m in \u001b[0;36m_decorator\u001b[1;34m(*args, **kwargs)\u001b[0m\n", "\u001b[1;32m/home/ipython/anaconda/lib/python2.7/site-packages/mercuryq-quartz-3.61.0-1530.egg/quartz/backtest.pyc\u001b[0m in \u001b[0;36mbacktest\u001b[1;34m(start, end, benchmark, universe, capital_base, initialize, handle_data, post_trading_day, commission, slippage, refresh_rate, freq, security_base, security_cost, max_history_window, accounts, threaded, display, preload_data, *args, **kwargs)\u001b[0m\n", "\u001b[1;32m/home/ipython/anaconda/lib/python2.7/site-packages/mercuryq-quartz-3.61.0-1530.egg/quartz/trading_agent.pyc\u001b[0m in \u001b[0;36mfrom_config\u001b[1;34m(cls, clock, sim_params, data_portal, strategy, account_manager, pms_lite, broker_client, report_client, market_roller, trading_scheduler, display, context)\u001b[0m\n", "\u001b[1;32m/home/ipython/anaconda/lib/python2.7/site-packages/mercuryq-quartz-3.61.0-1530.egg/quartz/context/context.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, clock, sim_params, strategy, market_service, universe_service, asset_service, calendar_service, market_roller, account_manager)\u001b[0m\n", "\u001b[1;31mException\u001b[0m: Exception in \"Context.__init__\": 'NoneType' object has no attribute 'strftime'!"]}]}, {"cell_type": "code", "collapsed": false, "id": "E15F59ED67B64B948EC7C16BC61C5A7F", "input": "def hedge_return_drawback(bt, perf, title):\n    \"\"\"\n    \u5bf9\u51b2\u4e4b\u540e\u7684\u7ec4\u5408\u51c0\u503c\u4ee5\u53ca\u56de\u64a4\n    \u8f93\u5165\uff1a\n        bt\uff1aquartz\u56de\u6d4b\u7ed3\u675f\u81ea\u52a8\u751f\u6210\u7684dict\n        title\uff1astr\n    \u8fd4\u56de\uff1a\n        ax\uff1amatplotlib figure \u5bf9\u8c61\n    \"\"\"\n    bt_quantile_ten = bt\n    data = bt_quantile_ten[[u'tradeDate',u'portfolio_value',u'benchmark_return']]\n    data['portfolio_return'] = data.portfolio_value/data.portfolio_value.shift(1) - 1.0\n    data['portfolio_return'].ix[0] = data['portfolio_value'].ix[0]/\t10000000.0 - 1.0\n    # \u8d85\u989d\u6536\u76ca\u7387\n    data['excess_return'] = data.portfolio_return - data.benchmark_return\n    data['excess'] = data.excess_return + 1.0\n    # \u7d2f\u8ba1\u8d85\u989d\u6536\u76ca\u7387\n    data['excess'] = data.excess.cumprod()\n\n    df_cum_rets = data['excess']\n    running_max = np.maximum.accumulate(df_cum_rets)\n    # \u56de\u64a4\u503c\n    underwater = -((running_max - df_cum_rets) / running_max)\n    underwater.index = data['tradeDate']\n    \n    # \u753b\u56fe\u663e\u793a\u5bf9\u51b2\u51c0\u503c\u4ee5\u53ca\u56de\u64a4\n    fig = plt.figure(figsize=(12, 5))\n    fig.set_tight_layout(True)\n    ax1 = fig.add_subplot(111)\n    ax2 = ax1.twinx()\n    x = range(len(underwater))\n    ax2.grid(False)\n    # ax1.set_ylim(-0.30, 0)\n    ax1.set_ylabel(u'\u56de\u64a4', fontproperties=font, fontsize=16)\n    ax1.fill_between(underwater.index, 0, np.array(underwater), color='#000066', alpha=1)\n    ax2.set_ylabel(u'\u51c0\u503c', fontproperties=font, fontsize=16)\n    ax2.plot(data['tradeDate'], data[['excess']], label='hedged(right)', color='r')\n    # ax2.set_ylim(bottom=0.9, top=7)\n    s = ax1.set_title(title, fontproperties=font, fontsize=16)\n    statistic_result = excess_statistic(data, perf, underwater)\n    return fig, statistic_result\n\n# \u7edf\u8ba1\u5bf9\u51b2\u540e\u7684\u6307\u6807\ndef excess_statistic(data, perf, underwater):\n    # \u5e74\u5316\u6536\u76ca\u7387\n    annual_return = (data['excess'].values[-1] - 1)*250/len(data)\n    # \u5e74\u5316\u6ce2\u52a8\u7387\n    annual_std = pow(250, 0.5)*data['excess_return'].std()\n    # \u4fe1\u606f\u6bd4\n    ir = annual_return/annual_std\n    # \u6700\u5927\u56de\u64a4\n    max_drawback = -1*min(underwater)\n    # \u7d2f\u8ba1\u6536\u76ca\u7387\n    accum_ret = data['excess'].values[-1]-1\n    # \u8fd4\u56de\n    return_df = pd.DataFrame()\n    return_df.loc[u'\u5e74\u5316\u6536\u76ca', 'group'] = annual_return\n    return_df.loc[u'\u5e74\u5316\u6ce2\u52a8\u7387', 'group'] = annual_std\n    return_df.loc[u'\u4fe1\u606f\u6bd4', 'group'] = ir\n    return_df.loc[u'\u6700\u5927\u56de\u64a4', 'group'] = max_drawback\n    return_df.loc[u'\u7d2f\u8ba1\u6536\u76ca', 'group'] = accum_ret\n    return return_df.round(4)\n\n\n# \u5bf9\u51b2\u6caa\u6df1300\u4e4b\u540e\u7684\u8868\u73b0\n_, rolling_hedge_perf= hedge_return_drawback(bt, perf, u\"xgboost rolling\u7ec4\u5408\u5bf9\u51b2\u6caa\u6df1300\")\nrolling_hedge_perf.columns=[u'rolling']\nrolling_hedge_perf", "language": "python", "metadata": {}, "outputs": [], "trusted": true}], "metadata": {}}]}