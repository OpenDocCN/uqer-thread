{"metadata": {"signature": "sha256:f30663866aea96f7aa0eda67c84323c47530cbeb6da1e77756baff01590f0b99"}, "nbformat": 3, "nbformat_minor": 0, "original_thread": "5afba89bb6fe2b010f16fefe", "worksheets": [{"cells": [{"cell_type": "markdown", "id": "F51317C160B34A309795EDF9B6E6E6E7", "metadata": {}, "source": "# \u5927\u7c7b\u8d44\u4ea7\u914d\u7f6e\uff1aBlack-Litterman\u6a21\u578b\u7684\u5b66\u4e60"}, {"cell_type": "markdown", "id": "880214AB1C5648F38B538583312A0D86", "metadata": {}, "source": "\u4e00\u3001Black-Litterman\u6a21\u578b\u6982\u8ff0\n---\n\n   Wealthfront\u3001Betterment\u5747\u4f7f\u7528Black-Litterman\u6a21\u578b,\u4e3a\u6295\u8d44\u8005\u5b9e\u73b0\u8d44\u4ea7\u7ec4\u5408\u914d\u7f6e\u3002\u8be5\u6a21\u578b\u6700\u65e9\u4e8e1990\u5e74,\u7531\u9ad8\u76db\u7684\u4e24\u4e2a\u4ea4\u6613\u5458Fischer Black\u548cRobert Litterman\u63d0\u51fa,\u968f\u540e\u53d1\u8868\u4e8e1992\u5e74\u3002\u6700\u521d\u8be5\u6a21\u578b\u88ab\u7528\u4e8e\u5168\u7403\u8d44\u672c\u5e02\u573a\u7684\u914d\u7f6e\u3002\n   \n Black-Litterman\u6a21\u578b\u662f\u57fa\u4e8eMPT\u57fa\u7840\u4e0a\u7684\u8d44\u4ea7\u914d\u7f6e\u7406\u8bba\u3002\u5176\u4e3b\u8981\u7684\u8d21\u732e\u662f\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7406\u8bba\u6846\u67b6\uff0c\u80fd\u591f\u5c06\u5e02\u573a\u5747\u8861\u6536\u76ca\u548c\u4e2a\u4eba\u89c2\u70b9\u6574\u5408\u5230\u4e00\u5757\uff0c\u7528\u4ee5\u91cd\u65b0\u4f30\u8ba1\u66f4\u53ef\u9760\u7684\u9884\u671f\u6536\u76ca\u7387\uff0c\u7136\u540e\u5c06\u9884\u671f\u6536\u76ca\u7387\u5e26\u5165MVO\uff0c\u5f97\u51fa\u6700\u4f18\u8d44\u4ea7\u914d\u7f6e\uff0c\u4f7f\u5f97\u4f18\u5316\u7ed3\u679c\u66f4\u52a0\u7a33\u5b9a\u548c\u51c6\u786e\u3002\n \n \n\u4e8c\u3001\u516c\u5f0f\n----\n---\n\ud835\udc38(\ud835\udc45)=[(\ud835\udf0f\ud835\udef4)^(\u22121)+\ud835\udc43^\ud835\udc47 \ud835\udefa^(\u22121) \ud835\udc43]^(\u22121) [(\ud835\udf0f\ud835\udef4)^(\u22121) \ud835\udf0b+\ud835\udc43^\ud835\udc47 \ud835\udefa^(\u22121) \ud835\udc5e]\n\n---\n \n\u4e09\u3001 \u5728\u5b9e\u8df5\u4e2d\u5e94\u7528Black-Litterman\u5e94\u7528\u8be5\u6a21\u578b\uff0c\u4e3b\u8981\u6709\u5982\u4e0b\u6b65\u9aa4\uff1a\n---\n\n1.\t\u6839\u636e\u5386\u53f2\u6570\u636e\u8ba1\u7b97\u51fa\u5386\u53f2\u6536\u76ca\u7387\u4e4b\u5747\u503c\u53ca\u534f\u65b9\u5dee\u77e9\u9635\n3.\t\u6c42\u51fa\u5148\u9a8c\u9884\u671f\u6536\u76ca\u4e4b\u671f\u671b\u503c\n4.\t\u878d\u5408\u6295\u8d44\u4eba\u7684\u4e2a\u4eba\u89c2\u70b9\n5.\t\u6839\u636e\u516c\u5f0f\u8ba1\u7b97\u51fa\u540e\u9a8c\u5206\u5e03\u4e4b\u671f\u671b\u503c\u3001\u534f\u65b9\u5dee\n6.\t\u6839\u636e\u540e\u9a8c\u6536\u76ca\u671f\u671b\u503c\u4e0e\u534f\u65b9\u5dee\u77e9\u9635\uff0c\u4ee3\u5165Markowitz\u6a21\u578b\u8fdb\u884c\u8d44\u4ea7\u914d\u7f6e\n\n"}, {"cell_type": "markdown", "id": "3052930B8DD44099AA380ABCC1903771", "metadata": {}, "source": "\u8bf4\u660e\n---\n\ud835\udf0b\uff1a\u5148\u9a8c\u9884\u671f\u6536\u76ca\u7387\u4e4b\u671f\u671b\u503c\n\u2022\t\u4e00\u822c\u6765\u8bf4\u4ee5\u5386\u53f2\u6536\u76ca\u7387\u5747\u503c\u4f5c\u4e3a\u5148\u9a8c\u9884\u671f\u6536\u76ca\u4e4b\u671f\u671b\u503c\n\u2022\t\u6839\u636e\u5e02\u573a\u73b0\u6709\u4ef7\u683c\u3001\u5e02\u573a\u7ec4\u5408\u53cd\u63a8\u51fa\u5e02\u573a\u9690\u542b\u7684\u5747\u8861\u6536\u76ca\u7387\u6765\u4f5c\u4e3a\u5148\u9a8c\u9884\u671f\u6536\u76ca\u4e4b\u671f\u671b\u503c\n\u2022\t\u6839\u636ecapm\u6a21\u578b\u4e2d\u7684alpha(\u5386\u53f2\u8d85\u989d\u6536\u76ca\u7387)\u6765\u4f30\u8ba1\u5148\u9a8c\u9884\u671f\u6536\u76ca\u4e4b\u671f\u671b\u503c\n"}, {"cell_type": "markdown", "id": "47C9540FFD6B436584B872A43934ABB2", "metadata": {}, "source": "\u4e0b\u9762\uff0c\u6211\u4eec\u5229\u7528\u6caa\u6df1300\u6307\u6570\u3001\u521b\u4e1a\u677f\u6307\u3001\u56fd\u503a\u6307\u6570\u3001\u4f01\u4e1a\u503a\u6307\u6570\u3001\u6052\u751f\u6307\u6570\u3001\u6807\u666e500\u6307\u6570\u3001\u539f\u6cb9\u6307\u6570\u3001\u9ec4\u91d1\u6307\u6570\u6784\u9020\u4e00\u4e2a\u5229\u7528B-L\u6a21\u578b\u7684\u7b80\u5355\u793a\u4f8b\u3002"}, {"cell_type": "code", "collapsed": false, "id": "F000A357CC504C97BD95E0ED5CB54DFB", "input": "#\u5f15\u5165\u9700\u8981\u7684python\u5e93\nimport numpy as np\nimport pandas as pd\nfrom cvxopt import matrix, solvers\nfrom scipy.stats.mstats import gmean\n\n\n#\u53d6\u51fa\u6df1300\u6307\u6570\u3001\u521b\u4e1a\u677f\u6307\u3001\u56fd\u503a\u6307\u6570\u3001\u4f01\u4e1a\u503a\u6307\u6570\u3001\u6052\u751f\u6307\u6570\u3001\u6807\u666e500\u6307\u6570\u3001\u539f\u6cb9\u6307\u6570\u3001\u9ec4\u91d1\u6307\u6570\u6570\u636e\uff0c\u5e76\u8fdb\u884c\u5408\u5e76\nstart = '20130501'\nend = '20180501'\nindices = ['000300', '399006', '000012','000013','HSI','SPX']\ndf = DataAPI.MktIdxdGet(ticker=indices, beginDate=start, endDate=end, field=\"tradeDate,ticker,closeIndex\")\ndf = df.pivot(index=\"tradeDate\", columns=\"ticker\", values=\"closeIndex\")\n#\u8bfb\u53d6\u539f\u6cb9\u548c\u9ec4\u91d1\u4ef7\u683c\uff0c \u6570\u636e\u662f\u81ea\u5df1\u4e0a\u4f20\u7684\u7f8e\u56fd\u539f\u6cb9\u548c\u9ec4\u91d1\u671f\u8d27\u8fde\u7eed\u5408\u7ea6\u4ef7\u683c\ntemp1=pd.read_excel('go.xls','Sheet1') \ntemp1=temp1.set_index('tradeDate')\ntemp1\ndf = df.merge(temp1,how='inner',left_index=True,right_index=True)\n\ndf.head()\n", "language": "python", "metadata": {}, "outputs": [], "trusted": true}, {"cell_type": "code", "collapsed": false, "id": "4E62A6D0240A49BB8B97A31403C0259D", "input": "#\u8ba1\u7b97\u5404\u6307\u6570\u6536\u76ca\u7387\u6570\u636e\nindices = ['000300', '399006', '000012','000013','HSI','SPX','GOLD','OIL']\nfor index in indices:\n    df[index] = df[index] / df[index].shift() - 1.\nreturn_table = df.dropna()", "language": "python", "metadata": {}, "outputs": [], "trusted": true}, {"cell_type": "code", "collapsed": false, "id": "38F1A7498E474B268D4C2E5D9B78BA71", "input": "return_table.head()", "language": "python", "metadata": {}, "outputs": [], "trusted": true}, {"cell_type": "code", "collapsed": false, "id": "5CC66BA6FB8D468988C2768636E96EFA", "input": "#\u5efa\u7acb\u51fd\u6570\u8ba1\u7b97\u5e74\u5316\u6536\u76ca\u7387\u3001\u5e74\u5316\u6807\u51c6\u5dee\u3001\u76f8\u5173\u7cfb\u6570\u77e9\u9635\n\ndef describe(return_table, is_print=True):\n    \"\"\"\n    \u8f93\u51fa\u6536\u76ca\u7387\u77e9\u9635\u7684\u63cf\u8ff0\u6027\u7edf\u8ba1\u91cf\uff0c\u5305\u62ec\uff1a\n        \u5e74\u5316\u6536\u76ca\u7387\n        \u5e74\u5316\u6807\u51c6\u5dee\n        \u76f8\u5173\u7cfb\u6570\u77e9\u9635\n    \n    Args:\n        return_table (DataFrame): \u6536\u76ca\u7387\u77e9\u9635\uff0c\u5217\u4e3a\u8d44\u4ea7\uff0c\u503c\u4e3a\u6309\u65e5\u671f\u5347\u5e8f\u6392\u5217\u7684\u6536\u76ca\u7387\n        is_print (bool): \u662f\u5426\u76f4\u63a5\u8f93\u51fa\n\n    Returns:\n        dict: \u63cf\u8ff0\u6027\u7edf\u8ba1\u91cf\u5b57\u5178\uff0c\u952e\u4e3a\"annualized_return\", \"annualized_volatility\", \"covariance_matrix\"\u548c\"coefficient_matrix\"\n\n    Examples:\n        >> describe(return_table)\n        >> describe(return_table, is_print=True)\n    \"\"\"\n    \n    output = {}\n    output['annualized_return'] = pd.DataFrame(dict(zip(return_table.columns, gmean(return_table+1.)**252 - 1.)), index=[0], columns=return_table.columns)\n    output['annualized_volatility'] = pd.DataFrame(return_table.std() * np.sqrt(250)).T\n    output['covariance_matrix'] = return_table.cov() * 250.\n    output['coefficient_matrix'] = return_table.corr()\n        \n    if is_print:\n        for key, val in output.iteritems():\n            print \"{}:\\n{}\\n\".format(key, val)\n    \n    return output\n", "language": "python", "metadata": {}, "outputs": [], "trusted": true}, {"cell_type": "code", "collapsed": false, "id": "042DA40710954E128E57F7271F8C9460", "input": "output=describe(return_table, is_print=True)", "language": "python", "metadata": {}, "outputs": [], "trusted": true}, {"cell_type": "code", "collapsed": false, "id": "164D898B260348BB8122173F868A054D", "input": "#\u5404\u8d44\u4ea7\u8fd1\u4e24\u5e74\u7684\u6536\u76ca\noutput['annualized_return']", "language": "python", "metadata": {}, "outputs": [], "trusted": true}, {"cell_type": "markdown", "id": "1CDA031FB4674E6984FF8B377AB7224B", "metadata": {}, "source": "\u56fd\u503a\u6307\u6570[000012]\u6307\u6570\uff0c\u4f01\u503a\u6307\u6570[000013]\u6307\u6570\uff0c000300\u6caa\u6df1300\u6307\u6570\uff0c\u4e2d\u8bc1500[000905]\u6307\u6570\uff0c\u521b\u4e1a\u677f\u6307[399006]\u6307\u6570\u5b9e\u65f6\u884c\u60c5"}, {"cell_type": "code", "collapsed": false, "id": "13B79B291BB7413A8EDD6AE3EF7485A7", "input": "# - \u751f\u6210\u89c2\u70b9\u77e9\u9635P\u3001Q\u3001Omega\uff0c\u6839\u636e\u6211\u4eec\u5bf9\u80a1\u5e02\u3001\u503a\u5e02\u3001\u9ec4\u91d1\u3001\u539f\u6cb9\u7b49\u5927\u7c7b\u8d44\u4ea7\u914d\u7f6e\u7684\u672a\u6765\u8d70\u52bf\u7684\u5224\u65ad\uff0c\u6211\u4eec\u7ed9\u51fa\u4e0b\u97623\u4e2a\u89c2\u70b9\uff1a\n# - \u89c2\u70b91\uff1a \u521b\u4e1a\u677f\u7684\u6536\u76ca\u4f4e\u4e8e\u6caa\u6df1300\u6536\u76ca2%(\u76f8\u6bd4\u539f\u6765\u5dee\u8ddd\u7684\u8fd118%\u663e\u8457\u4e0b\u8c03)\n# - \u89c2\u70b92\uff1a \u9ec4\u91d1\u6536\u76ca\u4e0a\u8c03\u523010%\uff0c\uff08\u76f8\u5bf9\u539f\u67655%\u5dee\u8ddd\u5fae\u4e0a\u8c03\uff09\n# - \u89c2\u70b93\uff1a\u539f\u6cb9\u6536\u76ca5%\uff08\u76f8\u6bd4\u539f\u6765\u8fd160%\u663e\u8457\u4e0b\u8c03\uff09\n# - \u89c2\u70b94\uff1a \u6052\u751f\u6307\u6570\u6536\u76ca\u4e0b\u8c03\u523010%\uff0c\n# - \u89c2\u70b95\uff1a\u6807\u666e\u6536\u76ca\u4e0b\u8c03\u52305%\n\n\noutput = describe(return_table, is_print=False)\n\ncovariance_matrix = output['covariance_matrix']\n\nexpected_return = output['annualized_return'].iloc[0, :]\n\ntau = 0.05\n\nP = np.array([[1,0,0,-1,0,0,0,0],[0,0,0,0,0,0,1,0],[0,0,0,0,0,0,0,1],[0,0,0,0,1,0,0,0],[0,0,0,0,0,1,0,0]])\n\nprint \"P:\",P\n\nQ = np.array([0.02,0.1,0.05,0.1,0.05])\n\nprint \"Q:\",Q\n\nOmega = tau*(P.dot(covariance_matrix).dot(P.transpose()))\n\nOmega = np.diag(np.diag(Omega,k=0))\n\nprint \"Omega:\",Omega", "language": "python", "metadata": {}, "outputs": [], "trusted": true}, {"cell_type": "code", "collapsed": false, "id": "5055F0FDE90D441B992F19CDF42DA617", "input": "# \u8ba1\u7b97\u6700\u5c0f\u65b9\u5dee\u7ec4\u5408\n\ndef get_BL_minimum_variance_portfolio(return_table,tau=0.05,P=None,Q=None,Omega=None, allow_short=False, show_details=True):\n    \"\"\"\n    \u8ba1\u7b97\u6700\u5c0f\u65b9\u5dee\u7ec4\u5408\n    \n    Args:\n        return_table (DataFrame): \u6536\u76ca\u7387\u77e9\u9635\uff0c\u5217\u4e3a\u8d44\u4ea7\uff0c\u503c\u4e3a\u6309\u65e5\u671f\u5347\u5e8f\u6392\u5217\u7684\u6536\u76ca\u7387\n        allow_short (bool): \u662f\u5426\u5141\u8bb8\u5356\u7a7a\n        show_details (bool): \u662f\u5426\u663e\u793a\u7ec6\u8282\n        P(np.array): \u89c2\u70b9\u77e9\u9635\n        Q(np.array): \u89c2\u70b9\u6536\u76ca\u77e9\u9635\n        Omega(np.array): \u89c2\u70b9\u7f6e\u4fe1\u5ea6\u77e9\u9635\n        tau(float): \u4e3a\u5747\u8861\u6536\u76ca\u65b9\u5dee\u7684\u523b\u5ea6\u503c\uff0c\u4f53\u73b0\u4e86\u5bf9\u4e2a\u4eba\u89c2\u70b9\u5728\u603b\u4f53\u4f30\u8ba1\u4e2d\u7684\u6743\u91cd\n\n    Returns:\n        dict: \u6700\u5c0f\u65b9\u5dee\u7ec4\u5408\u7684\u6743\u91cd\u4fe1\u606f\uff0c\u952e\u4e3a\u8d44\u4ea7\u540d\uff0c\u503c\u4e3a\u6743\u91cd\n    \"\"\"\n    \n    assets = return_table.columns\n    n_asset = len(assets)\n    if n_asset < 2:\n        weights = np.array([1.])\n        weights_dict = {assets[0]: 1.}\n    else:\n        output = describe(return_table, is_print=False)\n        covmat =(output['covariance_matrix'])\n        expected_return = output['annualized_return'].iloc[0, :]\n    \n        # \u6c42\u89e3\u8c03\u6574\u540e\u7684\u671f\u671b\u6536\u76ca\u3001\u65b9\u5dee\n        adjustedReturn = expected_return + tau*covmat.dot(P.transpose()).dot(np.linalg.inv(Omega+tau*(P.dot(covmat).dot(P.transpose())))).dot(Q - P.dot(expected_return))\n        right = (tau)*covmat.dot(P.transpose()).dot(np.linalg.inv(Omega+P.dot(covmat).dot(P.transpose()))).dot(P.dot(tau*covmat))\n        right = right.transpose()\n        right = right.set_index(expected_return.index)\n        M = tau*covmat - right\n        Sigma_p = covmat + M\n        adjustedReturn = adjustedReturn.as_matrix()\n        Sigma_p = matrix(Sigma_p.as_matrix())\n\n        P = 2 * Sigma_p\n        q = matrix(np.zeros(n_asset))\n\n        if allow_short:\n            G = matrix(0., (n_asset, n_asset))\n        else:\n            G = matrix(np.diag(-1 * np.ones(n_asset)))\n        \n        h = matrix(0., (n_asset, 1))\n        A = matrix(np.ones(n_asset)).T\n        b = matrix([1.0])\n        solvers.options['show_progress'] = False\n        sol = solvers.qp(P, q, G, h, A, b)\n        weights = np.array(sol['x'].T)[0]\n        weights_dict = dict(zip(assets, weights))\n\n    r = np.dot(weights, output['annualized_return'].iloc[0, :].as_matrix())\n    v = np.sqrt(np.dot(np.dot(weights, Sigma_p), weights.T))\n\n    if show_details:\n        print \"\"\"\nMinimum Variance Portfolio:\n    Short Allowed: {}\n    Portfolio Return: {}\n    Portfolio Volatility: {}\n    Portfolio Weights: {}\n\"\"\".format(allow_short, r, v, \"\\n\\t{}\".format(\"\\n\\t\".join(\"{}: {:.1%}\".format(k, v) for k, v in weights_dict.items()))).strip()\n    \n    return weights_dict", "language": "python", "metadata": {}, "outputs": [], "trusted": true}, {"cell_type": "code", "collapsed": false, "id": "0709EF00C2F34FCF926FE65522630B22", "input": "aa=get_BL_minimum_variance_portfolio(return_table,tau=0.05,P=P,Q=Q,Omega=Omega, allow_short=False, show_details=True)", "language": "python", "metadata": {}, "outputs": [], "trusted": true}, {"cell_type": "code", "collapsed": false, "id": "EC90DE5604064727BFA4E7B3E4ACB512", "input": "pd.DataFrame.from_dict(aa,orient='index').T", "language": "python", "metadata": {}, "outputs": [], "trusted": true}, {"cell_type": "code", "collapsed": false, "id": "1D3C1CCFB55F459A8ED65B8F788157AB", "input": "#\u8ba1\u7b97\u6700\u5927\u6548\u7528\u7ec4\u5408\uff0c\u76ee\u6807\u51fd\u6570\u4e3a\uff1a\u671f\u671b\u5e74\u5316\u6536\u76ca\u7387 - \u98ce\u9669\u538c\u6076\u7cfb\u6570 * \u671f\u671b\u5e74\u5316\u65b9\u5dee\uff0c\u98ce\u9669\u538c\u6076\u7cfb\u6570\uff0c\u8d8a\u5927\u8868\u793a\u5bf9\u98ce\u9669\u8d8a\u538c\u6076\uff0c\u9ed8\u8ba4\u4e3a3.0\n\ndef get_BL_maximum_utility_portfolio(return_table,tau=0.05,P=None,Q=None,Omega=None, risk_aversion=3., allow_short=False, show_details=True):\n    \"\"\"\n    \u8ba1\u7b97\u6700\u5927\u6548\u7528\u7ec4\u5408\uff0c\u76ee\u6807\u51fd\u6570\u4e3a\uff1a\u671f\u671b\u5e74\u5316\u6536\u76ca\u7387 - \u98ce\u9669\u538c\u6076\u7cfb\u6570 * \u671f\u671b\u5e74\u5316\u65b9\u5dee\n    \n    Args:0\n        return_table (DataFrame): \u6536\u76ca\u7387\u77e9\u9635\uff0c\u5217\u4e3a\u8d44\u4ea7\uff0c\u503c\u4e3a\u6309\u65e5\u671f\u5347\u5e8f\u6392\u5217\u7684\u6536\u76ca\u7387\n        risk_aversion (float): \u98ce\u9669\u538c\u6076\u7cfb\u6570\uff0c\u8d8a\u5927\u8868\u793a\u5bf9\u98ce\u9669\u8d8a\u538c\u6076\uff0c\u9ed8\u8ba4\u4e3a3.0\n        allow_short (bool): \u662f\u5426\u5141\u8bb8\u5356\u7a7a\n        show_details (bool): \u662f\u5426\u663e\u793a\u7ec6\u8282\n        P(np.array): \u89c2\u70b9\u77e9\u9635\n        Q(np.array): \u89c2\u70b9\u6536\u76ca\u77e9\u9635\n        Omega(np.array): \u89c2\u70b9\u7f6e\u4fe1\u5ea6\u77e9\u9635\n        tau(float): \u4e3a\u5747\u8861\u6536\u76ca\u65b9\u5dee\u7684\u523b\u5ea6\u503c\uff0c\u4f53\u73b0\u4e86\u5bf9\u4e2a\u4eba\u89c2\u70b9\u5728\u603b\u4f53\u4f30\u8ba1\u4e2d\u7684\u6743\u91cd\n\n    Returns:\n        dict: \u6700\u5c0f\u65b9\u5dee\u7ec4\u5408\u7684\u6743\u91cd\u4fe1\u606f\uff0c\u952e\u4e3a\u8d44\u4ea7\u540d\uff0c\u503c\u4e3a\u6743\u91cd\n    \"\"\"\n    \n    import numpy as np\n    from cvxopt import matrix, solvers\n\n    assets = return_table.columns\n    n_asset = len(assets)\n    if n_asset < 2:\n        weights = np.array([1.])\n        weights_dict = {assets[0]: 1.}\n    else:\n        output = describe(return_table, is_print=False)\n        covmat =(output['covariance_matrix'])\n        expected_return = output['annualized_return'].iloc[0, :]\n    \n        # \u6c42\u89e3\u8c03\u6574\u540e\u7684\u671f\u671b\u6536\u76ca\u3001\u65b9\u5dee\n        adjustedReturn = expected_return + tau*covmat.dot(P.transpose()).dot(np.linalg.inv(Omega+tau*(P.dot(covmat).dot(P.transpose())))).dot(Q - P.dot(expected_return))\n        right = (tau)*covmat.dot(P.transpose()).dot(np.linalg.inv(Omega+P.dot(covmat).dot(P.transpose()))).dot(P.dot(tau*covmat))\n        right = right.transpose()\n        right = right.set_index(expected_return.index)\n        M = tau*covmat - right\n        Sigma_p = covmat + M\n        adjustedReturn = adjustedReturn.as_matrix()\n        Sigma_p = matrix(Sigma_p.as_matrix())\n\n        if abs(risk_aversion) < 0.01:\n            max_ret = max(adjustedReturn)\n            weights = np.array([1. if adjustedReturn[i] == max_ret else 0. for i in range(n_asset)])\n            weights_dict = {asset: weights[i] for i, asset in enumerate(assets)}\n        else:\n            P = risk_aversion * Sigma_p\n            q = matrix(-adjustedReturn.T)\n\n            if allow_short:\n                G = matrix(0., (n_asset, n_asset))\n            else:\n                G = matrix(np.diag(-1 * np.ones(n_asset)))\n\n            h = matrix(0., (n_asset, 1))\n            A = matrix(np.ones(n_asset)).T\n            b = matrix([1.0])\n            solvers.options['show_progress'] = False\n            sol = solvers.qp(P, q, G, h, A, b)\n            weights = np.array(sol['x'].T)[0]\n            weights_dict = dict(zip(assets, weights))\n\n    r = np.dot(weights, output['annualized_return'].iloc[0, :].as_matrix())\n    v = np.sqrt(np.dot(np.dot(weights, Sigma_p), weights.T))\n    \n    if show_details:\n        print \"\"\"\nMaximum Utility Portfolio:\n    Risk Aversion: {}\n    Short Allowed: {}\n    Portfolio Return: {}\n    Portfolio Volatility: {}\n    Portfolio Weights: {}\n\"\"\".format(risk_aversion, allow_short, r, v, \"\\n\\t{}\".format(\"\\n\\t\".join(\"{}: {:.1%}\".format(k, v) for k, v in weights_dict.items()))).strip()\n    \n    return weights_dict\n\ndef get_maximum_sharpe_portfolio(return_table, riskfree_rate=0.,tau=0.05,P=None,Q=None,Omega=None,allow_short=False, show_details=True):\n    \"\"\"\n    \u8ba1\u7b97\u6700\u5927\u6548\u7528\u7ec4\u5408\uff0c\u76ee\u6807\u51fd\u6570\u4e3a\uff1a\uff08\u671f\u671b\u5e74\u5316\u6536\u76ca\u7387 - \u65e0\u98ce\u9669\u6536\u76ca\u7387\uff09/ \u671f\u671b\u5e74\u5316\u65b9\u5dee\n    \n    Args:\n        return_table (DataFrame): \u6536\u76ca\u7387\u77e9\u9635\uff0c\u5217\u4e3a\u8d44\u4ea7\uff0c\u503c\u4e3a\u6309\u65e5\u671f\u5347\u5e8f\u6392\u5217\u7684\u6536\u76ca\u7387\n        riskfree_rate (float): \u65e0\u98ce\u9669\u6536\u76ca\u7387\n        allow_short (bool): \u662f\u5426\u5141\u8bb8\u5356\u7a7a\n        show_details (bool): \u662f\u5426\u663e\u793a\u7ec6\u8282\n        P(np.array): \u89c2\u70b9\u77e9\u9635\n        Q(np.array): \u89c2\u70b9\u6536\u76ca\u77e9\u9635\n        Omega(np.array): \u89c2\u70b9\u7f6e\u4fe1\u5ea6\u77e9\u9635\n        tau(float): \u4e3a\u5747\u8861\u6536\u76ca\u65b9\u5dee\u7684\u523b\u5ea6\u503c\uff0c\u4f53\u73b0\u4e86\u5bf9\u4e2a\u4eba\u89c2\u70b9\u5728\u603b\u4f53\u4f30\u8ba1\u4e2d\u7684\u6743\u91cd\n\n    Returns:\n        dict: \u6700\u5c0f\u65b9\u5dee\u7ec4\u5408\u7684\u6743\u91cd\u4fe1\u606f\uff0c\u952e\u4e3a\u8d44\u4ea7\u540d\uff0c\u503c\u4e3a\u6743\u91cd\n    \"\"\"\n    \n    import numpy as np\n    from cvxopt import matrix, solvers\n\n    assets = return_table.columns\n    n_asset = len(assets)\n    if n_asset < 2:\n        output = describe(return_table, is_print=False)\n        r = output['annualized_return'].iat[0, 0]\n        v = output['annualized_volatility'].iat[0, 0]\n        weights_dict = {assets[0]: 1.}\n    else:\n        efs = get_BL_efficient_frontier(return_table,tau,P=P,Q=Q,Omega=Omega,allow_short=allow_short, n_samples=100)\n        i_star = max(range(100), key=lambda x: (efs.at[x, \"returns\"] - riskfree_rate) / efs.at[x, \"risks\"])\n        r = efs.at[i_star, \"returns\"]\n        v = efs.at[i_star, \"risks\"]\n        weights_dict = efs.at[i_star, \"weights\"]\n\n    s = (r - riskfree_rate) / v\n    \n    if show_details:\n        print \"\"\"\nMaximum Sharpe Portfolio:\n    Riskfree Rate: {}\n    Short Allowed: {}\n    Portfolio Return: {}\n    Portfolio Volatility: {}\n    Portfolio Sharpe: {}\n    Portfolio Weights: {}\n\"\"\".format(riskfree_rate, allow_short, r, v, s, \"\\n\\t{}\".format(\"\\n\\t\".join(\"{}: {:.1%}\".format(k, v) for k, v in weights_dict.items()))).strip()\n    \n    return weights_dict\n", "language": "python", "metadata": {}, "outputs": [], "trusted": true}, {"cell_type": "code", "collapsed": false, "id": "16D749A85E4C4A7A8B7E813C72C38CE4", "input": "# \u8ba1\u7b97\u6700\u5927\u6548\u7528\u7ec4\u5408\uff0c\u76ee\u6807\u51fd\u6570\u4e3a\uff1a\u671f\u671b\u5e74\u5316\u6536\u76ca\u7387 - \u98ce\u9669\u538c\u6076\u7cfb\u6570 * \u671f\u671b\u5e74\u5316\u65b9\u5dee,\u98ce\u9669\u7cfb\u6570\u4e3a\u9ed8\u8ba4\u503c3\u65f6\u7684\u7ec4\u5408\u6743\u91cd\nbb=get_BL_maximum_utility_portfolio(return_table,tau=0.4,P=P,Q=Q,Omega=Omega, risk_aversion=3., allow_short=False, show_details=True)", "language": "python", "metadata": {}, "outputs": [], "trusted": true}, {"cell_type": "code", "collapsed": false, "id": "C9787EF710AA40608B6AF681C392E675", "input": "# \u8ba1\u7b97\u6700\u5927\u6548\u7528\u7ec4\u5408\uff0c\u76ee\u6807\u51fd\u6570\u4e3a\uff1a\u671f\u671b\u5e74\u5316\u6536\u76ca\u7387 - \u98ce\u9669\u538c\u6076\u7cfb\u6570 * \u671f\u671b\u5e74\u5316\u65b9\u5dee,\u98ce\u9669\u7cfb\u6570\u4e3a\u9ed8\u8ba4\u503c\u65f6\u7684\u7ec4\u5408\u6743\u91cd\nbb=get_BL_maximum_utility_portfolio(return_table,tau=0.2,P=P,Q=Q,Omega=Omega, risk_aversion=3., allow_short=False, show_details=True)", "language": "python", "metadata": {}, "outputs": [], "trusted": true}, {"cell_type": "code", "collapsed": false, "id": "71AC391094164B739CBE86559B36268B", "input": "#,  \u8ba1\u7b97\u6700\u5927\u6548\u7528\u7ec4\u5408\uff0c\u76ee\u6807\u51fd\u6570\u4e3a\uff1a\u671f\u671b\u5e74\u5316\u6536\u76ca\u7387 - \u98ce\u9669\u538c\u6076\u7cfb\u6570 * \u671f\u671b\u5e74\u5316\u65b9\u5dee\u98ce\u9669\u7cfb\u6570\u4e3a1\u65f6\u7684\u7ec4\u5408\u6743\u91cd\npp=get_BL_maximum_utility_portfolio(return_table,tau=0.05,P=P,Q=Q,Omega=Omega, risk_aversion=1, allow_short=False, show_details=True)", "language": "python", "metadata": {}, "outputs": [], "trusted": true}, {"cell_type": "code", "collapsed": false, "id": "501E2CE159814C2AA88523972457A6DD", "input": "pd.DataFrame.from_dict(pp,orient='index').T", "language": "python", "metadata": {}, "outputs": [], "trusted": true}, {"cell_type": "code", "collapsed": false, "id": "E789C6A0A41D4E688272D558DE784E33", "input": "#  \u8ba1\u7b97\u6700\u5927\u6548\u7528\u7ec4\u5408\uff0c\u76ee\u6807\u51fd\u6570\u4e3a\uff1a\u671f\u671b\u5e74\u5316\u6536\u76ca\u7387 - \u98ce\u9669\u538c\u6076\u7cfb\u6570 * \u671f\u671b\u5e74\u5316\u65b9\u5dee,\u8ba1\u7b97\u98ce\u9669\u7cfb\u6570\u4e3a50\u65f6\u7684\u7ec4\u5408\u6743\u91cd\nbb=get_BL_maximum_utility_portfolio(return_table,tau=0.1,P=P,Q=Q,Omega=Omega, risk_aversion=50, allow_short=False, show_details=True)", "language": "python", "metadata": {}, "outputs": [], "trusted": true}, {"cell_type": "code", "collapsed": false, "id": "F77700FAD47942C089874C70DA75B37D", "input": "##\u8ba1\u7b97\u6700\u5927\u6548\u7528\u7ec4\u5408\uff0c\u76ee\u6807\u51fd\u6570\u4e3a\uff1a\uff08\u671f\u671b\u5e74\u5316\u6536\u76ca\u7387 - \u65e0\u98ce\u9669\u6536\u76ca\u7387\uff09/ \u671f\u671b\u5e74\u5316\u65b9\u5dee,\n\nget_maximum_sharpe_portfolio(return_table, riskfree_rate=0.,tau=0.05,P=P,Q=Q,Omega=Omega,allow_short=True, show_details=True)", "language": "python", "metadata": {}, "outputs": [], "trusted": true}, {"cell_type": "code", "collapsed": false, "id": "05715ADEB91B45B79BFD81AE42F99DAC", "input": "def get_BL_efficient_frontier(return_table,tau=0.05,P=None,Q=None,Omega=None,allow_short=False, n_samples=25):\n    \"\"\"\n    \u8ba1\u7b97Efficient Frontier\n    \n    Args:\n        return_table (DataFrame): \u6536\u76ca\u7387\u77e9\u9635\uff0c\u5217\u4e3a\u8d44\u4ea7\uff0c\u503c\u4e3a\u6309\u65e5\u671f\u5347\u5e8f\u6392\u5217\u7684\u6536\u76ca\u7387\n        n_samples (int): \u7528\u4e8e\u8ba1\u7b97Efficient Frontier\u7684\u91c7\u6837\u70b9\u6570\u91cf\n        P(np.array): \u89c2\u70b9\u77e9\u9635\n        Q(np.array): \u89c2\u70b9\u6536\u76ca\u77e9\u9635\n        Omega(np.array): \u89c2\u70b9\u7f6e\u4fe1\u5ea6\u77e9\u9635\n        tau(float): \u4e3a\u5747\u8861\u6536\u76ca\u65b9\u5dee\u7684\u523b\u5ea6\u503c\uff0c\u4f53\u73b0\u4e86\u5bf9\u4e2a\u4eba\u89c2\u70b9\u5728\u603b\u4f53\u4f30\u8ba1\u4e2d\u7684\u6743\u91cd\n\n    Returns:\n        DataFrame: Efficient Frontier\u7684\u7ed3\u679c\uff0c\u5217\u4e3a\"returns\", \"risks\", \"weights\"\n    \"\"\"\n    \n    import numpy as np\n    import pandas as pd\n    from cvxopt import matrix, solvers\n    \n    assets = return_table.columns\n    n_asset = len(assets)\n    if n_asset < 2:\n        raise ValueError(\"There must be at least 2 assets to calculate the efficient frontier!\")\n\n    output = describe(return_table, is_print=False)\n    covmat =(output['covariance_matrix'])\n    expected_return = output['annualized_return'].iloc[0, :]\n    \n    # \u6c42\u89e3\u8c03\u6574\u540e\u7684\u671f\u671b\u6536\u76ca\u3001\u65b9\u5dee\n    adjustedReturn = expected_return + tau*covmat.dot(P.transpose()).dot(np.linalg.inv(Omega+tau*(P.dot(covmat).dot(P.transpose())))).dot(Q - P.dot(expected_return))\n    right = (tau)*covmat.dot(P.transpose()).dot(np.linalg.inv(Omega+P.dot(covmat).dot(P.transpose()))).dot(P.dot(tau*covmat))\n    right = right.transpose()\n    right = right.set_index(expected_return.index)\n    M = tau*covmat - right\n    Sigma_p = covmat + M\n    adjustedReturn = adjustedReturn.as_matrix()\n    Sigma_p = matrix(Sigma_p.as_matrix())\n\t\n    risks, returns, weights = [], [], []\n    for level_return in np.linspace(min(adjustedReturn), max(adjustedReturn), n_samples):\n        P = 2 * Sigma_p\n        q = matrix(np.zeros(n_asset))\n        \n        if allow_short:\n            G = matrix(0., (n_asset, n_asset))\n        else:\n            G = matrix(np.diag(-1 * np.ones(n_asset)))\n        \n        h = matrix(0., (n_asset, 1))    \n        A = matrix(np.row_stack((np.ones(n_asset), adjustedReturn)))\n        b = matrix([1.0, level_return])\n        solvers.options['show_progress'] = False\n        sol = solvers.qp(P, q, G, h, A, b)\n        risks.append(np.sqrt(sol['primal objective']))\n        returns.append(level_return)\n        weights.append(dict(zip(assets, list(sol['x'].T))))\n    \n    output = {\"returns\": returns,\n              \"risks\": risks,\n              \"weights\": weights}\n    output = pd.DataFrame(output)\n    return output\n\ndef draw_efficient_frontier(effcient_frontier_output):\n    \"\"\"\n    \u7ed8\u51faEfficient Frontier\n    \n    Args:\n        effcient_frontier_output: Efficient Frontier\u7684\u8ba1\u7b97\u7ed3\u679c\uff0c\u5373get_efficient_frontier\u7684\u8f93\u51fa\n    \"\"\"\n\n    import seaborn\n    from matplotlib import pyplot as plt\n\n    fig = plt.figure(figsize=(7, 4))\n    ax = fig.add_subplot(111)\n    ax.plot(effcient_frontier_output['risks'], effcient_frontier_output['returns'])\n    ax.set_title('Efficient Frontier', fontsize=14)\n    ax.set_xlabel('Standard Deviation', fontsize=12)\n    ax.set_ylabel('Expected Return', fontsize=12)\n    ax.tick_params(labelsize=12)\n    plt.show()\n", "language": "python", "metadata": {}, "outputs": [], "trusted": true}, {"cell_type": "code", "collapsed": false, "id": "D76316749F28485888B568AA7C78A813", "input": "efficient_frontier = get_BL_efficient_frontier(return_table,tau,P=P,Q=Q,Omega=Omega,allow_short=False, n_samples=200)\ndraw_efficient_frontier(efficient_frontier)\nefficient_frontier.tail()", "language": "python", "metadata": {}, "outputs": [{"ename": "NameError", "evalue": "name 'return_table' is not defined", "output_type": "pyerr", "traceback": ["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)", "\u001b[1;32m<mercury-input-9-D76316749F28485888B568AA7C78A813>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0m_register_showtb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[0m_pdb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_Pdb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[0m_pdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[0mefficient_frontier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_BL_efficient_frontier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreturn_table\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtau\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mOmega\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mOmega\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mallow_short\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdraw_efficient_frontier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mefficient_frontier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mefficient_frontier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", "\u001b[1;31mNameError\u001b[0m: name 'return_table' is not defined"]}], "trusted": true}, {"cell_type": "code", "collapsed": false, "id": "C94FFBD3C8B34DAF8E8BE817E6F3C845", "input": "tt=efficient_frontier['weights']\ntt.tail()", "language": "python", "metadata": {}, "outputs": [{"ename": "NameError", "evalue": "name 'efficient_frontier' is not defined", "output_type": "pyerr", "traceback": ["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)", "\u001b[1;32m<mercury-input-5-C94FFBD3C8B34DAF8E8BE817E6F3C845>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mefficient_frontier\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'weights'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", "\u001b[1;31mNameError\u001b[0m: name 'efficient_frontier' is not defined"]}], "trusted": true}, {"cell_type": "code", "collapsed": false, "id": "6028C324D654463D86D5911776F0A9B2", "input": "uu=efficient_frontier['weights'][0]\nuu", "language": "python", "metadata": {}, "outputs": [], "trusted": true}, {"cell_type": "code", "collapsed": false, "id": "846B5A0D2B20409180302AB103583104", "input": "for i in range(10):\n    \n    uu=efficient_frontier['weights'][i]\n    ii=pd.DataFrame.from_dict(uu,orient='index').T\n    jj=df.append(ii)\nwt=jj.dropna()\nwt.tail(10)\n    ", "language": "python", "metadata": {}, "outputs": [], "trusted": true}, {"cell_type": "markdown", "id": "1B6C097F55E640D49222A10B498BBB4B", "metadata": {}, "source": "\u4ee3\u7801\u4fee\u6539\u4e4b\u300aPython\u4e0e\u91cf\u5316\u6295\u8d44\uff1a\u4ece\u57fa\u7840\u5230\u5b9e\u6218\u300b"}], "metadata": {}}]}