{"metadata": {"signature": "sha256:1d1ca688abe10a16cd73e4a272806f25659693dba3915d6b20f4ad88d47ea0db"}, "nbformat": 3, "nbformat_minor": 0, "worksheets": [{"cells": [{"cell_type": "markdown", "id": "095FF7C5D5F64E15AC987C4315A9DCE6", "metadata": {}, "source": "# 7.\u975e\u7ebf\u6027\u56de\u5f52-\u673a\u5668\u5b66\u4e60\u5165\u95e8"}, {"cell_type": "code", "collapsed": false, "id": "F9B68F5196D943988C188C12859185F2", "input": "import numpy as np\nimport random\n\n#\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\ndef gradientDescent(x, y, theta, alpha, m, numIterations):\n    xTrans = x.transpose()\n    for i in range(0, numIterations):\n        hypothesis = np.dot(x, theta)\n        loss = hypothesis - y\n        cost = np.sum(loss ** 2) / (2 * m)\n        # print(\"Iteration %d | Cost: %f\" % (i, cost))\n        gradient = np.dot(xTrans, loss) / m\n        # \u66f4\u65b0theta\u503c\n        theta = theta - alpha * gradient\n    return theta\n\n#\u521b\u5efa\u6570\u636e\ndef genData(numPoints, bias, variance):     \n    x = np.zeros(shape=(numPoints, 2))\n    y = np.zeros(shape=numPoints)\n    \n    for i in range(0, numPoints):\n        x[i][0] = 1\n        x[i][1] = i\n       \n        y[i] = (i + bias) + random.uniform(0, 1) * variance\n    return x, y\n\n# gen 100 points with a bias of 25 and 10 variance as a bit of noise\nx, y = genData(100, 25, 10)\n# print \"x\",x\n# print 'y',y\nm, n = np.shape(x)\nn_y = np.shape(y)\n# print 'x_shape:',str(m),str(n)\n# print 'y_shape:',n_y\nnumIterations= 100000\nalpha = 0.0005\ntheta = np.ones(n)\ntheta = gradientDescent(x, y, theta, alpha, m, numIterations)\nprint(theta)", "language": "python", "metadata": {}, "outputs": [{"output_type": "stream", "stream": "stdout", "text": "x_shape:"}, {"output_type": "stream", "stream": "stdout", "text": " 100 2\ny_shape: (100,)\n[ 29.86570177   0.99866346]"}, {"output_type": "stream", "stream": "stdout", "text": "\n"}], "trusted": true}], "metadata": {}}]}