{"metadata": {"signature": "sha256:41b5f5e663af612be02270b708f0897a006a2bd6008b72f3a349d69ae6699f9c"}, "nbformat": 3, "nbformat_minor": 0, "original_thread": "55263359f9f06c8f3390457b", "worksheets": [{"cells": [{"cell_type": "markdown", "id": "6F95CED9DC6148118C28C1196124A4EE", "metadata": {}, "source": "# "}, {"cell_type": "markdown", "id": "6E51D7A02B46480A916A089C09D097A7", "metadata": {}, "source": "\u7b56\u7565\u7b80\u4ecb\n-----------\n\u4ece\u516c\u53f8\u57fa\u672c\u9762\u3001\u5e02\u573a\u9a71\u52a8\u6307\u6807\u3001\u5e02\u573a\u60c5\u7eea\u7b49\u591a\u7ef4\u5ea6\u9a8c\u8bc1\u62e5\u6709\u201c\u5929\u65f6\u3001\u5730\u5229\u3001\u4eba\u548c\u201d\u7684\u5927\u725b\u80a1\uff0c\u8ba9\u6bcf\u4e2a\u4eba\u90fd\u80fd\u751f\u4ea7\u7b26\u5408\u81ea\u5df1\u6295\u8d44\u7406\u5ff5\u7684\u5927\u6570\u636e\u6307\u6570\u3002\u5b9e\u73b0\u4e2d\u53c2\u8003\u4e86\u6c34\u661f\u793e\u533a\u4e2d\u7684\u725b\u4eba@\u5434\u5b87\u7b1b\u7684\u56e0\u5b50\u8ba1\u5206\u5361\u7b56\u7565\u3002\n\n\u672c\u7b56\u7565\u7684\u53c2\u6570\u5982\u4e0b\uff1a\n\n* \u8d77\u59cb\u65e5\u671f\uff1a ```2014\u5e741\u67081\u65e5```\n* \u7ed3\u675f\u65e5\u671f\uff1a ```2016\u5e745\u670818\u65e5```\n* \u80a1\u7968\u6c60\uff1a ```\u4e0a\u8bc150```\n* \u4e1a\u7ee9\u57fa\u51c6\uff1a ```\u4e0a\u8bc150```\n* \u8d77\u59cb\u8d44\u91d1\uff1a ```100000\u5143```\n* \u8c03\u4ed3\u5468\u671f\uff1a ```1\u4e2a\u6708```\n\n\n\n\u7b56\u7565\u53c2\u6570\u83b7\u53d6\uff1a\n\n1. ``\u5341\u65e5\u79fb\u52a8\u5747\u7ebf(MA10)`` ``60\u65e5\u79fb\u52a8\u5747\u7ebf(MA60)`` ``\u8d44\u4ea7\u56de\u62a5\u7387(ROA)`` ``\u5e02\u76c8\u7387(PE)`` ``\u5bf9\u6570\u5e02\u503c(LCAP)`` ``\u6ce2\u5e45\u4e2d\u4f4d\u6570(DHILO)`` ``\u51c0\u5229\u6da6/\u8425\u4e1a\u603b\u6536\u5165(NPToTOR)`` ``\u4ea7\u6743\u6bd4\u7387(DebtEquityRatio)`` ``\u8425\u4e1a\u5229\u6da6\u540c\u6bd4\u589e\u957f(OperatingProfitGrowRate)`` ``\u603b\u8d44\u4ea7\u540c\u6bd4\u589e\u957f(TotalAssetGrowRate)`` \u5747\u53ef\u4ee5\u901a\u8fc7``DataAPI.MktStockFactorsDateRangeGet``\u83b7\u5f97\n2. ``\u5e02\u573a\u65b0\u95fb\u70ed\u5ea6\u6307\u6807``\u53ef\u4ee5\u901a\u8fc7``DataAPI.NewsHeatIndexGet``\u83b7\u5f97\n3. ``\u5e02\u573a\u60c5\u7eea\u6307\u6807``\u53ef\u4ee5\u901a\u8fc7``DataAPI.NewsSentimentIndexGet``\u83b7\u5f97\uff1b\u4e0e``\u65b0\u95fb\u70ed\u5ea6\u6307\u6807``\u4e00\u6837\uff0c\u90fd\u662fDataYes\u5229\u7528\u5927\u6570\u636e\u5206\u6790\u4ece\u6d77\u91cf\u5173\u8054\u65b0\u95fb\u4e2d\u63d0\u53d6\u51fa\u6765\u7684\n"}, {"cell_type": "markdown", "id": "E7AE757DB2EE4A3CB8D7A63B803D87CD", "metadata": {}, "source": "\u8c03\u4ed3\u7b56\u7565\n-----------\n\n (1) \u5bf9\u6bcf\u53ea\u80a1\u7968\u83b7\u53d6\u4e4b\u524d\u7684120\u4e2a\u4ea4\u6613\u65e5\u7684\u6536\u76d8\u4ef7\uff0c\u8ba1\u7b9720\u65e5\u7d2f\u8ba1\u6536\u76ca\uff0c\u5171\u5f97\u5230100\u4e2a\u6536\u76ca\u7387\u6570\u636e\n\n (2) \u83b7\u53d6\u8be5\u80a1\u7968\u540c\u671f\u7684100\u4e2a\u4ea4\u6613\u65e5\u7684\u57fa\u672c\u9762\u3001\u5e02\u573a\u9a71\u52a8\u6307\u6807\u548c\u5e02\u573a\u70ed\u5ea6\u3001\u60c5\u7eea\u6307\u6807\uff0c\u5206\u522b\u8ba1\u7b97\u5747\u503c\u3001\u6807\u51c6\u5dee\uff0c\u5e76\u8fdb\u884c\u4e2d\u5fc3\u5316\n    \n (3) \u4ee5\u8be5\u80a1\u796820\u65e5\u7d2f\u8ba1\u6536\u76ca\u7387\u4e3a\u56e0\u53d8\u91cf\uff0c\u57fa\u672c\u9762\u3001\u5e02\u573a\u9a71\u52a8\u6307\u6807\u548c\u5e02\u573a\u70ed\u5ea6\u3001\u60c5\u7eea\u6307\u6807\u4e3a\u81ea\u53d8\u91cf\u8fdb\u884c[\u5f39\u6027\u7f51 ( ElasticNet ) \u56de\u5f52](http://scikit-learn.org/stable/modules/linear_model.html)\n    \n (4) \u83b7\u53d6\u8be5\u80a1\u7968\u524d\u4e00\u65e5\u7684\u57fa\u672c\u9762\u3001\u5e02\u573a\u9a71\u52a8\u6307\u6807\u548c\u5e02\u573a\u70ed\u5ea6\u3001\u60c5\u7eea\u6307\u6807\n    \n (5) \u5bf9\u8be5\u80a1\u7968\u524d\u4e00\u65e5\u7684\u57fa\u672c\u9762\u3001\u5e02\u573a\u9a71\u52a8\u6307\u6807\u548c\u5e02\u573a\u70ed\u5ea6\u3001\u60c5\u7eea\u6307\u6807\uff0c\u4f9d\u636e\u524d100\u4e2a\u4ea4\u6613\u65e5\u7684\u5747\u503c\u548c\u6807\u51c6\u5dee\uff0c\u7f6e\u76f8\u5bf9\u5927\u5c0f\u4e3a \uff08\u524d\u4e00\u65e5\u503c - \u5747\u503c\uff09/ \u6807\u51c6\u5dee \u5e76\u56db\u820d\u4e94\u5165\uff0c\u4f5c\u4e3a\u5728\u8be5\u9879\u56e0\u5b50\u4e0a\u7684\u5f97\u5206\n    \n (6) \u6839\u636e\u4e4b\u524d\u8ba1\u7b97\u51fa\u7684\u6743\u91cd\u5bf9\u8fd9\u4e9b\u5f97\u5206\u8fdb\u884c\u52a0\u603b\uff0c\u5f97\u5230\u8be5\u80a1\u7968\u7684\u5f97\u5206\uff0c\u5e76\u4ee5\u6b64\u4e3a\u6307\u6570\u8fdb\u884c\u80a1\u7968\u7b5b\u9009\n    \n (7) \u6839\u636e\u6307\u6570\u5f97\u5206\u6392\u5e8f\uff0c\u9009\u53d6\u603b\u5206\u6700\u9ad8\u7684\u524d\u4e94\u652f\u80a1\u7968\u4f5c\u4e3a\u4e70\u5165\u5217\u8868\n    \n (8) \u6839\u636e\u4e70\u5165\u5217\u8868\u8c03\u4ed3"}, {"cell_type": "code", "collapsed": false, "id": "A95A458F236542BB8CA7C967F36D1B5E", "input": "import pandas as pd\nimport numpy  as np\nimport statsmodels.api as sm\nimport statsmodels.regression.linear_model as lm\nfrom sklearn.linear_model import ElasticNet\nfrom CAL.PyCAL import *\n\nused_factors = ['MA10', 'MA60', 'ROA', 'PE', 'LCAP', 'DHILO', 'DebtEquityRatio', 'OperatingProfitGrowRate', 'TotalAssetGrowRate', 'NPToTOR']\n\n#used_factors = ['ASSI', 'EBITToTOR', 'ETP5', 'MA60', 'HSIGMA', 'PE', 'VOL60', 'SUE', 'DAVOL20', 'TotalAssetGrowRate']\n\ndef StockFactorsGet(universe, trading_days):\n    data_all = {}\n    for i,stock in enumerate(universe):\n        try:\n            data = DataAPI.MktStockFactorsDateRangeGet(secID = stock, beginDate = trading_days[0], endDate = trading_days[-1], field = ['tradeDate'] + used_factors)\n            # data['tradeDate'] = pd.to_datetime(data['tradeDate'])\n        except Exception, e:\n            print e\n            \n        try:\n            news_data = DataAPI.NewsHeatIndexGet(secID = stock, beginDate = trading_days[0], endDate = trading_days[-1])\n            heatIndex = news_data.set_index('newsPublishDate').sort_index().reset_index()[['heatIndex','newsPublishDate']]\n            heatIndex['flag'] = heatIndex['newsPublishDate'].apply(lambda x: True if x in data.tradeDate.values else False)\n            heatIndex = heatIndex[heatIndex.flag].reset_index()\n            data = pd.merge(data, heatIndex, how = 'inner', left_index = 'tradeDate', right_index = 'newsPublishDate').drop(['index','newsPublishDate','flag'], 1)\n        except Exception, e:\n            data['heatIndex'] = 0\n        \n        try:\n            emotion_data = DataAPI.NewsSentimentIndexGet(secID = stock, beginDate = trading_days[0], endDate = trading_days[-1])\n            emotionIndex = emotion_data.set_index('newsPublishDate').sort_index().reset_index()[['sentimentIndex','newsPublishDate']]\n            emotionIndex['flag'] = emotionIndex['newsPublishDate'].apply(lambda x: True if x in data.tradeDate.values else False)\n            emotionIndex = emotionIndex[emotionIndex.flag].reset_index()\n            data = pd.merge(data, emotionIndex, how = 'inner', left_index = 'tradeDate', right_index = 'newsPublishDate').drop(['index','newsPublishDate','flag'], 1)\n        except Exception, e:\n            # print 'emotion', stock, e\n            data['sentimentIndex'] = 0\n        \n        data['news_emotion'] = data['heatIndex'] * data['sentimentIndex']\n        \n        data_all[stock] = data\n    return data_all\n\ndef StockRegDataGet(stock, trading_days, factors, shift = 20):\n    start = trading_days[0]\n    end   = trading_days[-1]\n    data  = factors[(factors.tradeDate >= start.strftime('%Y-%m-%d')) & (factors.tradeDate <= end.strftime('%Y-%m-%d'))][:-shift]\n    \n    ret = DataAPI.MktEqudGet(secID = stock, beginDate = start.strftime('%Y%m%d'), endDate = end.strftime('%Y%m%d'), field = ['tradeDate', 'closePrice'])\n    ret['fwdPrice'] = ret['closePrice'].shift(-shift)\n    ret['return'] = ret['fwdPrice'] / ret['closePrice'] - 1.\n    ret = ret[:-shift]\n    \n    data = data.merge(ret, how = 'inner', left_on = ['tradeDate'], right_on = ['tradeDate'])\n    data = data.loc[:, ['return', 'heatIndex', 'sentimentIndex', 'news_emotion'] + used_factors]\n    return data\n\ndef GetRegressionResult(data):\n    data = data.dropna()\n    \n    all_factors = ['heatIndex', 'sentimentIndex', 'news_emotion'] + used_factors\n    for f in all_factors:\n        if data[f].std() == 0:\n            continue\n        data[f] = (data[f] - data[f].mean()) / data[f].std()\n    \n    y = np.array(data['return'].tolist())\n    x = []\n    for f in all_factors:\n        x.append(data[f].tolist())\n    x = np.column_stack(tuple(x))\n    x = np.array( [ np.append(v,1) for v in x] ) \n    \n    en = ElasticNet(fit_intercept=True, alpha=0)\n    en.fit(x, y)\n    res = en.coef_[:-1]\n    w = dict(zip(all_factors, res))\n    return w\n\ndef preparing(universe, date, factors_all):\n    date = Date(date.year, date.month, date.day)\n    \n    cal = Calendar('China.SSE')\n    start = cal.advanceDate(date, '-120B', BizDayConvention.Following)\n    end   = cal.advanceDate(date, '-1B',   BizDayConvention.Following)\n    \n    start = datetime(start.year(), start.month(), start.dayOfMonth())\n    end   = datetime(  end.year(),   end.month(),   end.dayOfMonth())\n    \n    trading_days = quartz.utils.tradingcalendar.get_trading_days(start, end)\n    datas, means, vols, weights = {}, {}, {}, {}\n    for i,stock in enumerate(universe):\n        try:\n            datas[stock]   = StockRegDataGet(stock, trading_days, factors_all[stock])\n            means[stock]   = dict(datas[stock].mean())\n            vols[stock]    = dict(datas[stock].std())\n            weights[stock] = GetRegressionResult(datas[stock])\n        except Exception, e:\n            pass\n    return means, vols, weights", "language": "python", "metadata": {}, "outputs": [], "trusted": true}, {"cell_type": "code", "collapsed": false, "id": "6313CA9CFC4A417090F38DBAFAA5EF7E", "input": "from datetime import datetime\nend   = datetime(2016, 5, 18)\nf_start = datetime(2014, 1, 1)\nuniverse = set_universe('SH50')\nf_days = quartz.utils.tradingcalendar.get_trading_days(f_start, end)\nfactors_all = StockFactorsGet(universe, f_days)", "language": "python", "metadata": {}, "outputs": [], "trusted": true}, {"cell_type": "strategy", "collapsed": false, "id": "34DC9E75337C4718BC2D0EB87DAD151A", "input": "from datetime import datetime\nstart = datetime(2014, 6, 1)\nend   = datetime(2016, 5, 18)\nbenchmark = 'SH50'\nuniverse = set_universe('SH50')\ncapital_base = 100000\nrefresh_rate = 20\n\n# f_start = datetime(2012, 6, 1)\n# f_days = quartz.utils.tradingcalendar.get_trading_days(f_start, end)\n# factors_all = StockFactorsGet(universe, f_days)\n\ndef initialize(account):\n    pass\n\ndef handle_data(account):\n    print account.current_date\n    means, vols, weights = preparing(account.universe, account.current_date, factors_all)\n    \n    cal  = Calendar('China.SSE')\n    date = Date(account.current_date.year, account.current_date.month, account.current_date.day)\n    date = cal.advanceDate(date, '-1B', BizDayConvention.Following)\n    date = datetime(date.year(), date.month(), date.dayOfMonth())\n    \n    factors_cur = StockFactorsGet(account.universe, [date])\n    \n    score = {}\n    all_factors = ['heatIndex', 'sentimentIndex', 'news_emotion'] + used_factors\n    for stock in account.universe:\n        if stock not in weights:\n            continue\n        \n        fac = factors_cur[stock]\n        s = 0\n        for f in all_factors:\n            try:\n                x = fac[f].iloc[-1]\n                x = (x - means[stock][f])/vols[stock][f]\n                s += weights[stock][f] * int(round(x))\n            except:\n                pass\n        score[stock] = s\n    \n    buylist = sorted(score.keys(), key = lambda x: score[x])[-5:]\n    rebalance(account, buylist)\n\ndef rebalance(account, buylist):\n    for stock in account.valid_secpos:\n        if stock not in buylist:\n            order_to(stock, 0)\n    \n    for stock in buylist:\n        order(stock, account.referencePortfolioValue / len(buylist) / account.referencePrice[stock])", "language": "python", "metadata": {}, "outputs": [{"output_type": "stream", "stream": "stdout", "text": "2014-06-03 00:00:00"}, {"output_type": "stream", "stream": "stderr", "text": "-c:76: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\npython2.7/site-packages/sklearn/linear_model/coordinate_descent.py:454: UserWarning: Coordinate descent with alpha=0 may lead to unexpected results and is discouraged.\n  positive)\npython2.7/site-packages/sklearn/linear_model/coordinate_descent.py:466: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations\n  ConvergenceWarning)\npython2.7/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n  DeprecationWarning)\n"}, {"output_type": "stream", "stream": "stderr", "text": "-c:66: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\npython2.7/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n  DeprecationWarning)\n"}, {"output_type": "stream", "stream": "stderr", "text": "python2.7/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n  DeprecationWarning)\npython2.7/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n  DeprecationWarning)\n"}, {"output_type": "stream", "stream": "stdout", "text": "\n"}, {"output_type": "stream", "stream": "stderr", "text": "python2.7/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n  DeprecationWarning)\n"}, {"output_type": "stream", "stream": "stdout", "text": "2014-07-01 00:00:00\n"}, {"output_type": "stream", "stream": "stdout", "text": "2014-07-29 00:00:00\n"}, {"output_type": "stream", "stream": "stdout", "text": "2014-08-26 00:00:00\n"}, {"output_type": "stream", "stream": "stdout", "text": "2014-09-24 00:00:00\n"}, {"output_type": "stream", "stream": "stdout", "text": "2014-10-29 00:00:00\n"}, {"output_type": "stream", "stream": "stdout", "text": "2014-11-26 00:00:00\n"}, {"output_type": "stream", "stream": "stdout", "text": "2014-12-24 00:00:00\n"}, {"output_type": "stream", "stream": "stderr", "text": "python2.7/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n  DeprecationWarning)\npython2.7/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n  DeprecationWarning)\npython2.7/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n  DeprecationWarning)\n"}, {"output_type": "stream", "stream": "stdout", "text": "2015-01-23 00:00:00\n"}, {"output_type": "stream", "stream": "stdout", "text": "2015-02-27 00:00:00\n"}, {"output_type": "stream", "stream": "stdout", "text": "2015-03-27 00:00:00\n"}, {"output_type": "stream", "stream": "stdout", "text": "2015-04-27 00:00:00\n"}, {"output_type": "stream", "stream": "stdout", "text": "2015-05-26 00:00:00\n"}, {"output_type": "stream", "stream": "stdout", "text": "2015-06-24 00:00:00\n"}, {"output_type": "stream", "stream": "stdout", "text": "2015-07-22 00:00:00\n"}, {"output_type": "stream", "stream": "stdout", "text": "2015-08-19 00:00:00\n"}, {"output_type": "stream", "stream": "stdout", "text": "2015-09-18 00:00:00\n"}, {"output_type": "stream", "stream": "stdout", "text": "2015-10-23 00:00:00\n"}]}], "metadata": {}}]}