# 深度学习更有效吗？基于LSTM的多因子策略

本研究利用上一次发帖所采用的弹性网获选取的因子，共12个。预测下个月该股票的涨跌，涨的标签为1，跌的标签为0，
训练数据为数据为20090101到20150401。回测时间从2015-3-29到2016年10月1日（17个月）。首先比较了逻辑回归，和支持向量机，和深度学习方法。然后比较了MPL ,LSTM,GRU三种递归神经网络,最后实验发现LSTM效果好一些。
1.  [![逻辑回归于SVM准确率都只有53%](http://storage-uqer.datayes.com/572ec6fc228e5b303367f590/39c6c362-9034-11e6-8d0f-f8bc124ed898)](http://storage-uqer.datayes.com/572ec6fc228e5b303367f590/345015aa-9034-11e6-aa82-f8bc124ed898)
平台不支持深度学习模块，数据需要自己在本地电脑处理好再上传，keras各种参数可以可以自己调整，直到最优
import theano as theano
import keras as keras
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation
from keras.optimizers import SGD
from keras.optimizers import Adam
from keras.layers import Embedding
from keras.layers import LSTM
from keras.layers import GRU
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler


model = Sequential()
model.add(Embedding(12, 128))  #features=12
model.add(LSTM(output_dim=128, activation='sigmoid', inner_activation='relu'))#relu隐藏层激活效果更好
model.add(Dropout(0.1))
model.add(Dense(1))
model.add(Activation('sigmoid'))
             
model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])
print("Training model...")#模型训练
model.fit(x_train, y_lables, batch_size=300,validation_split=0.2, nb_epoch=100)

10次迭代，准确度53%，100次迭代情况下，准确度提升到71%，500次迭代准确度下降到63%。说明100次左右模型就已经收敛。
![100次迭代下的准确率](http://storage-uqer.datayes.com/572ec6fc228e5b303367f590/60f4b6f4-9036-11e6-8d0f-f8bc124ed898)
最后将预测概率，保存在测试数据中，一共约4300多个预测数据，预测结果1，且对应概率值大于0.6的只有200次左右。也就是平均每月不到15次。
因此取下个月预测结果为1，且概率值最大的前10只股票进行操作，每月末调仓。故意选取了，15年股票市场下降阶段，果然结果不怎么样（可以考虑做多预测为1，且概率排名前10的股票，做空预测为0，概率排名前十的股票，估计效果好一些，但是不会写这部分代码）
![LSTM](http://storage-uqer.datayes.com/572ec6fc228e5b303367f590/f9ad6dee-9038-11e6-a073-f8bc124ed898)