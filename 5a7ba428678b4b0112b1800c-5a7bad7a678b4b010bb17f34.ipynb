{"metadata": {"signature": "sha256:abd03d944b5ca7f23464915ee15b3b5a30135a5d31cba6f15f1c2aefc2b3c41d"}, "nbformat": 3, "nbformat_minor": 0, "worksheets": [{"cells": [{"cell_type": "markdown", "id": "EDD95336D1A2422DBC6421475A519D95", "metadata": {}, "source": "# \u4f7f\u7528TensorFlow\u57fa\u7840\u51fd\u6570\u6784\u5efa\u7b80\u5355\u7684\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u8fdb\u884c\u56de\u6d4b"}, {"cell_type": "markdown", "id": "7F4978E690144FD298A506F0A6A2884A", "metadata": {}, "source": "\u6df1\u5ea6\u5b66\u4e60\u8fd9\u4e2a\u8bcd\u201c\u8033\u95fb\u76ee\u67d3\u201d\u4e86\u5f88\u591a\u6b21\u4e86\uff0c\u5927\u5bb6\u4e5f\u90fd\u8dc3\u8dc3\u6b32\u8bd5\uff0c\u60f3\u5728\u91cf\u5316\u7814\u7a76\u4e2d\u7528\u4e0a\u6df1\u5ea6\u5b66\u4e60\u3002\u4f18\u77ff\u96c6\u6210\u4e86TensorFlow 1.4.1\u7248\u672c\uff0c\u6211\u4eec\u7ec8\u4e8e\u53ef\u4ee5\u5927\u5c55\u8eab\u624b\u4e86\u3002\uff08**\u76ee\u524d\u8fd8\u4ec5\u5bf9\u4e13\u4e1a\u7248\u7528\u6237\u5f00\u653e**\uff09\n\u4e0b\u624b\u524d\uff0c\u6211\u4eec\u5148\u5927\u6982\u7684\u4e86\u89e3\u4e00\u4e0bTensorFlow\u3002TensorFlow\u5b57\u9762\u4e0a\u7684\u610f\u601d\u662f\u5f20\u91cf\u5728\u6d41\u52a8\uff0c\u90a3\u4ec0\u4e48\u662f\u5f20\u91cf\uff0c\u5f20\u91cf\u53c8\u5728\u54ea\u6d41\u52a8\u5462?Google\u5bf9TensorFlow\u7684\u5b9a\u4f4d\u5176\u5b9e\u4e0d\u4ec5\u4ec5\u662f\u4e00\u4e2a\u6df1\u5ea6\u5b66\u4e60\u7684\u5e93\uff0c\u800c\u662f\u4e00\u4e2a\u57fa\u4e8e\u6570\u636e\u6d41\u56fe\u7684\u6570\u503c\u8ba1\u7b97\u6846\u67b6\u3002\u5728\u6570\u636e\u6d41\u56fe\u4e2d\u8282\u70b9\u8868\u793a\u64cd\u4f5c\uff0c\u8fb9\u8868\u793a\u5728\u8282\u70b9\u95f4\u76f8\u4e92\u8054\u7cfb\u7684\u591a\u4e3a\u6570\u7ec4\u5373\u5f20\u91cf\uff0c\u53ea\u8981\u628a\u8fd9\u4e2a\u6570\u636e\u6d41\u56fe\u753b\u597d\uff0c\u5f20\u91cf\u5c31\u53ef\u4ee5\u5728\u56fe\u4e0a\u201c\u6d41\u52a8\u201d\u8d77\u6765\u3002\u4f7f\u7528TensorFlow\u524d\uff0c\u5148\u753b\u4e2a\u56fe\uff08graph\uff09\u3002\u9664\u6b64\u4e4b\u5916\u6211\u4eec\u8fd8\u9700\u8981\u4e86\u89e3\uff1a\n1\u3001\u4f7f\u7528Variable\u8868\u793a\u90a3\u4e9b\u53ef\u88ab\u8bad\u7ec3\u7684\u53d8\u91cf\uff0c\u7ef4\u62a4\u8ba1\u7b97\u72b6\u6001\u3002\n2\u3001\u5728\u4f1a\u8bddsession\u4e2d\u6267\u884c\u56fe\u3002\n3\u3001\u4f7f\u7528feed\u548cfetch\u53ef\u4ee5\u4e3a\u4efb\u610f\u7684\u64cd\u4f5c\u8d4b\u503c\u6216\u83b7\u53d6\u6570\u636e\u3002\n\u4ee5\u4e0a\u51e0\u70b9\u6211\u4eec\u4f1a\u5728\u5b9e\u9645\u4ee3\u7801\u4e2d\u4e00\u4e00\u4ecb\u7ecd\u5230\u3002\n\u8fd1\u51e0\u5e74\u6df1\u5ea6\u5b66\u4e60\u7684\u706b\u70ed\uff0c\u4f7f\u5f97\u6a21\u578b\u53d8\u5f97\u8d8a\u6765\u8d8a\u591a\uff0cCNN\u3001RNN\u3001LSTM\u7b49\u7b49\u4e00\u4e2a\u4e2a\u90fd\u5982\u96f7\u704c\u8033\uff0c\u5b83\u4eec\u5728\u56fe\u50cf\u8bed\u97f3\u4e0a\u7684\u6548\u679c\u5f88\u597d\uff0c\u80fd\u5426\u5728\u91cf\u5316\u6295\u8d44\u4e0a\u53d6\u5f97\u6210\u6548\u5c31\u770b\u5404\u4f4d\u7684\u4e86\u3002\u672c\u7cfb\u5217\u53ea\u4f5c\u4e3a\u4e00\u4e2aTensorFlow\u7684\u4f7f\u7528\u6559\u7a0b\uff0c\u5e2e\u52a9\u5927\u5bb6\u80fd\u5feb\u901f\u4e0a\u624b\uff0c\u5e0c\u671b\u5927\u5bb6\u591a\u591a\u5728\u4f18\u77ff\u4e0a\u4f7f\u7528\uff0c\u69a8\u5e72\u6211\u4eec\u7684\u670d\u52a1\u5668\u8d44\u6e90\u3002\u672c\u7cfb\u5217\u9884\u8ba1\u5206\u4e0b\u9762\u51e0\u8d34\uff1a\n1\u3001\u4f7f\u7528TensorFlow\u57fa\u7840\u51fd\u6570\u6784\u5efa\u7b80\u5355\u7684\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u8fdb\u884c\u56de\u6d4b\u3002\n2\u3001\u4f7f\u7528TensorFlow\u4e2d\u7684\u9ad8\u7ea7API\uff1aEstimator\u3001Experiment\u548cDataset\u3002\n3\u3001\u4f7f\u7528TensorFlow\u6784\u5efa\u6df1\u5ea6\u5b66\u4e60\u7f51\u7edc\u5e76\u8fdb\u884c\u8c03\u4f18\u3002"}, {"cell_type": "markdown", "id": "AB2BDC0348794C248233A01DD96441EF", "metadata": {}, "source": "\u672c\u6587\u5c06\u5c55\u793a\u5982\u4f55\u7528TensorFlow\u753b\u4e00\u4e2a\u7b80\u5355LR\u548c\u591a\u5c42\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u6d41\u7a0b\u56fe\u5e76\u8fdb\u884c\u6548\u679c\u56de\u6d4b\u3002\u753b\u56fe\u524d\u6211\u4eec\u5f97\u660e\u786e\u8f93\u5165\u8f93\u51fa\u662f\u5565\uff0c\u4ece\u591a\u56e0\u5b50\u6a21\u578b\u89d2\u5ea6\u6765\u8bf4\u6211\u4eec\u7684\u8f93\u5165\u662f\u4e00\u5806\u56e0\u5b50\u7136\u540e\u5e0c\u671b\u5f97\u5230alpha\u4fe1\u53f7\uff0c\u4ece\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u89d2\u5ea6\u6765\u8bf4\u8f93\u5165\u5c31\u662f\u4e00\u5806\u7279\u5f81\u8f93\u51fa\u662f\u5206\u7c7b\u6216\u56de\u5f52\u7ed3\u679c\u3002\u672c\u6587\u4e2d\u6211\u4eec\u7684\u8f93\u5165\u662f\u4f18\u77ff\u63d0\u4f9b\u7684\u56e0\u5b50\uff0c\u57fa\u4e8e\u6211\u4eec\u5bf9\u8fd9\u4e9b\u56e0\u5b50\u6709\u9884\u6d4b\u80fd\u529b\u7684\u5047\u8bbe\uff0c\u6211\u4eec\u76ee\u6807\u662f\u901a\u8fc7\u56e0\u5b50\u5224\u65ad\u4e0b\u4e00\u4e2a\u8c03\u4ed3\u5468\u671f\u4e2d\u80a1\u7968\u662f\u6da8\u662f\u8dcc\u3002\u5177\u4f53\u800c\u8a00\uff0c\u6211\u4eec\u53d6\u6bcf\u6708\u672b\u7684\u6bcf\u53ea\u80a1\u7968\u7684\u56e0\u5b50\u4e3a\u8f93\u5165\u7279\u5f81\uff0c\u4ee5\u4e0b\u4e2a\u6708\u80a1\u7968\u662f\u6da8\uff08\u503c\u4e3a1\uff09\u662f\u8dcc\uff08\u503c\u4e3a0\uff09\u4e3a\u8f93\u51fa\u6807\u7b7e\u3002\u4e00\u822c\u800c\u8a00\u6211\u4eec\u9700\u8981\u5206\u8bad\u7ec3\u96c6\u3001\u6d4b\u8bd5\u96c6\u3002\u8bad\u7ec3\u96c6\u7528\u6765\u8bad\u7ec3\u6211\u4eec\u7684\u6a21\u578b\uff0c\u6d4b\u8bd5\u96c6\u7528\u6765\u9a8c\u8bc1\u6211\u4eec\u7684\u6a21\u578b\u6548\u679c\u5982\u4f55\uff0c\u662f\u5426\u8fc7\u62df\u5408\u5bfc\u81f4\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u4e0a\u7684\u6548\u679c\u5927\u6253\u6298\u6263\u3002"}, {"cell_type": "code", "collapsed": true, "id": "85EEF673B5F44AF696368BFCDEDB4176", "input": "import pandas  as pd\nimport numpy as np\nimport os\n# \u5bf9\u6a2a\u622a\u9762\u7684\u6bcf\u4e2a\u56e0\u5b50\u53bb\u6781\u503c\u6807\u51c6\u5316\ndef process_data(df):\n    df.set_index('secID',inplace=True)\n    for col in df.columns:\n        df[col] = standardize(winsorize(df[col]))\n    return df.reset_index()\n# \u5f97\u5230\u8f93\u5165\u7279\u5f81\ndef get_features(tradeDate,tickers=''):\n    print 'feature day:',tradeDate\n    features = DataAPI.MktStockFactorsOneDayGet(tradeDate=tradeDate,secID=tickers,field=u\"\",pandas=\"1\").fillna(0).drop(['ticker','tradeDate'],axis=1)\n    features = process_data(features)\n    return features\n# \u5f97\u5230\u8f93\u51fa\u6807\u7b7e\ndef get_labels(monthEndDate):\n    print 'label day:',monthEndDate\n    labels = DataAPI.MktEqumGet(secID=u\"\",ticker=u\"\",monthEndDate=monthEndDate,isOpen=u\"\",beginDate=u\"\",endDate=u\"\",field=u\"secID,chgPct\",pandas=\"1\")\n    labels['label'] = labels['chgPct'].map(lambda x : 1 if (x >0) else 0)\n    labels['lable'] = labels['label'].astype(int)\n    return labels[['secID','label']]\n# \u83b7\u53d6\u4e0d\u540c\u65f6\u95f4\u6bb5\u548c\u6295\u8d44\u57df\u7684\u6837\u672c\ndef get_samples(start,end,tickers=''):\n    tradeCal = DataAPI.TradeCalGet(exchangeCD=u\"XSHG\",beginDate=start,endDate=end,field=u\"\",pandas=\"1\").query('isMonthEnd==1')\n    tradeCal['nextMonthEnd'] = tradeCal['calendarDate'].shift(-1)\n    tradeCal.dropna(inplace=True)\n    samples = []\n    for index, row in tradeCal.iterrows():\n        features = get_features(row['calendarDate'],tickers)\n        labels = get_labels(row['nextMonthEnd'])\n        sample = pd.merge(features,labels,how='inner',on='secID')\n        samples.append(sample)\n    df = pd.concat(samples).fillna(0)\n    return df\ndata_path='tensorflow_data'\nif ~ os.path.exists(data_path):\n    os.mkdir(data_path)\nprint 'train_samples\\n'\ntrain_samples = get_samples('20141231','20160101')\ntrain_samples.fillna(0).to_csv('tensorflow_data/train.csv',index=False)\nprint 'test_samples\\n'\ntest_samples = get_samples('20151231','20160301')\ntest_samples.fillna(0).to_csv('tensorflow_data/test.csv',index=False)", "language": "python", "metadata": {}, "outputs": [{"output_type": "stream", "stream": "stdout", "text": "train_samples\n"}, {"output_type": "stream", "stream": "stdout", "text": "\nfeature day:"}, {"output_type": "stream", "stream": "stdout", "text": " 2014-12-31\nlabel day:"}, {"output_type": "stream", "stream": "stdout", "text": " 2015-01-30\nfeature day:"}, {"output_type": "stream", "stream": "stdout", "text": " 2015-01-30\nlabel day:"}, {"output_type": "stream", "stream": "stdout", "text": " 2015-02-27\nfeature day:"}, {"output_type": "stream", "stream": "stdout", "text": " 2015-02-27\nlabel day:"}, {"output_type": "stream", "stream": "stdout", "text": " 2015-03-31\nfeature day:"}, {"output_type": "stream", "stream": "stdout", "text": " 2015-03-31\nlabel day:"}, {"output_type": "stream", "stream": "stdout", "text": " 2015-04-30\nfeature day:"}, {"output_type": "stream", "stream": "stdout", "text": " 2015-04-30\nlabel day:"}, {"output_type": "stream", "stream": "stdout", "text": " 2015-05-29\nfeature day:"}, {"output_type": "stream", "stream": "stdout", "text": " 2015-05-29\nlabel day:"}, {"output_type": "stream", "stream": "stdout", "text": " 2015-06-30\nfeature day:"}, {"output_type": "stream", "stream": "stdout", "text": " 2015-06-30\nlabel day:"}, {"output_type": "stream", "stream": "stdout", "text": " 2015-07-31\nfeature day:"}, {"output_type": "stream", "stream": "stdout", "text": " 2015-07-31\nlabel day:"}, {"output_type": "stream", "stream": "stdout", "text": " 2015-08-31\nfeature day:"}, {"output_type": "stream", "stream": "stdout", "text": " 2015-08-31\nlabel day:"}, {"output_type": "stream", "stream": "stdout", "text": " 2015-09-30\nfeature day:"}, {"output_type": "stream", "stream": "stdout", "text": " 2015-09-30\nlabel day:"}, {"output_type": "stream", "stream": "stdout", "text": " 2015-10-30\nfeature day:"}, {"output_type": "stream", "stream": "stdout", "text": " 2015-10-30\nlabel day:"}, {"output_type": "stream", "stream": "stdout", "text": " 2015-11-30\nfeature day:"}, {"output_type": "stream", "stream": "stdout", "text": " 2015-11-30\nlabel day:"}, {"output_type": "stream", "stream": "stdout", "text": " 2015-12-31\ntest_samples\n"}, {"output_type": "stream", "stream": "stdout", "text": " 2015-12-31\nlabel day:"}, {"output_type": "stream", "stream": "stdout", "text": " 2016-01-29\nfeature day:"}, {"output_type": "stream", "stream": "stdout", "text": " 2016-01-29\nlabel day:"}, {"output_type": "stream", "stream": "stdout", "text": " 2016-02-29\n"}], "trusted": true}, {"cell_type": "markdown", "id": "B2F73403804A495DA4708AC41DA13C15", "metadata": {}, "source": "\u51c6\u5907\u5b8c\u8f93\u5165\u8f93\u51fa\uff0c\u6211\u4eec\u5c31\u8981\u5f00\u59cb\u753b\u56fe\u4e86\u3002"}, {"cell_type": "code", "collapsed": true, "id": "53151F72AAE54A0F8991BD94FEA76C15", "input": "import tensorflow as tf\n\n# \u5b9a\u4e49\u6a21\u578b\u53c2\u6570\n# \u5b66\u4e60\u7387\nlearning_rate = 0.01\n# \u8fed\u4ee3\u6b21\u6570\ntrain_epochs = 5000\n# \u8fed\u4ee3\u591a\u5c11\u6b21\u540e\u6253\u5370\u4e00\u4e9b\u4fe1\u606f\ndisplay_step = 200\n\n# \u8bad\u7ec3\u7528\u7684\u7279\u5f81\uff0c\u5c06dataframe\u8f6c\u4e3a\u77e9\u9635\ntrain_X = train_samples.ix[:,1:-1].as_matrix()\n# \u8bad\u7ec3\u7528\u7684\u6807\u7b7e\ntrain_Y = train_samples.ix[:,-1:].as_matrix()\nn_samples = train_X.shape[0]\nfeature_dim = train_X.shape[1]\nprint 'samples:',n_samples,'feature_dim:',feature_dim\n\n# \u5b9a\u4e49\u4e00\u4e2a\u56fe\nwith tf.Graph().as_default() as graph_lr:\n    # \u5b9a\u4e49\u8f93\u5165\u8282\u70b9\n    with tf.name_scope('Input'):\n        # \u4e3afeed\u64cd\u4f5c\u521b\u5efa\u5360\u4f4d\u7b26\u3002\u6211\u4eec\u9700\u8981\u5c06\u51c6\u5907\u597d\u7684\u8bad\u7ec3\u6570\u636e\u6ce8\u5165\u5230\u5f20\u91cf\u4e2d\uff0c\u8fd9\u79cd\u6ce8\u5165\u64cd\u4f5c\u5728TensorFlow\u4e2d\u79f0\u4e3afeed\u3002\n        X = tf.placeholder(tf.float32, [None,feature_dim])\n        Y = tf.placeholder(tf.float32, [None,1])\n\n    with tf.name_scope('Inference'):\n        # \u5b9a\u4e49\u53d8\u91cf\u6743\u91cdW\u548c\u504f\u7f6eb\uff0c\u8fd9\u91cc\u7528\u7684\u662ftf.Variable()\u6765\u521b\u5efa\u8868\u793a\u8fd9\u662f\u6a21\u578b\u4e2d\u9700\u8981\u8bad\u7ec3\u66f4\u65b0\u7684\u503c\u3002\u7ed9\u8fd9\u4e9b\u53d8\u91cf\u52a0\u4e2a\u540d\u5b57\uff0c\u4ee5\u4fbf\u91cd\u8f7d\u6a21\u578b\u65f6\u80fd\u8bc6\u522b\u3002\n        W = tf.Variable(tf.random_normal([feature_dim,1]),name='W')\n        b = tf.Variable(tf.random_normal([1]),name='b')\n        # \u5f97\u5230\u9884\u6d4b\u503c\u7684\u64cd\u4f5c\uff0c\u8fd9\u91cc\u6211\u4eec\u9009\u7528\u7684\u6fc0\u6d3b\u51fd\u6570\u662fsigmod\uff0c\u5176\u4f59\u8fd8\u6709relu\u3001relu6\u3001softplus\u3001tanh\u7b49\n        Y_ = tf.nn.sigmoid(tf.matmul(X,W)+b)\n\n    # \u5b9a\u4e49\u635f\u5931\u51fd\u6570\n    with tf.name_scope('Loss'):\n    # \u635f\u5931\u51fd\u6570\u4f7f\u7528\u7684\u662f\u5206\u7c7b\u635f\u5931\u51fd\u6570\uff1a\u4ea4\u53c9\u71b5\uff08crossentropy\uff09\uff0c\u4ee3\u7801\u53ef\u4ee5\u7528\u5176\u63d0\u4f9b\u7684\u51fd\u6570tf.nn.sigmoid_cross_entropy_with_logits(labels=Y, logits=Y_)\n        cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(Y_), reduction_indices=1))\n    \n    # \u5b9a\u4e49\u4f18\u5316\u65b9\u6cd5\n    with tf.name_scope('Train'):\n        optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n\n    # \u5b9a\u4e49\u8bc4\u4f30\u65b9\u6cd5\n    with tf.name_scope('Eval'):\n        correct_prediction = tf.equal(tf.round(Y_), Y)\n        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\n    # \u521d\u59cb\u5316\u5404\u4e2a\u8282\u70b9\n    init = tf.global_variables_initializer()\n    \n    # \u8fd9\u91cc\u6211\u4eec\u9700\u8981\u5c06\u6211\u4eec\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u4fdd\u5b58\u4e0b\u6765\uff0c\u4ee5\u4fbf\u56de\u6d4b\u65f6\u4f7f\u7528\n    saver = tf.train.Saver([W,b])\n    # \u542f\u52a8\u4e00\u4e2a\u4f1a\u8bdd\u6765\u8fd0\u884c\u6211\u4eec\u5b9a\u4e49\u7684\u56fe\uff0cTensorFlow\u4f1a\u81ea\u52a8\u5b8c\u6210\u4f18\u5316\u5de5\u4f5c\n    with tf.Session() as sess:\n        sess.run(init)\n        for epoch in range(train_epochs):\n            sess.run(optimizer, feed_dict={X: train_X, Y: train_Y})\n            if (epoch + 1) % display_step == 0:\n                epoch_cost = sess.run(cost, feed_dict={X: train_X, Y: train_Y})\n                saver.save(sess, 'tensorflow_model_lr/my-model.ckpt')\n                print 'epochs:', '%d' % (epoch + 1), 'cost=', '{:.9f}'.format(epoch_cost)\n        print 'finish optimize'\n        training_cost = sess.run(cost, feed_dict={X: train_X, Y: train_Y})\n        print \"training cost=\", training_cost\n        test_X, test_Y = test_samples.ix[:,1:-1].as_matrix(), test_samples.ix[:,-1:].as_matrix()\n        print(\"test accuracy:\", sess.run(accuracy, feed_dict={X: test_X, Y: test_Y}))\n        prediction = sess.run(Y_, feed_dict={X: test_X})\n        P = tf.round(prediction)\n        # \u67e5\u770b\u4e8c\u5206\u7c7b\u76f8\u5173\u7684\u6307\u6807\n        print 'P:',P.eval(feed_dict={X: test_X})\n        TP = tf.count_nonzero(P * Y, dtype=tf.float32)\n        TN = tf.count_nonzero((P - 1) * (Y - 1), dtype=tf.float32)\n        FP = tf.count_nonzero(P * (Y - 1), dtype=tf.float32)\n        FN = tf.count_nonzero((P - 1) * Y, dtype=tf.float32)\n        print 'TP:',TP.eval(feed_dict={X: test_X, Y: test_Y})\n        print 'TN:',TN.eval(feed_dict={X: test_X, Y: test_Y})\n        print 'FP:',FP.eval(feed_dict={X: test_X, Y: test_Y})\n        print 'FN:',FN.eval(feed_dict={X: test_X, Y: test_Y})\n        precision =tf.divide(TP, TP + FP)\n        recall = tf.divide(TP, TP + FN)\n        F1 = 2 * precision * recall / (precision + recall)\n        print 'precision:',precision.eval(feed_dict={X: test_X, Y: test_Y}) ,'recall:',recall.eval(feed_dict={X: test_X, Y: test_Y}),'F1:',F1.eval(feed_dict={X: test_X, Y: test_Y})", "language": "python", "metadata": {}, "outputs": [{"output_type": "stream", "stream": "stdout", "text": "samples:"}, {"output_type": "stream", "stream": "stdout", "text": " 32666 feature_dim: 244\nepochs:"}, {"output_type": "stream", "stream": "stdout", "text": " 200 cost= 2.921933413\nepochs:"}, {"output_type": "stream", "stream": "stdout", "text": " 400 cost= 2.341215849\nepochs:"}, {"output_type": "stream", "stream": "stdout", "text": " 600 cost= 1.939928532\nepochs:"}, {"output_type": "stream", "stream": "stdout", "text": " 800 cost= 1.651077986\nepochs:"}, {"output_type": "stream", "stream": "stdout", "text": " 1000 cost= 1.430582404\nepochs:"}, {"output_type": "stream", "stream": "stdout", "text": " 1200 cost= 1.252103090\nepochs:"}, {"output_type": "stream", "stream": "stdout", "text": " 1400 cost= 1.100485086\nepochs:"}, {"output_type": "stream", "stream": "stdout", "text": " 1600 cost= 0.968017340\nepochs:"}, {"output_type": "stream", "stream": "stdout", "text": " 1800 cost= 0.851172566\nepochs:"}, {"output_type": "stream", "stream": "stdout", "text": " 2000 cost= 0.748061180\nepochs:"}, {"output_type": "stream", "stream": "stdout", "text": " 2200 cost= 0.657328188\nepochs:"}, {"output_type": "stream", "stream": "stdout", "text": " 2400 cost= 0.577859163\nepochs:"}, {"output_type": "stream", "stream": "stdout", "text": " 2600 cost= 0.508512378\nepochs:"}, {"output_type": "stream", "stream": "stdout", "text": " 2800 cost= 0.448167890\nepochs:"}, {"output_type": "stream", "stream": "stdout", "text": " 3000 cost= 0.395779938\nepochs:"}, {"output_type": "stream", "stream": "stdout", "text": " 3200 cost= 0.350403309\nepochs:"}, {"output_type": "stream", "stream": "stdout", "text": " 3400 cost= 0.311183959\nepochs:"}, {"output_type": "stream", "stream": "stdout", "text": " 3600 cost= 0.277331293\nepochs:"}, {"output_type": "stream", "stream": "stdout", "text": " 3800 cost= 0.248113081\nepochs:"}, {"output_type": "stream", "stream": "stdout", "text": " 4000 cost= 0.222863525\nepochs:"}, {"output_type": "stream", "stream": "stdout", "text": " 4200 cost= 0.200994357\nepochs:"}, {"output_type": "stream", "stream": "stdout", "text": " 4400 cost= 0.181994170\nepochs:"}, {"output_type": "stream", "stream": "stdout", "text": " 4600 cost= 0.165425152\nepochs:"}, {"output_type": "stream", "stream": "stdout", "text": " 4800 cost= 0.150918022\nepochs:"}, {"output_type": "stream", "stream": "stdout", "text": " 5000 cost= 0.138163775\nfinish optimize\ntraining cost= 0.138164\n('test accuracy:', 0.3515625)"}, {"output_type": "stream", "stream": "stdout", "text": "\nP: [[ 1.]\n [ 1.]\n [ 1.]\n ..., \n [ 1.]\n [ 1.]\n [ 1.]]\nTP:"}, {"output_type": "stream", "stream": "stdout", "text": " 770.0\nTN: 220.0\nFP: 1754.0\nFN: 72.0\nprecision: 0.305071 recall: 0.914489 F1: 0.457516\n"}], "trusted": true}, {"cell_type": "markdown", "id": "238C7F4BB9B8482285A7A5E391122985", "metadata": {}, "source": "\u6211\u4eec\u8bf4\u4e86\u534a\u5929\u753b\u56fe\uff0c\u4f46\u5176\u5b9e\u662f\u5728\u5806\u4ee3\u7801\uff0c\u90a3\u6211\u4eec\u7684\u56fe\u5230\u5e95\u957f\u5565\u6837\u5462\uff1f\u6211\u4eec\u5c06\u4e0a\u9762\u5b9a\u4e49\u7684\u56fe\u53ef\u89c6\u5316\u540e\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u56fe\u4e2d\u6807\u8bc6\u4e86\u4e3b\u8981\u7684\u8ba1\u7b97\u8282\u70b9\uff0c\u8fb9\u5c31\u662f\u6d41\u52a8\u7684\u5f20\u91cf\uff0c\u548c\u672c\u6587\u5f00\u5934\u4ecb\u7ecd\u7684\u4e00\u6837\u3002"}, {"cell_type": "markdown", "id": "46DE1C0EF19843C180729FA358115D66", "metadata": {}, "source": "![Alt text](https://static.wmcloud.com/v1/AUTH_datayes/rrp/66eae96b7e1d4056858a14872743ae1a.png \"lr model\")"}, {"cell_type": "markdown", "id": "21B0C0D6470943E484F1AB96B174E072", "metadata": {}, "source": "\u4e0a\u9762\u6211\u4eec\u5b9a\u4e49\u4e86\u4e00\u4e2a\u7b80\u5355\u7684LR\u6a21\u578b\uff0c\u4e0b\u9762\u6211\u4eec\u589e\u52a0\u7f51\u7edc\u7684\u5c42\u6570\u3002"}, {"cell_type": "code", "collapsed": false, "id": "4D40EB3B5FC0438A8FE9570671B41F7E", "input": "learning_rate = 0.001\ntrain_epochs = 10\ndisplay_step = 2\n\ntrain_X = train_samples.ix[:,1:-1].as_matrix()\ntrain_Y = train_samples.ix[:,-1:].as_matrix()\nn_samples = train_X.shape[0]\nfeature_dim = train_X.shape[1]\nprint 'samples:',n_samples,'feature_dim:',feature_dim\n\nwith tf.Graph().as_default():\n    with tf.name_scope('Input'):\n        X = tf.placeholder(tf.float32, [None,feature_dim])\n        Y = tf.placeholder(tf.float32, [None,1])\n\n    #\u8fd9\u91cc\u6211\u4eec\u6539\u53d8\u4e0b\u7f51\u7edc\u7ed3\u6784\uff0c\u589e\u52a0\u4e862\u5c42\u7f51\u7edc\n    with tf.name_scope('Inference'):\n        # \u5b9a\u4e49\u7f51\u7edc\u7684\u5c42\u6570\u53ca\u6bcf\u5c42\u7684\u8282\u70b9\u6570\n        layer1 = feature_dim/2\n        layer2 = layer1/2\n        W = {  \n            \"L1\":tf.Variable(tf.random_normal([feature_dim, layer1]),name='W_L1'),  \n            \"L2\":tf.Variable(tf.random_normal([layer1, layer2]),name='W_L2'),  \n            \"output\": tf.Variable(tf.random_normal([layer2, 1]),name='W_output')  \n        }  \n\n        b = {  \n            \"L1\":tf.Variable(tf.random_normal([layer1]),name='b_L1'),  \n            \"L2\":tf.Variable(tf.random_normal([layer2]),name='b_L2'),  \n            \"output\":tf.Variable(tf.random_normal([1]),name='b_output')  \n        }  \n \n        net1 = tf.nn.sigmoid(tf.matmul(X, W[\"L1\"]) + b[\"L1\"])\n        net2 = tf.nn.sigmoid(tf.matmul(net1, W[\"L2\"]) + b[\"L2\"])\n        Y_ = tf.nn.sigmoid(tf.matmul(net2, W[\"output\"]) + b[\"output\"]) \n\n    with tf.name_scope('Loss'):\n        cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(Y_), reduction_indices=1))\n    \n    with tf.name_scope('Train'):\n        optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n\n    with tf.name_scope('Eval'):\n        correct_prediction = tf.equal(tf.round(Y_), Y)\n        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\n    init = tf.global_variables_initializer()\n    \n    saver = tf.train.Saver()\n    with tf.Session() as sess:\n        sess.run(init)\n        for epoch in range(train_epochs):\n            sess.run(optimizer, feed_dict={X: train_X, Y: train_Y})\n            if (epoch + 1) % display_step == 0:\n                epoch_cost = sess.run(cost, feed_dict={X: train_X, Y: train_Y})\n                saver.save(sess, 'tensorflow_model_mlp/my-model.ckpt')\n                print 'epochs:', '%d' % (epoch + 1), 'cost=', '{:.9f}'.format(epoch_cost)\n        print 'finish optimize'\n        training_cost = sess.run(cost, feed_dict={X: train_X, Y: train_Y})\n        print \"training cost=\", training_cost\n        test_X, test_Y = test_samples.ix[:,1:-1].as_matrix(), test_samples.ix[:,-1:].as_matrix()\n        print(\"test accuracy:\", sess.run(accuracy, feed_dict={X: test_X, Y: test_Y}))\n        prediction = sess.run(Y_, feed_dict={X: test_X})\n        P = tf.round(prediction)\n        # print 'P:',P.eval(feed_dict={X: test_X})\n        TP = tf.count_nonzero(P * Y, dtype=tf.float32)\n        TN = tf.count_nonzero((P - 1) * (Y - 1), dtype=tf.float32)\n        FP = tf.count_nonzero(P * (Y - 1), dtype=tf.float32)\n        FN = tf.count_nonzero((P - 1) * Y, dtype=tf.float32)\n        print 'TP:',TP.eval(feed_dict={X: test_X, Y: test_Y})\n        print 'TN:',TN.eval(feed_dict={X: test_X, Y: test_Y})\n        print 'FP:',FP.eval(feed_dict={X: test_X, Y: test_Y})\n        print 'FN:',FN.eval(feed_dict={X: test_X, Y: test_Y})\n        precision =tf.divide(TP, TP + FP)\n        recall = tf.divide(TP, TP + FN)\n        F1 = 2 * precision * recall / (precision + recall)\n        print 'precision:',precision.eval(feed_dict={X: test_X, Y: test_Y}) ,'recall:',recall.eval(feed_dict={X: test_X, Y: test_Y}),'F1:',F1.eval(feed_dict={X: test_X, Y: test_Y})", "language": "python", "metadata": {}, "outputs": [{"output_type": "stream", "stream": "stdout", "text": "samples:"}, {"output_type": "stream", "stream": "stdout", "text": " 30380 feature_dim: 244\nepochs:"}, {"output_type": "stream", "stream": "stdout", "text": " 2 cost= 0.582974732\nepochs:"}, {"output_type": "stream", "stream": "stdout", "text": " 4 cost= 0.580095232\nepochs:"}, {"output_type": "stream", "stream": "stdout", "text": " 6 cost= 0.577233374\nepochs:"}, {"output_type": "stream", "stream": "stdout", "text": " 8 cost= 0.574391186\nepochs:"}, {"output_type": "stream", "stream": "stdout", "text": " 10 cost= 0.571568608\nfinish optimize\ntraining cost="}, {"output_type": "stream", "stream": "stdout", "text": " 0.571569\n('test accuracy:', 0.5700565)\nTP:"}, {"output_type": "stream", "stream": "stdout", "text": " 5085.0\nTN: 969.0\nFP: 919.0\nFN: 3647.0\nprecision: "}, {"output_type": "stream", "stream": "stdout", "text": "0.846935 recall: 0.582341 F1: 0.690147\n"}], "trusted": true}, {"cell_type": "markdown", "id": "BAA26C9C6446443E9A1BCA98A074CE3F", "metadata": {}, "source": "\u8bad\u7ec3\u5b8c\u6a21\u578b\u540e\uff0c\u5982\u679c\u6a21\u578b\u7684\u6548\u679c\u4e0d\u9519\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u7528\u6a21\u578b\u6765\u8fdb\u884c\u56de\u6d4b\u3002\u4e0b\u9762\u6211\u4eec\u5c06\u4fdd\u5b58\u7684\u6a21\u578b\u8f7d\u5165\u5185\u5b58\uff0c\u7136\u540e\u7528\u56de\u6d4b\u6846\u67b6\u8fdb\u884c\u56de\u6d4b\u3002"}, {"cell_type": "code", "collapsed": false, "id": "3F7506818D5A403CB78D0C421A4CA4D2", "input": "#\u5728\u8f7d\u5165\u6a21\u578b\u65f6\u9700\u8981\u660e\u786e\u4e0b\u6211\u4eec\u7684\u6a21\u578b\u662f\u600e\u6837\u7684\uff0c\u4e3b\u8981\u6d89\u53ca\u5230\u51e0\u4e2a\u8bad\u7ec3\u7684\u53d8\u91cf\uff0c\u6211\u4eec\u4e5f\u53ea\u9700\u8981\u628a\u8fd9\u4e2a\u56fe\u7684\u51e0\u4e2a\u8282\u70b9\u660e\u786e\u5c31\u884c\u3002\nimport tensorflow as tf\nfeature_dim = 244\ntf.reset_default_graph()\nsess = tf.Session()\nX = tf.placeholder(tf.float32, [None,feature_dim])\nY = tf.placeholder(tf.float32, [None,1])\n# \u8fd9\u91cc\u9700\u8981\u5c06\u53d8\u91cf\u7684\u540d\u5b57\u4e0e\u4e4b\u524d\u8bad\u7ec3\u65f6\u7684\u5bf9\u5e94\uff0c\u6ce8\u610f\u8bad\u7ec3\u65f6\u8fd9\u4e24\u4e2a\u53d8\u91cf\u7684name_scope\u662fInference\nW = tf.Variable(tf.zeros([feature_dim,1]),name='Inference/W')\nb = tf.Variable(tf.zeros([1]),name='Inference/b')\nY_ = tf.nn.sigmoid(tf.matmul(X,W)+b)\nsaver = tf.train.Saver()\nsaver.restore(sess, \"tensorflow_model_lr/my-model.ckpt\")", "language": "python", "metadata": {}, "outputs": [{"output_type": "stream", "stream": "stdout", "text": "INFO:tensorflow:Restoring parameters from tensorflow_model_lr/my-model.ckpt\n"}], "trusted": true}, {"cell_type": "markdown", "id": "F11BA8E3C23D4071B672B2AFE6F7E419", "metadata": {}, "source": "\u6211\u4eec\u7528\u7684\u662f15\u5e74\u7684\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\uff0c16\u5e741\u30012\u6708\u7684\u6570\u636e\u8fdb\u884c\u6d4b\u8bd5\u7684\uff0c\u56e0\u6b64\u6211\u4eec\u56de\u6d4b\u533a\u95f4\u8981\u907f\u5f00\u8fd9\u4e24\u4e2a\u65f6\u95f4\u6bb5\u3002\u56e0\u4e3a\u6211\u4eec\u5728\u8bad\u7ec3\u6d4b\u8bd5\u65f6\u4f1a\u8fdb\u884c\u8c03\u4f18\uff0c\u5982\u679c\u5728\u6d4b\u8bd5\u96c6\u4e0a\u8fdb\u884c\u56de\u6d4b\u5c31\u4f1a\u7528\u5230\u672a\u6765\u6570\u636e\u3002\u6211\u4eec\u9009\u53d6\u6a21\u578b\u9884\u6d4b\u503c\u6700\u5927\u7684\u524d10\u4e2a\u6765\u6784\u5efa\u6211\u4eec\u7684\u7ec4\u5408\u3002"}, {"cell_type": "strategy", "collapsed": false, "has_detail": true, "id": "2176BD209845451D9A0CD454DAD8EFD9", "input": "start = '2016-03-01'                       # \u56de\u6d4b\u8d77\u59cb\u65f6\u95f4\nend = '2017-03-01'                         # \u56de\u6d4b\u7ed3\u675f\u65f6\u95f4\nuniverse = DynamicUniverse('HS300')        # \u8bc1\u5238\u6c60\uff0c\u652f\u6301\u80a1\u7968\u548c\u57fa\u91d1\u3001\u671f\u8d27\nbenchmark = 'HS300'                        # \u7b56\u7565\u53c2\u8003\u57fa\u51c6\nfreq = 'd'                                 # 'd'\u8868\u793a\u4f7f\u7528\u65e5\u9891\u7387\u56de\u6d4b\uff0c'm'\u8868\u793a\u4f7f\u7528\u5206\u949f\u9891\u7387\u56de\u6d4b\nrefresh_rate = Monthly(1)                          # \u6267\u884chandle_data\u7684\u65f6\u95f4\u95f4\u9694\n\naccounts = {\n    'fantasy_account': AccountConfig(account_type='security', capital_base=10000000)\n}\n\ndef get_candidate(features,N):\n    prediction = sess.run(Y_, feed_dict={X: features.ix[:,1:].as_matrix()})\n    prediction = pd.DataFrame(prediction,columns=['prob'])\n    res = pd.concat([features['secID'],prediction],axis=1).sort_values(by='prob',ascending=False).reset_index()\n    if res.shape[0]>N:\n        return list(res.ix[:N-1,'secID'])\n    else:\n        return list(res['secID'])\ndef initialize(context):                   # \u521d\u59cb\u5316\u7b56\u7565\u8fd0\u884c\u73af\u5883\n    pass\n\ndef handle_data(context):                  # \u6838\u5fc3\u7b56\u7565\u903b\u8f91\n    account = context.get_account('fantasy_account')\n    close_price = account.reference_price\n    prev = context.previous_date.strftime('%Y%m%d')\n    input_features = get_features(prev,context.get_universe(asset_type='stock'))\n    # print 'input_features:',input_features.shape\n    candidate_list = get_candidate(input_features,10)\n    for s in  account.avail_security_position: \n        if s not in candidate_list:\n            order_pct_to(s,0)\n    cnt=0\n    for s in candidate_list:\n        if not (np.isnan(close_price[s]) or (close_price[s] == 0)):  \n            cnt=cnt+1\n    for s in candidate_list:\n        if not (np.isnan(close_price[s]) or (close_price[s] == 0)):  \n            order_pct_to(s, 0.95/float(cnt))", "language": "python", "metadata": {}, "outputs": [{"output_type": "stream", "stream": "stdout", "text": "feature day:"}, {"output_type": "stream", "stream": "stdout", "text": " 20160229\n"}, {"output_type": "stream", "stream": "stdout", "text": "feature day: 20160331\n"}, {"output_type": "stream", "stream": "stdout", "text": "feature day: 20160429\n"}, {"output_type": "stream", "stream": "stdout", "text": "feature day: 20160531\n"}, {"output_type": "stream", "stream": "stdout", "text": "feature day: 20160630\n"}, {"output_type": "stream", "stream": "stdout", "text": "feature day: 20160729\n"}, {"output_type": "stream", "stream": "stdout", "text": "feature day: 20160831\n"}, {"output_type": "stream", "stream": "stdout", "text": "feature day: 20160930\n"}, {"output_type": "stream", "stream": "stdout", "text": "feature day: 20161031\n"}, {"output_type": "stream", "stream": "stdout", "text": "feature day: 20161130\n"}, {"output_type": "stream", "stream": "stdout", "text": "feature day: 20161230\n"}, {"output_type": "stream", "stream": "stdout", "text": "feature day: 20170126\n"}, {"output_type": "stream", "stream": "stdout", "text": "feature day: 20170228\n"}, {"metadata": {}, "output_type": "pyout", "prompt_number": 18, "text": "'{\"information\": 0.62392, \"benchmark_cumulative_return\": {\"1470787200000\": 0.1271514148, \"1461801600000\": 0.0983900076, \"1468454400000\": 0.138766839, \"1485302400000\": 0.1732207528, \"1468368000000\": 0.1408881492, \"1486080000000\": 0.1692547647, \"1467072000000\": 0.0899867835, \"1463443200000\": 0.0724797191, \"1487635200000\": 0.210378086, \"1459468800000\": 0.1196983319, \"1488240000000\": 0.1999477318, \"1477440000000\": 0.1658865245, \"1478736000000\": 0.1783321929, \"1471824000000\": 0.1596292851, \"1484611200000\": 0.1560014415, \"1464307200000\": 0.0643037783, \"1480636800000\": 0.2264102421, \"1481760000000\": 0.160893939, \"1468281600000\": 0.1375219942, \"1467590400000\": 0.1137211999, \"1475107200000\": 0.1275149289, \"1476316800000\": 0.1477615556, \"1479772800000\": 0.2053531804, \"1464652800000\": 0.1015104604, \"1465171200000\": 0.1047174477, \"1482364800000\": 0.1592390113, \"1483401600000\": 0.1615170565, \"1459382400000\": 0.1183752933, \"1486684800000\": 0.1862818931, \"1464048000000\": 0.0646711153, \"1458604800000\": 0.121051953, \"1477958400000\": 0.167364213, \"1487721600000\": 0.2127878443, \"1469404800000\": 0.1228226075, \"1476748800000\": 0.1542554615, \"1472688000000\": 0.1473900483, \"1463097600000\": 0.068625635, \"1478476800000\": 0.1665092945, \"1474848000000\": 0.1191384645, \"1486425600000\": 0.1696693655, \"1473638400000\": 0.1338458443, \"1461542400000\": 0.0988946181, \"1474243200000\": 0.1340265588, \"1470009600000\": 0.10402969, \"1473206400000\": 0.1610270422, \"1479340800000\": 0.1942917156, \"1465344000000\": 0.09957334, \"1458259200000\": 0.1023455699, \"1474416000000\": 0.1352470767, \"1476057600000\": 0.1447113034, \"1486512000000\": 0.1757868987, \"1471219200000\": 0.1793094413, \"1465948800000\": 0.0830247575, \"1473292800000\": 0.1605915898, \"1485388800000\": 0.1774108965, \"1462320000000\": 0.1153771703, \"1473811200000\": 0.1255489637, \"1458172800000\": 0.085747986, \"1479945600000\": 0.2124344085, \"1458777600000\": 0.1057819256, \"1480032000000\": 0.2237492211, \"1481155200000\": 0.2059714325, \"1484265600000\": 0.1537619719, \"1467676800000\": 0.1146550073, \"1463961600000\": 0.0728960575, \"1463702400000\": 0.069766569, \"1487894400000\": 0.2072604134, \"1465862400000\": 0.0689898442, \"1487030400000\": 0.1940376727, \"1483920000000\": 0.1690493757, \"1481587200000\": 0.183344935, \"1471478400000\": 0.169252332, \"1473120000000\": 0.1616557201, \"1478563200000\": 0.1715574844, \"1479859200000\": 0.2075651954, \"1486944000000\": 0.1942013583, \"1471996800000\": 0.1572202218, \"1461888000000\": 0.0970568907, \"1461283200000\": 0.1033666068, \"1482278400000\": 0.1602343311, \"1471564800000\": 0.1694382594, \"1483488000000\": 0.1705823212, \"1480550400000\": 0.2389493954, \"1476403200000\": 0.1488743398, \"1478044800000\": 0.1584327466, \"1486339200000\": 0.1722827751, \"1466121600000\": 0.0809357675, \"1460419200000\": 0.1185010984, \"1458518400000\": 0.1292699447, \"1462492800000\": 0.0878852824, \"1479427200000\": 0.1876608837, \"1478822400000\": 0.1875795622, \"1462233600000\": 0.1167947365, \"1481673600000\": 0.1742775851, \"1485129600000\": 0.1691119307, \"1485216000000\": 0.1692405161, \"1482969600000\": 0.146065272, \"1474329600000\": 0.1320383518, \"1470700800000\": 0.131891695, \"1472428800000\": 0.1495461112, \"1460937600000\": 0.1219774197, \"1460678400000\": 0.1371824594, \"1487203200000\": 0.1958201432, \"1473724800000\": 0.1330566085, \"1486598400000\": 0.1803061512, \"1472601600000\": 0.1565011866, \"1471910400000\": 0.1613790879, \"1461110400000\": 0.1054952151, \"1482796800000\": 0.1525362411, \"1480291200000\": 0.2285391978, \"1467849600000\": 0.1155485015, \"1475020800000\": 0.1228243452, \"1461024000000\": 0.1254005693, \"1478217600000\": 0.1656693196, \"1484870400000\": 0.1659174545, \"1483660800000\": 0.1634076081, \"1487289600000\": 0.1890464773, \"1484092800000\": 0.1588299709, \"1462406400000\": 0.1169267971, \"1481068800000\": 0.2079189787, \"1463616000000\": 0.0643041258, \"1473033600000\": 0.1536813454, \"1472774400000\": 0.1517470053, \"1477353600000\": 0.1702844898, \"1468972800000\": 0.1251579949, \"1466035200000\": 0.0754858353, \"1464912000000\": 0.1083796964, \"1479081600000\": 0.1921068078, \"1459296000000\": 0.1177452252, \"1458086400000\": 0.0738726109, \"1474502400000\": 0.1437562968, \"1461628800000\": 0.1048470756, \"1488326400000\": 0.2019036187, \"1469059200000\": 0.1303424157, \"1482192000000\": 0.1499919895, \"1456876800000\": 0.060423282, \"1470268800000\": 0.1125371725, \"1466553600000\": 0.0891388155, \"1487548800000\": 0.2064058424, \"1474588800000\": 0.1383856009, \"1471392000000\": 0.1722282132, \"1484784000000\": 0.1570207408, \"1468800000000\": 0.1336435831, \"1464220800000\": 0.064898746, \"1468540800000\": 0.1385979405, \"1459814400000\": 0.1344998917, \"1470096000000\": 0.1082848213, \"1483056000000\": 0.1503454253, \"1482451200000\": 0.1494828611, \"1457568000000\": 0.0471522349, \"1478131200000\": 0.1694608487, \"1466467200000\": 0.0795321024, \"1464134400000\": 0.0631663195, \"1469664000000\": 0.1194349058, \"1459987200000\": 0.115317743, \"1468195200000\": 0.1132464768, \"1476230400000\": 0.1468454721, \"1474934400000\": 0.1262527077, \"1470614400000\": 0.1239687545, \"1464825600000\": 0.1006555418, \"1463529600000\": 0.0662280401, \"1469750400000\": 0.1134549936, \"1460073600000\": 0.1071285961, \"1484524800000\": 0.1536000239, \"1467158400000\": 0.0951958789, \"1477008000000\": 0.1564824201, \"1480377600000\": 0.2386032577, \"1470355200000\": 0.1138650765, \"1458864000000\": 0.1113305557, \"1456963200000\": 0.0628869071, \"1477526400000\": 0.1627222832, \"1466726400000\": 0.0693971469, \"1476144000000\": 0.1491207371, \"1476921600000\": 0.1533074054, \"1470873600000\": 0.123682739, \"1484697600000\": 0.1605224317, \"1456790400000\": 0.0184978664, \"1465257600000\": 0.1041148343, \"1475193600000\": 0.130607232, \"1457654400000\": 0.0489378332, \"1476662400000\": 0.1391543326, \"1459123200000\": 0.1015688451, \"1479254400000\": 0.1918788295, \"1460332800000\": 0.122548408, \"1480982400000\": 0.2021521011, \"1477612800000\": 0.1607869004, \"1459900800000\": 0.1320817928, \"1457308800000\": 0.0790184562, \"1462752000000\": 0.0653866752, \"1483574400000\": 0.1704005641, \"1480464000000\": 0.2295539792, \"1484179200000\": 0.1529668281, \"1482105600000\": 0.1569143973, \"1469145600000\": 0.1208337055, \"1488153600000\": 0.1976585657, \"1468886400000\": 0.1288518687, \"1457049600000\": 0.0752130259, \"1460505600000\": 0.1334215127, \"1478649600000\": 0.1652800884, \"1473379200000\": 0.1531127898, \"1469577600000\": 0.1184291601, \"1482710400000\": 0.1546269688, \"1460592000000\": 0.138442943, \"1470960000000\": 0.1448381511, \"1458691200000\": 0.1246321852, \"1472515200000\": 0.1510078135, \"1461196800000\": 0.0983976532, \"1476835200000\": 0.1524861971, \"1487808000000\": 0.2070769187, \"1477267200000\": 0.1703272357, \"1477872000000\": 0.1594496131, \"1487116800000\": 0.1891406574, \"1465776000000\": 0.0656389804, \"1467763200000\": 0.1179290675, \"1479686400000\": 0.1958820032, \"1467244800000\": 0.0960754719, \"1466985600000\": 0.084476034, \"1481241600000\": 0.2141581467, \"1482883200000\": 0.147498477, \"1457481600000\": 0.0675733206, \"1471305600000\": 0.1740343156, \"1472083200000\": 0.1499600169, \"1479168000000\": 0.1919754423, \"1467331200000\": 0.0961724322, \"1459209600000\": 0.0896423834, \"1466640000000\": 0.0833545615, \"1464566400000\": 0.0657672182, \"1484006400000\": 0.1670931413, \"1472169600000\": 0.1493059695, \"1462838400000\": 0.0666019801, \"1457913600000\": 0.0654127397, \"1463356800000\": 0.075706168, \"1457395200000\": 0.0800030026, \"1481846400000\": 0.1628390525, \"1480896000000\": 0.205715652, \"1464739200000\": 0.0983781917, \"1461715200000\": 0.1002440688, \"1462924800000\": 0.0713620695, \"1481500800000\": 0.184784743, \"1466380800000\": 0.0817409896, \"1467936000000\": 0.1094062938, \"1469491200000\": 0.136272979, \"1470182400000\": 0.1098327105, \"1463011200000\": 0.0739087538, \"1458000000000\": 0.0685717682}, \"benchmark_annualized_return\": 0.20642, \"turnover_rate\": 9.50337, \"max_drawdown\": 0.09222, \"beta\": 1.16587, \"sharpe\": 1.25419, \"alpha\": 0.04528, \"volatility\": 0.19545, \"annualized_return\": 0.28013, \"cumulative_return\": {\"1470787200000\": 0.23142749, \"1461801600000\": 0.147025919, \"1468454400000\": 0.1854937964, \"1485302400000\": 0.2516743271, \"1468368000000\": 0.1920958064, \"1486080000000\": 0.2506712404, \"1467072000000\": 0.1436818201, \"1463443200000\": 0.119091888, \"1487635200000\": 0.2882769304, \"1459468800000\": 0.166384529, \"1488240000000\": 0.2692787004, \"1477440000000\": 0.2297787268, \"1478736000000\": 0.2237778973, \"1471824000000\": 0.24418979, \"1484611200000\": 0.2278247971, \"1464307200000\": 0.125683578, \"1480636800000\": 0.2648156609, \"1481760000000\": 0.2486336209, \"1468281600000\": 0.1729600064, \"1467590400000\": 0.1570899564, \"1475107200000\": 0.1863859674, \"1476316800000\": 0.2128374868, \"1479772800000\": 0.2562260373, \"1464652800000\": 0.162496098, \"1465171200000\": 0.1823971201, \"1482364800000\": 0.2378567109, \"1483401600000\": 0.2313007271, \"1459382400000\": 0.1691844406, \"1486684800000\": 0.2581023204, \"1464048000000\": 0.112066298, \"1458604800000\": 0.1822541706, \"1477958400000\": 0.2276745873, \"1487721600000\": 0.2890511404, \"1469404800000\": 0.1871606064, \"1476748800000\": 0.2241227868, \"1472688000000\": 0.2277677774, \"1463097600000\": 0.121496968, \"1478476800000\": 0.2078353273, \"1474848000000\": 0.1847838774, \"1486425600000\": 0.2505391404, \"1473638400000\": 0.1933800574, \"1461542400000\": 0.149565749, \"1474243200000\": 0.1943224974, \"1470009600000\": 0.15474122, \"1473206400000\": 0.2303807674, \"1479340800000\": 0.2568485873, \"1465344000000\": 0.1751999101, \"1458259200000\": 0.1453649606, \"1474416000000\": 0.1967000474, \"1476057600000\": 0.2000563268, \"1486512000000\": 0.2517446404, \"1471219200000\": 0.2658099, \"1465948800000\": 0.1641832001, \"1473292800000\": 0.2284093474, \"1485388800000\": 0.2617815671, \"1462320000000\": 0.171730948, \"1473811200000\": 0.1873705174, \"1458172800000\": 0.1008975806, \"1479945600000\": 0.2510100173, \"1458777600000\": 0.1560561906, \"1480032000000\": 0.2628256173, \"1481155200000\": 0.2792116809, \"1484265600000\": 0.2266473471, \"1467676800000\": 0.1623964264, \"1463961600000\": 0.113392938, \"1463702400000\": 0.108460678, \"1487894400000\": 0.2866814704, \"1465862400000\": 0.1410017001, \"1487030400000\": 0.2682164004, \"1483920000000\": 0.2484547271, \"1481587200000\": 0.2673546609, \"1471478400000\": 0.2653569, \"1473120000000\": 0.2313584474, \"1478563200000\": 0.2126772173, \"1479859200000\": 0.2520609973, \"1486944000000\": 0.2683808204, \"1471996800000\": 0.23453758, \"1461888000000\": 0.140208089, \"1461283200000\": 0.156661479, \"1482278400000\": 0.2304680709, \"1471564800000\": 0.25319191, \"1483488000000\": 0.2426690971, \"1480550400000\": 0.2743716809, \"1476403200000\": 0.2227890268, \"1478044800000\": 0.2117454673, \"1486339200000\": 0.2492704104, \"1466121600000\": 0.1594462001, \"1460419200000\": 0.184809949, \"1458518400000\": 0.2130544706, \"1462492800000\": 0.144992498, \"1479427200000\": 0.2495916673, \"1478822400000\": 0.2344850073, \"1462233600000\": 0.171720158, \"1481673600000\": 0.2631378309, \"1485129600000\": 0.2440795471, \"1485216000000\": 0.2484383871, \"1482969600000\": 0.2187286009, \"1474329600000\": 0.1907562774, \"1470700800000\": 0.22833547, \"1472428800000\": 0.22637617, \"1460937600000\": 0.185743159, \"1460678400000\": 0.194454739, \"1487203200000\": 0.2690662704, \"1473724800000\": 0.1936332774, \"1486598400000\": 0.2564311104, \"1472601600000\": 0.23833075, \"1471910400000\": 0.2433151, \"1461110400000\": 0.166590879, \"1482796800000\": 0.2199985109, \"1480291200000\": 0.2631733573, \"1467849600000\": 0.1590598264, \"1475020800000\": 0.1856850774, \"1461024000000\": 0.189902509, \"1478217600000\": 0.2101418373, \"1484870400000\": 0.2350147771, \"1483660800000\": 0.2418492471, \"1487289600000\": 0.2621819304, \"1484092800000\": 0.2367862071, \"1462406400000\": 0.178145598, \"1481068800000\": 0.2699789709, \"1463616000000\": 0.101423348, \"1473033600000\": 0.2279248574, \"1472774400000\": 0.2273289774, \"1477353600000\": 0.2316400868, \"1468972800000\": 0.1863294764, \"1466035200000\": 0.1470760501, \"1464912000000\": 0.1738425001, \"1479081600000\": 0.2464790473, \"1459296000000\": 0.1738712106, \"1458086400000\": 0.0667468906, \"1474502400000\": 0.2020621174, \"1461628800000\": 0.156161189, \"1488326400000\": 0.2738270099, \"1469059200000\": 0.1869339764, \"1482192000000\": 0.2234226209, \"1456876800000\": 0.0910486806, \"1470268800000\": 0.18712784, \"1466553600000\": 0.1513557601, \"1487548800000\": 0.2763635904, \"1474588800000\": 0.2025932174, \"1471392000000\": 0.27518544, \"1484784000000\": 0.2283877871, \"1468800000000\": 0.1898383764, \"1464220800000\": 0.116169438, \"1468540800000\": 0.1918228964, \"1459814400000\": 0.181483239, \"1470096000000\": 0.16701747, \"1483056000000\": 0.2218812909, \"1482451200000\": 0.2328378809, \"1457568000000\": 0.0391449206, \"1478131200000\": 0.2176742473, \"1466467200000\": 0.1472996901, \"1464134400000\": 0.110485488, \"1469664000000\": 0.1745658264, \"1459987200000\": 0.161758859, \"1468195200000\": 0.1497526664, \"1476230400000\": 0.2137892268, \"1474934400000\": 0.1927353474, \"1470614400000\": 0.21844804, \"1464825600000\": 0.1769334401, \"1463529600000\": 0.101183608, \"1469750400000\": 0.1692790864, \"1460073600000\": 0.154634859, \"1484524800000\": 0.2262472671, \"1467158400000\": 0.1497388201, \"1477008000000\": 0.2227447868, \"1480377600000\": 0.2650323273, \"1470355200000\": 0.19610249, \"1458864000000\": 0.1635272706, \"1456963200000\": 0.0950841406, \"1477526400000\": 0.2212882168, \"1466726400000\": 0.1204199001, \"1476144000000\": 0.2177673968, \"1476921600000\": 0.2243319968, \"1470873600000\": 0.20988416, \"1484697600000\": 0.2308291971, \"1456790400000\": 0.0275768406, \"1465257600000\": 0.1789939901, \"1475193600000\": 0.1896380674, \"1457654400000\": 0.0393803606, \"1476662400000\": 0.2099827968, \"1459123200000\": 0.1463423406, \"1479254400000\": 0.2511580273, \"1460332800000\": 0.182723039, \"1480982400000\": 0.2541263609, \"1477612800000\": 0.2211792468, \"1459900800000\": 0.175665549, \"1457308800000\": 0.0925701406, \"1462752000000\": 0.119662948, \"1483574400000\": 0.2387256671, \"1480464000000\": 0.2567578473, \"1484179200000\": 0.2250363271, \"1482105600000\": 0.2388795409, \"1469145600000\": 0.1806896964, \"1488153600000\": 0.2693119604, \"1468886400000\": 0.1882366164, \"1457049600000\": 0.0737536306, \"1460505600000\": 0.197830129, \"1478649600000\": 0.2121407473, \"1473379200000\": 0.2180269974, \"1469577600000\": 0.1773451264, \"1482710400000\": 0.2225967709, \"1460592000000\": 0.199083789, \"1470960000000\": 0.23475137, \"1458691200000\": 0.2034898106, \"1472515200000\": 0.22218693, \"1461196800000\": 0.159298589, \"1476835200000\": 0.2259653868, \"1487808000000\": 0.2820764304, \"1477267200000\": 0.2328179268, \"1477872000000\": 0.2182291668, \"1487116800000\": 0.2612771404, \"1465776000000\": 0.1375418901, \"1467763200000\": 0.1610173564, \"1479686400000\": 0.2507324573, \"1467244800000\": 0.1481072701, \"1466985600000\": 0.1424895501, \"1481241600000\": 0.2801458309, \"1482883200000\": 0.2211447709, \"1457481600000\": 0.0703709206, \"1471305600000\": 0.29111333, \"1472083200000\": 0.2250627, \"1479168000000\": 0.2488940173, \"1467331200000\": 0.1461691564, \"1459209600000\": 0.1355344006, \"1466640000000\": 0.1416594601, \"1464566400000\": 0.119186488, \"1484006400000\": 0.2457367371, \"1472169600000\": 0.22223334, \"1462838400000\": 0.134317388, \"1457913600000\": 0.0779060606, \"1463356800000\": 0.130683188, \"1457395200000\": 0.0983007906, \"1481846400000\": 0.2392167409, \"1480896000000\": 0.2580710309, \"1464739200000\": 0.1626985201, \"1461715200000\": 0.149497119, \"1462924800000\": 0.134705358, \"1481500800000\": 0.2567382009, \"1466380800000\": 0.1549673701, \"1467936000000\": 0.1517078764, \"1469491200000\": 0.1985003164, \"1470182400000\": 0.16896449, \"1463011200000\": 0.126284238, \"1458000000000\": 0.0671780006}}'"}], "trading_days": "", "trusted": true}, {"cell_type": "markdown", "id": "0BF9FFAF0C3345B9837A31CB057B7D74", "metadata": {}, "source": "\u540c\u6837\u6211\u4eec\u5c1d\u8bd5\u4e0b\u591a\u5c42\u7f51\u7edc\u7684\u6548\u679c\uff0c\u4e0b\u9762\u4ee3\u7801\u5c55\u793a\u5982\u4f55\u8f7d\u5165\u4e4b\u524d\u8bad\u7ec3\u7684MLP\u6a21\u578b\u3002"}, {"cell_type": "code", "collapsed": false, "id": "351349E008B2466A860EC8F0954BD6D8", "input": "tf.reset_default_graph()\nX = tf.placeholder(tf.float32, [None,feature_dim])\nY = tf.placeholder(tf.float32, [None,1])\nlayer1 = feature_dim/2\nlayer2 = layer1/2\nW = {  \n    \"L1\":tf.Variable(tf.random_normal([feature_dim, layer1]),name='Inference/W_L1'),  \n    \"L2\":tf.Variable(tf.random_normal([layer1, layer2]),name='Inference/W_L2'),  \n    \"output\": tf.Variable(tf.random_normal([layer2, 1]),name='Inference/W_output')  \n    }  \n\nb = {  \n    \"L1\":tf.Variable(tf.random_normal([layer1]),name='Inference/b_L1'),  \n    \"L2\":tf.Variable(tf.random_normal([layer2]),name='Inference/b_L2'),  \n    \"output\":tf.Variable(tf.random_normal([1]),name='Inference/b_output')  \n}  \n\nnet1 = tf.nn.sigmoid(tf.matmul(X, W[\"L1\"]) + b[\"L1\"])\nnet2 = tf.nn.sigmoid(tf.matmul(net1, W[\"L2\"]) + b[\"L2\"])\nY_ = tf.nn.sigmoid(tf.matmul(net2, W[\"output\"]) + b[\"output\"])\nsess = tf.Session()\nsaver = tf.train.Saver()\nsaver.restore(sess, \"tensorflow_model_mlp/my-model.ckpt\")", "language": "python", "metadata": {}, "outputs": [], "trusted": true}, {"cell_type": "code", "collapsed": false, "id": "513BF825E9C44084B2CB5A47C581803F", "input": "\u672c\u6587\u7c97\u6d45\u5730\u4ecb\u7ecd\u4e86\u5982\u4f55\u5728\u4f18\u77ff\u4e0a\u4f7f\u7528TensorFlow\uff0c\u7279\u5f81\u3001\u6a21\u578b\u3001\u7ec4\u5408\u6784\u5efa\u672c\u8eab\u90fd\u6709\u5f88\u591a\u53ef\u4ee5\u8c03\u6574\u3002TensorFlow\u4f5c\u4e3a\u4e00\u4e2a\u8ba1\u7b97\u6846\u67b6\u8fd8\u6709\u8bb8\u591a\u503c\u5f97\u7814\u7a76\u7684\u5730\u65b9\uff0c\u4f8b\u5982\u6211\u4eec\u5728\u8bad\u7ec3\u5b9a\u4e49LR\u548cMLP\u7684\u56fe\u65f6\u662f\u4e0d\u662f\u6709\u5f88\u591a\u91cd\u590d\u7684\u5de5\u4f5c\uff1f\u5176\u5b9eTensorFlow\u4e5f\u5c06\u8fd9\u4e9b\u91cd\u590d\u7684\u5de5\u4f5c\u62bd\u8c61\u5316\uff0c\u4f5c\u4e3a\u4e00\u4e2a\u6846\u67b6\u53ef\u4ee5\u65b9\u4fbf\u7528\u6237\u8fdb\u884c\u6a21\u578b\u7684\u5b9a\u4e49\u548c\u8bad\u7ec3\u3002\u4e0b\u6b21\u6211\u4eec\u4f1a\u4ecb\u7ecd\u5982\u4f55\u4f7f\u7528TensorFlow\u4e2d\u7684\u9ad8\u7ea7API\uff1aEstimator\u3001Experiment\u548cDataset\u3002\u53e6\u5916\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u8fd8\u6709\u5f88\u591a\u53c2\u6570\u9700\u8981\u8fdb\u884c\u8c03\u6574\u4f18\u5316\uff0c\u540e\u9762\u6709\u673a\u4f1a\u6211\u4eec\u8fd8\u4f1a\u8fdb\u884c\u4ecb\u7ecd\u3002", "language": "python", "metadata": {}, "outputs": [], "trusted": true}], "metadata": {}}]}