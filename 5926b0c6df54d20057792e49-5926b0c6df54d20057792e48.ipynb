{"metadata": {"signature": "sha256:ec57e9f5b848066278c457ef169462c0a88d55e253e5062395b5584551acacb1"}, "nbformat": 3, "nbformat_minor": 0, "worksheets": [{"cells": [{"cell_type": "markdown", "id": "4FBDEB98A3ED41AD8FD63611D2C830EA", "metadata": {}, "source": "# CW-RNN \u6536\u76ca\u7387\u65f6\u95f4\u5e8f\u5217\u56de\u5f52"}, {"cell_type": "markdown", "id": "B037320A57084FC88C3F4F098FE83117", "metadata": {}, "source": "![](http://storage-uqer.datayes.com/57b19ec7228e5b79a7759010/4a511654-4134-11e7-a439-0242ac140004)\nCW-RNN\u662f\u4e00\u4e2a\u5e26\u65f6\u949f\u9891\u7387\u7684RNN\u53d8\u79cd\uff0c\u4f3c\u4e4e\u662f\u5bf9\u56de\u5f52\u6709\u4e0d\u9519\u7684\u6548\u679c\uff0c\u4e0d\u8fc7\u8fd9\u4e2a\u6709\u4e89\u8bba\u3002\u5bf9\u4e00\u4e2a\u65f6\u95f4\u5e8f\u5217\uff0c\u65e0\u8bba\u662f\u56de\u5f52\u8fd8\u662f\u5206\u7c7b\u90fd\u662f\u5c06\u6570\u636e\u7ecf\u8fc7\u5faa\u73af\u6309\u7167\u65f6\u95f4\u5e8f\u5217\u8f93\u5165\uff0cRNN\u4f7f\u7528\u9690\u85cf\u77e9\u9635\u8fdb\u884c\u8bb0\u5fc6\uff0c\u7136\u540e\u5224\u5b9a\u8f93\u51fa\u3002\u9488\u5bf9\u539f\u59cbRNN\u5bf9\u957f\u5e8f\u5217\u8bb0\u5fc6\u6548\u679c\u6781\u5dee\uff0c\u4f5c\u8005\u5728\u8fd9\u91cc\u8bbe\u8ba1\u4e86\u4e00\u79cd\u5c06\u9690\u85cf\u72b6\u6001\u77e9\u9635\uff08\u8bb0\u5fc6\u673a\u5236\uff09\u5206\u5272\u6210g\u4e2a\u5c0f\u6a21\u5757\u5e76\u4f7f\u7528\u7c7b\u65f6\u949f\u9891\u7387\u63a9\u7801\u7684\u65b9\u5f0f\uff0c\u5c06RNN\u7684\u8bb0\u5fc6\u5206\u5272\u6210\u51e0\u4e2a\u90e8\u5206\uff0c\u7136\u540e\u7ecf\u8fc7\u7279\u5b9a\u8bbe\u8ba1\uff0c\u4f7fCW-RNN\u8bb0\u5fc6\u77e9\u9635\u4e2d\u6bcf\u4e2a\u90e8\u5206\u5904\u7406\u4e0d\u540c\u7684\u65f6\u523b\u7684\u6570\u636e\uff0c\u52a0\u5f3a\u8bb0\u5fc6\u6548\u679c\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff0cY\u8f74\u65b9\u5411CW\u9ad8\u9891\u5411\u4f4e\u9891\u6392\u5217\u3002\u5176\u4e2d\u901a\u8fc7\u8bbe\u7f6e\u4e09\u89d2\u63a9\u7801\u77e9\u9635\u4f7f\u76f8\u5bf9\u4f4e\u9891\u4e0d\u6c72\u53d6\u76f8\u5bf9\u9ad8\u9891\u7684\u8bb0\u5fc6\u4fe1\u606f\uff0c\u4f46\u76f8\u5bf9\u9ad8\u9891\u6c72\u53d6\u76f8\u5bf9\u4f4e\u9891\u7684\u5168\u90e8\u8bb0\u5fc6\u4fe1\u606f\u3002\u4e5f\u5c31\u662f\u5177\u6709\u9ad8\u9891\u66f4\u65b0\u7684g\u6a21\u5757\u76f8\u5f53\u4e8e\u77ed\u671f\u8bb0\u5fc6\uff08\u7f13\u5b58\u8bb0\u5fc6\uff09\uff0c\u4f4e\u9891g\u6a21\u5757\u76f8\u5f53\u4e8e\u957f\u671f\u8bb0\u5fc6\u3002\n![](https://pic4.zhimg.com/v2-d5f26a7478f7ff771aed1fd92f10c05f_b.png)\n\u5728\u8bba\u6587\u4e2d\u4f5c\u8005\u5217\u4e3e\u7684\u6570\u636e\u663e\u793a\u8fd9\u79cd\u8bbe\u8ba1\u5728\u7279\u5b9a\u7684\u5e94\u7528\u4e2d\u5177\u6709\u66f4\u4f18\u7684\u6548\u679c\u3002\u4f8b\u5982\uff0c\u5bf9\u4e00\u4e2a\u957f\u5ea6\u4e3aL\u7684\u65f6\u95f4\u5e8f\u5217\u8fdb\u884c\u9884\u6d4b\uff0c\u5728\u4f7f\u7528CW-RNN\u7684\u65f6\u5019\u53ef\u4ee5\u901a\u8fc7\u8bbe\u7f6e\u65f6\u949f\u9891\u7387\u4eba\u5de5\u8bbe\u5b9a\u8bb0\u5fc6\u5e8f\u5217\u3002\u5982\uff0cL\u957f\u5ea6\u4e3a36\uff0c\u90a3\u6211\u4eec\u53ef\u4ee5\u8bbe\u7f6eCW\u4e3a[1,2,4,8,16,12,18,36]\uff0c\u8fd9\u76f8\u5f53\u4e8e\u5728\u957f\u5ea6\u4e3a36\u7684\u5e8f\u5217\u8bbe\u7f6e\u4e86\u591a\u4e2a\u8bb0\u5fc6\u70b9\uff0c\u6bcf\u4e2a\u8bb0\u5fc6\u70b9\u57fa\u4e8e\u6b64\u8bb0\u5fc6\u70b9\u4e4b\u524d\u7684\u8f93\u5165\u503c\u8fdb\u884c\u62bd\u8c61\u8bb0\u5fc6\u3002\u8fd9\u4e2a\u8bbe\u8ba1\u4e0eRNN\u7ecf\u5178\u53d8\u79cdLSTM\u6709\u5de8\u5927\u7684\u5dee\u5f02\u3002LSTM\u901a\u8fc7gate\u7ed3\u6784\u5b9e\u73b0\u81ea\u52a8\u7684\u8bb0\u5fc6\u9009\u62e9\u6c72\u53d6\uff0c\u8fd9\u91cc\u7684CW\u8bbe\u8ba1\u9700\u8981\u6709\u4e00\u79cd\u7c7b\u4f3c\u4e8e\u5148\u9a8c\u503c\u7684CW\u8bbe\u5b9a\uff0c\u8fd9\u5e76\u4e0d\u662f\u4e00\u79cd\u5341\u5206\u4f18\u96c5\u7684\u8bbe\u8ba1\u3002\u4f46\u8fd9\u79cd\u8bbe\u8ba1\u589e\u52a0\u7684\u4eba\u5de5\u8bbe\u5b9a\u5e8f\u5217\u8282\u70b9\u9009\u53d6\u7684\u64cd\u4f5c\u7a7a\u95f4\uff0c\u5e94\u8be5\u53ef\u4ee5\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u5bf9\u6807\u6536\u76ca\u7387\u7684\u65f6\u95f4\u5e8f\u5217\u8fdb\u884c\u7279\u522b\u8bbe\u8ba1\uff0c\u4ece\u800c\u53d6\u5f97\u4e0d\u9519\u7684\u56de\u5f52\u6548\u679c\u3002\n\n\u5982\u4e0b\u56fe\uff0c\u8be5\u8bbe\u8ba1\u8fdb\u884c\u65f6\u95f4\u5e8f\u5217\u56de\u5f52\u62df\u5408\uff0c\u5728\u53d6\u5c40\u90e8\u56fe\u7684\u65f6\u5019\u53ef\u4ee5\u89c2\u5bdf\u5230\uff0cLSTM\u7684\u56de\u5f52\u6548\u679c\u76f8\u5bf9\u5e73\u6ed1\uff0c\u800cCW-RNN\u5e76\u6ca1\u6709\u8fd9\u79cd\u7f3a\u9677\u3002\n![](https://pic1.zhimg.com/v2-ef82d480198390e36887e831b2d63cb8_b.png)\n\u9884\u6d4b\u5e8f\u5217\u534f\u65b9\u5dee\n![](https://pic4.zhimg.com/v2-392cd000c4ca71c3e7d8f7febf0737df_b.png)\n![](https://pic4.zhimg.com/v2-25560e4b0feb3739c0b2e7a2160defa7_b.png)"}, {"cell_type": "code", "collapsed": false, "id": "CA93DCD7AFC846E082071397FB8197FD", "input": "import numpy as np\nimport pandas as pd\nimport statsmodels.api as sm\nimport tensorflow as tf\nimport matplotlib.pylab as plt\nimport seaborn as sns\n%matplotlib inline \nsns.set_style('whitegrid')\n\nclass ClockworkRNN(object):\n    def __init__(self,\n                 in_length,\n                 in_width,\n                 out_width,\n                 training_epochs=1e2,\n                 batch_size=1024,\n                 learning_rate=1e-4,\n                 hidden_neurons=360,\n                 Rb=60,\n                 Ti=2,\n                 Ti_sum=6,\n                 display=1e2):\n        # \n        self.in_length = in_length\n        self.in_width = in_width\n        self.out_width = out_width\n        self.batch_size = batch_size    \n        self.learning_rate = learning_rate\n        self.display = display\n        #\n        self.hidden_neurons = hidden_neurons\n        self.Rb = Rb\n        self.Ti = Ti\n        self.Ti_sum = Ti_sum\n        self.clockwork_periods = [self.Ti**x for x in range(self.Ti_sum)]\n        self.training_epochs = training_epochs\n        self.inputs = tf.placeholder(dtype=tf.float32, shape=[None, self.in_length, self.in_width], name='inputs')\n        self.targets = tf.placeholder(dtype=tf.float32, shape=[None, self.out_width], name='targets')\n        #\n        self.__inference()   \n        \n    #  \u4e0b\u4e09\u89d2\u63a9\u7801\u77e9\u9635\uff0c\u5904\u7406g-moduels\u5212\u5206\u5f62\u6210\u7684\u4e0a\u4e09\u89d2\u6743\u91cd\u77e9\u9635\n    def __Mask_Matrix(self,W,k):\n        length = np.int(W/k)\n        tmp = np.ones([W,W])\n        for i in range(length)[1:]:\n            tmp[i*k:(i+1)*k,:i*k]=0\n        tmp[(i+1)*k:,:i*k]=0\n        return np.transpose(tmp)\n    \n    def __inference(self):\n        self.sess = sess = tf.InteractiveSession()\n        \n        # \u6807\u51c6RNN\u521d\u59cb\u6743\u91cd\n        with tf.variable_scope('input_layers'):\n            self.WI = tf.get_variable('W', shape=[self.in_width, self.hidden_neurons], initializer=tf.truncated_normal_initializer(stddev=0.1))\n            self.bI = tf.get_variable('b', shape=[self.hidden_neurons], initializer=tf.truncated_normal_initializer(stddev=0.1))\n        \n        traingular_mask = self.__Mask_Matrix(self.hidden_neurons, self.Rb)\n        self.traingular_mask = tf.constant(traingular_mask, dtype=tf.float32, name='mask_upper_traingular')\n        with tf.variable_scope('hidden_layers'):\n            self.WH = tf.get_variable('W', shape=[self.hidden_neurons, self.hidden_neurons], initializer=tf.truncated_normal_initializer(stddev=0.1))\n            self.WH = tf.multiply(self.WH, self.traingular_mask)\n            self.bH = tf.get_variable('b', shape=[self.hidden_neurons], initializer=tf.truncated_normal_initializer(stddev=0.1))\n        \n        with tf.variable_scope('output_layers'):\n            self.WO = tf.get_variable('W', shape=[self.hidden_neurons, self.out_width], initializer=tf.truncated_normal_initializer(stddev=0.1))\n            self.bO = tf.get_variable('b', shape=[self.out_width], initializer=tf.truncated_normal_initializer(stddev=0.1))\n\n        # \u8f93\u5165\u8bad\u7ec3\u6570\u636e\u8f6c\u6362\u4e3a\u5217\u8868\n        X_list = [tf.squeeze(x, axis=[1]) for x \n                  in tf.split(value=self.inputs, axis=1, num_or_size_splits=self.in_length, name='inputs_list')]\n        \n        with tf.variable_scope('clockwork_rnn') as scope:\n            # \u5b9a\u4e49\u521d\u59cb\u65f6\u523b\u7684\u9690\u85cf\u72b6\u6001\uff0c\u8bbe\u5b9a\u4e3a\u51680\n            self.state = tf.get_variable('hidden_sate', shape=[self.batch_size, self.hidden_neurons],initializer=tf.zeros_initializer(),trainable=False)\n            for i in range(self.in_length):\n                \n                # \u83b7\u53d6g_moduels\u7d22\u5f15\n                if i>0:\n                    scope.reuse_variables()\n                g_counter = 0\n                for j in range(self.Ti_sum):\n                    if i%self.clockwork_periods[j]==0:\n                        g_counter += 1\n                if g_counter == self.Ti_sum:\n                    g_counter = self.hidden_neurons\n                else:\n                    g_counter *= self.Rb\n                \n                # t\u65f6\u523beq1\n                tmp_right = tf.matmul(X_list[i], tf.slice(self.WI, [0,0], [-1,g_counter]))\n                tmp_right = tf.nn.bias_add(tmp_right, tf.slice(self.bI,[0],[g_counter]))\n                self.WH = tf.multiply(self.WH, self.traingular_mask)\n                tmp_left = tf.matmul(self.state, tf.slice(self.WH, [0,0], [-1,g_counter]))\n                tmp_left = tf.nn.bias_add(tmp_left, tf.slice(self.bH,[0],[g_counter]))\n                tmp_hidden = tf.tanh(tf.add(tmp_left, tmp_right))\n                \n                #\u66f4\u65b0\u9690\u85cf\u72b6\u6001\n                self.state = tf.concat(axis=1, values=[tmp_hidden, tf.slice(self.state, [0, g_counter], [-1,-1])])\n            \n            self.final_state = self.state\n            self.pred = tf.nn.bias_add(tf.matmul(self.final_state, self.WO),self.bO)\n            #self.cost_sum = tf.reduce_sum(tf.square(self.targets - self.pred))\n            self.cost = tf.reduce_sum(tf.square(self.targets - self.pred))\n        self.optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(self.cost)\n        self.sess.run(tf.global_variables_initializer())\n            \n    def fit(self, inputs, targets):\n        sess = self.sess\n        for step in range(np.int(self.training_epochs)):\n            for i in range(np.int(len(targets)/self.batch_size)):\n                batch_x = inputs[i*self.batch_size:(i+1)*self.batch_size].reshape([self.batch_size, self.in_length, self.in_width])\n                batch_y = targets[i*self.batch_size:(i+1)*self.batch_size].reshape([self.batch_size, self.out_width])                    \n                sess.run(self.optimizer, feed_dict={self.inputs:batch_x, self.targets:batch_y})\n            if len(targets)%self.batch_size !=0:\n                batch_x = inputs[-self.batch_size:].reshape([self.batch_size, self.in_length, self.in_width])\n                batch_y = targets[-self.batch_size:].reshape([self.batch_size, self.out_width])                    \n                sess.run(self.optimizer, feed_dict={self.inputs:batch_x, self.targets:batch_y})\n            if step%self.display == 0:\n                print (sess.run(self.cost, feed_dict={self.inputs:batch_x, self.targets:batch_y}))\n            \n                \n    def prediction(self, inputs):\n        sess = self.sess\n        tmp = np.zeros(self.out_width)\n        for i in range(np.int(len(inputs)/self.batch_size)):    \n            batch_x = inputs[i*self.batch_size:(i+1)*self.batch_size].reshape([self.batch_size, self.in_length, self.in_width])\n            tmp = np.vstack((tmp,sess.run(self.pred, feed_dict={self.inputs:batch_x})))   \n        if len(inputs)%self.batch_size !=0:\n            batch_x = inputs[-self.batch_size:].reshape([self.batch_size, self.in_length, self.in_width])\n            tp = np.vstack((tmp,sess.run(self.pred, feed_dict={self.inputs:batch_x})))  \n            l = len(targets)%self.batch_size\n            tp = tp[-l:]\n            tmp = np.vstack((tmp,tp))\n        tmp = np.delete(tmp,0,0)\n        return tmp\n    \n\ntmp = pd.read_csv('F:/QuantPython/MyCodes/ClockWorkRNN/SHCI.csv')\ntmp['trading_moment'] = pd.to_datetime(tmp['Unnamed: 0'].values)\ntmp.set_index('trading_moment', drop=True, inplace=True)\ntmp['Returns'] = np.log(tmp.close.shift(-10)/tmp.close)\ntmp.dropna(inplace=True)\ntp = np.array(tmp['Returns'])\ndel tmp['Unnamed: 0']\n\nin_length = 36\nout_length = 1\ninputs = np.zeros(in_length)\ntargets = np.zeros(1)\nfor i in range(len(tp))[in_length:-out_length]:\n    m = tp[i-in_length:i]\n    R = tp[i:i+1]\n    inputs = np.vstack((inputs,m))\n    targets = np.vstack((targets,R))\ntargets = np.delete(targets,0,0)\ninputs = np.delete(inputs,0,0)\n\nT_inputs = inputs[:512]\nT_targets = targets[:512]\n\na = ClockworkRNN(36,1,1,training_epochs=2e4,batch_size=512)\na.fit(T_inputs, T_targets)\n\noutputs = a.prediction(T_inputs)\nCW_RNN = outputs\nshow = pd.DataFrame([T_targets.ravel('C'), outputs.ravel('C')]).T\nshow.plot()", "language": "python", "metadata": {}, "outputs": [], "trusted": true}], "metadata": {}}]}